[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Matt Triano is a Data Scientist at the University of Chicago’s Urban Labs. When not innovating on data platforms, Matt enjoys exploring new tech, open source development, and hardware hacking.\n\n\nDePaul University | Chicago, IL M.S. in Computer Science | Sept 2013 - Mar 2018\nPurdue University | West Lafayette, IN B.S. in Physics | Aug 2006 - Dec 2010"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "",
    "text": "DePaul University | Chicago, IL M.S. in Computer Science | Sept 2013 - Mar 2018\nPurdue University | West Lafayette, IN B.S. in Physics | Aug 2006 - Dec 2010"
  },
  {
    "objectID": "posts/007_midjourney_experiments/midjourney_experiments.html",
    "href": "posts/007_midjourney_experiments/midjourney_experiments.html",
    "title": "Midjourney Experiments",
    "section": "",
    "text": "Over the past decade, the field of generative AI has made amazing progress. Driven by breakthrough advances in machine learning modeling strategies (primarily the GAN 1 in 2014 and the Transformer 2 in 2017) coupled with exponential growth of the amount of available computing power 3, generative AI applications for different data formats started appearing in the late 2010s and early 2020s. Notable examples include\nOver the past two years, text-to-image platforms have jockeyed to lead that market with DALL-E generating a massive amount of initial hype, but Midjourney has emerged as the clearly superior service, despite having the least conventional workflow.\nMidjourney’s model was the first to reliably produce human forms (including well-formed hands, a difficulty for prior models), its best outputs are unambiguously superior to the best outputs from any other model, and it’s tremendously fun to play with. Midjourney isn’t free to use (the least expensive tier is \\$10/mo), but it’s free to look at (or search) the endless stream of images generated by other Midjourney users, it’s easy to unsubscribe, and it’s hard to not get at least \\$10 worth of fun out of the service.\nIn this post, I’ll point out the important parts of the interface, walk through setup and (un)subscription, demonstrate useful commands, and show examples of what Midjourney can do."
  },
  {
    "objectID": "posts/007_midjourney_experiments/midjourney_experiments.html#midjourney-interface",
    "href": "posts/007_midjourney_experiments/midjourney_experiments.html#midjourney-interface",
    "title": "Midjourney Experiments",
    "section": "Midjourney Interface",
    "text": "Midjourney Interface\nThe Discord interface is packed with buttons, lists, and inputs, but you only need to know 5 areas you need to know.\n\nThe Midjourney server icon\n\nThis, the ship icon, should always be selected.\n\nThe Channel list\n\nPick any “newbies-##” or “general-##” channel.\n\nThe Prompt input\n\nThis is where you enter prompts or commands for the Midjourney Bot to handle.\n\nThe Search bar\n\nYou can search through all public images in the Midjourney server.\n\nThe message display space\n\nThis is where you’ll find all (public) images generated in the selected channel (either by you or other users).\n\n\n\n\n\nInterface"
  },
  {
    "objectID": "posts/007_midjourney_experiments/midjourney_experiments.html#how-to-unsubscribe",
    "href": "posts/007_midjourney_experiments/midjourney_experiments.html#how-to-unsubscribe",
    "title": "Midjourney Experiments",
    "section": "How to unsubscribe",
    "text": "How to unsubscribe\nTo unsubscribe, go to the Midjourney account page, click Cancel Plan (1, then 2), and then confirm cancellation in the popup. If you’ve used less than 20 GPU minutes (~30 images) in the billing period, you can choose to get a refund."
  },
  {
    "objectID": "posts/007_midjourney_experiments/midjourney_experiments.html#aspect-ratio",
    "href": "posts/007_midjourney_experiments/midjourney_experiments.html#aspect-ratio",
    "title": "Midjourney Experiments",
    "section": "Aspect Ratio",
    "text": "Aspect Ratio\nThe desired aspect ratio for an image.\n\nParameter: --ar l:w or --aspect w:h (where w is width h is height)\nExamples:\n\n--ar 1:1 (square, default)\n--ar 9:16 (good for stories; typical phone screen aspect ratio)\n--ar 19:10 (good for covers or landscapes)\n--ar 4:5 (good for portraits)"
  },
  {
    "objectID": "posts/007_midjourney_experiments/midjourney_experiments.html#quality",
    "href": "posts/007_midjourney_experiments/midjourney_experiments.html#quality",
    "title": "Midjourney Experiments",
    "section": "Quality",
    "text": "Quality\nControls the rendering quality (i.e., amount of CPU time spent generating an image).\n\nParameter: --q value or --quality value\nAccepted values: [0.25, 0.5, 1] (higher values = higher quality, default is 1)\nExample: --q 0.25"
  },
  {
    "objectID": "posts/007_midjourney_experiments/midjourney_experiments.html#stylize",
    "href": "posts/007_midjourney_experiments/midjourney_experiments.html#stylize",
    "title": "Midjourney Experiments",
    "section": "Stylize",
    "text": "Stylize\nInfluences how strongly Midjourney stylizes an image.\n\nParameter: --s value or --stylize value\nAccepted values: 0 to 1000 (lower values = simpler, higher values = more intricate, default is 100)\nExample: --s 1000"
  },
  {
    "objectID": "posts/007_midjourney_experiments/midjourney_experiments.html#negative-prompting",
    "href": "posts/007_midjourney_experiments/midjourney_experiments.html#negative-prompting",
    "title": "Midjourney Experiments",
    "section": "Negative prompting",
    "text": "Negative prompting\nAllows you to strongly signal something should be excluded from an image.\n\nParameter: --no value\nAccepted values: Any text.\nExample: --no plants\n\nThe full list of parameters is available here"
  },
  {
    "objectID": "posts/007_midjourney_experiments/midjourney_experiments.html#papercut",
    "href": "posts/007_midjourney_experiments/midjourney_experiments.html#papercut",
    "title": "Midjourney Experiments",
    "section": "Papercut",
    "text": "Papercut"
  },
  {
    "objectID": "posts/007_midjourney_experiments/midjourney_experiments.html#in-the-style-of",
    "href": "posts/007_midjourney_experiments/midjourney_experiments.html#in-the-style-of",
    "title": "Midjourney Experiments",
    "section": "In the style of …",
    "text": "In the style of …\n\nI’ll keep adding to the Neat Prompt Tags section."
  },
  {
    "objectID": "posts/007_midjourney_experiments/midjourney_experiments.html#footnotes",
    "href": "posts/007_midjourney_experiments/midjourney_experiments.html#footnotes",
    "title": "Midjourney Experiments",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIan Goodfellow et. al’s paper (2014) presenting the Generative Adversarial Network (or GAN) deep learning model architecture.↩︎\nGoogle’s famous Attention is all you need paper (2017) which presented the Transformer deep learning model architecture.↩︎\nOpenAI’s 2018 analysis of available computing power (or “compute”) and the amount of compute needed to train models.↩︎\nGoogle’s “Transformer: A Novel Neural Network Architecture for Language Understanding” blog post (2017) outlining how Google used Transformers to generate more accurate translations in Google Translate.↩︎\nBefore or on Feb 11, 2019, This Person Does Not Exist came online, generating a hyperrealistic but fake image of a human face.↩︎\nIn late 2020, DeepMind (a subsidiary of Alphabet) announced AlphaFold2 a reengineered version of their protein-structure prediction system, which uses transformers to predict much more accurate representations of proteins. Understanding the molecular structure of complex proteins makes it possible to determine what molecular groups are exposed on the outer surface of the molecule, which is useful as only those exposed groups can interact with groups on other molecules.↩︎\nIn late 2020, uberduck.ai introduced a text-to-speech generation service and (per Uberduck copy) over 5000 voice models that can be used to generate speech from text. In early to mid 2021, this platform gained some press when users started generating not-quite-passable tracks with different rapper voice models.↩︎\nHugging created spaces where users could host small AI applications using existing transformer models on their platform.↩︎\nassuming the use is not for commercial purposes by a company earning over $1M in gross refenue per year, which must purchase the Pro (\\$60/mo) or Mega (\\$120/mo) plan. Source↩︎\nA lawsuit↩︎"
  },
  {
    "objectID": "posts/004_census_tiger_dev/TIGER_data_collector_dev.html",
    "href": "posts/004_census_tiger_dev/TIGER_data_collector_dev.html",
    "title": "Census TIGER Dataset Collector Dev",
    "section": "",
    "text": "Code\nimport textwrap\nfrom typing import Dict, List, Union, Optional\nfrom urllib.request import urlretrieve\n\nfrom bs4 import BeautifulSoup\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport requests\n\n\nThe US Census Bureau (USCB) runs a massive array of surveys of residents of the United States. After aggregating responses into demographic and/or geographic groups, the USCB publishes those aggregated datasets to its massive public data catalog. I’ve already developed some tooling to collect and ingest Census datasets into my personal data warehouse and analytics environment, but to map out geographic Census data or join in other geospatial datasets, I also need to collect and ingest spatial files describing the geographic boundaries of Census groupings. Fortunately, the USCB provides shapefiles with these geometries in their TIGER (Topologically Integrated Geographic Encoding and Referencing) data offerings, and in this notebook, I’ll synthesize the findings the experiments and research in my last notebook into a data model and data collection tools.\n\nReferences:\n\nTIGER Technical Docs\nTIGER Geographic Codes\n\nEach year, the USCB can add or alter geographic boundaries or connected data features, so they organize TIGER data offering into annual vintages, which can be downloaded either through the USCB web interface or from their file server interface (https://www2.census.gov/geo/tiger/).\nThe functions in the cell below aid in scraping the table off of any of pages linked in that file-tree interface.\n\n\nCode\ndef request_page(metadata_url: str) -&gt; requests.models.Response:\n    resp = requests.get(metadata_url)\n    if resp.status_code == 200:\n        return resp\n    else:\n        raise Exception(f\"Couldn't get page metadata for url {metadata_url}\")\n\ndef scrape_census_ftp_metadata_page(metadata_url: str) -&gt; pd.DataFrame:\n    resp = request_page(metadata_url=metadata_url)\n    soup = BeautifulSoup(resp.content, \"html.parser\")\n    table = soup.find(\"table\")\n    rows = table.find_all(\"tr\")\n    table_contents = []\n    for row in rows:\n        cols = row.find_all(\"td\")\n        cols = [col.text.strip() for col in cols]\n        table_contents.append(cols)\n    table_rows = [el for el in table_contents if len(el) &gt; 0]\n\n    metadata_df = pd.DataFrame(\n        [row[1:] for row in table_rows],\n        columns=[\"name\", \"last_modified\", \"size\", \"description\"],\n    )\n    metadata_df[\"last_modified\"] = pd.to_datetime(metadata_df[\"last_modified\"])\n    metadata_df[\"is_dir\"] = metadata_df[\"name\"].str.endswith(\"/\")\n    metadata_df[\"clean_name\"] = metadata_df[\"name\"].str.replace(\"/$\", \"\", regex=True)\n    metadata_df[\"is_file\"] = (~metadata_df[\"is_dir\"]) & (\n        metadata_df[\"clean_name\"] != \"Parent Directory\"\n    )\n    while metadata_url.strip().endswith(\"/\"):\n        metadata_url = metadata_url[:-1]\n    mask = metadata_df[\"is_file\"] | metadata_df[\"is_dir\"]\n    metadata_df = metadata_df.loc[mask].copy()\n    metadata_df[\"metadata_url\"] = (metadata_url + \"/\" + metadata_df[\"clean_name\"])\n    return metadata_df\n\n\nrequest_page() makes a GET request for the content at the URL metadata_url and returns the response (if successful, i.e. if the response has the “success” HTTP response status code). This function is only called by scrape_census_ftp_metadata_page(), but it’s separated out to make it easier to test scrape_census_ftp_metadata_page().\n\n\nCode\ndef request_page(metadata_url: str) -&gt; requests.models.Response:\n    resp = requests.get(metadata_url)\n    if resp.status_code == 200:\n        return resp\n    else:\n        raise Exception(f\"Couldn't get page metadata for url {metadata_url}\")\n\n\nscrape_census_ftp_metadata_page() gets the content from a given Census file-tree page (at URL metadata_url), parses it into a convenient and well structured format (a pandas DataFrame) with features that aid in filtering to desired rows.\n\n\nCode\nresp = request_page(metadata_url=\"https://www2.census.gov/geo/tiger/\")\nsoup = BeautifulSoup(resp.content, \"html.parser\")\ntable = soup.find(\"table\")\nrows = table.find_all(\"tr\")\nrows[0:7]\n\n\n[&lt;tr&gt;&lt;th valign=\"top\"&gt;&lt;img alt=\"[ICO]\" src=\"/icons/blank.gif\"/&gt;&lt;/th&gt;&lt;th&gt;&lt;a href=\"?C=N;O=D\"&gt;Name&lt;/a&gt;&lt;/th&gt;&lt;th&gt;&lt;a href=\"?C=M;O=A\"&gt;Last modified&lt;/a&gt;&lt;/th&gt;&lt;th&gt;&lt;a href=\"?C=S;O=A\"&gt;Size&lt;/a&gt;&lt;/th&gt;&lt;th&gt;&lt;a href=\"?C=D;O=A\"&gt;Description&lt;/a&gt;&lt;/th&gt;&lt;/tr&gt;,\n &lt;tr&gt;&lt;th colspan=\"5\"&gt;&lt;hr/&gt;&lt;/th&gt;&lt;/tr&gt;,\n &lt;tr&gt;&lt;td valign=\"top\"&gt;&lt;img alt=\"[PARENTDIR]\" src=\"/icons/back.gif\"/&gt;&lt;/td&gt;&lt;td&gt;&lt;a href=\"/geo/\"&gt;Parent Directory&lt;/a&gt;&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;td align=\"right\"&gt;  - &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;,\n &lt;tr&gt;&lt;td valign=\"top\"&gt;&lt;img alt=\"[   ]\" src=\"/icons/layout.gif\"/&gt;&lt;/td&gt;&lt;td&gt;&lt;a href=\"Directory_Contents_ReadMe.pdf\"&gt;Directory_Contents_ReadMe.pdf&lt;/a&gt;&lt;/td&gt;&lt;td align=\"right\"&gt;2019-06-25 09:13  &lt;/td&gt;&lt;td align=\"right\"&gt;439K&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;,\n &lt;tr&gt;&lt;td valign=\"top\"&gt;&lt;img alt=\"[DIR]\" src=\"/icons/folder.gif\"/&gt;&lt;/td&gt;&lt;td&gt;&lt;a href=\"GENZ2010/\"&gt;GENZ2010/&lt;/a&gt;&lt;/td&gt;&lt;td align=\"right\"&gt;2013-07-24 12:46  &lt;/td&gt;&lt;td align=\"right\"&gt;  - &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;,\n &lt;tr&gt;&lt;td valign=\"top\"&gt;&lt;img alt=\"[DIR]\" src=\"/icons/folder.gif\"/&gt;&lt;/td&gt;&lt;td&gt;&lt;a href=\"GENZ2012/\"&gt;GENZ2012/&lt;/a&gt;&lt;/td&gt;&lt;td align=\"right\"&gt;2013-07-24 12:47  &lt;/td&gt;&lt;td align=\"right\"&gt;  - &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;,\n &lt;tr&gt;&lt;td valign=\"top\"&gt;&lt;img alt=\"[DIR]\" src=\"/icons/folder.gif\"/&gt;&lt;/td&gt;&lt;td&gt;&lt;a href=\"GENZ2013/\"&gt;GENZ2013/&lt;/a&gt;&lt;/td&gt;&lt;td align=\"right\"&gt;2014-07-02 08:28  &lt;/td&gt;&lt;td align=\"right\"&gt;  - &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;]\n\n\nThe cell above shows code that extracts HTML tr (table-row) elements extracted from the page (sorry for showing something so ugly!), and the cell below shows the (beautiful) end product of scrape_census_ftp_metadata_page().\n\n\nCode\nall_tiger_vintages_df = scrape_census_ftp_metadata_page(\n    metadata_url=\"https://www2.census.gov/geo/tiger/\"\n)\ndisplay(all_tiger_vintages_df.head(4))\n\n\n\n\n\n\n\n\n\nname\nlast_modified\nsize\ndescription\nis_dir\nclean_name\nis_file\nmetadata_url\n\n\n\n\n1\nDirectory_Contents_ReadMe.pdf\n2019-06-25 09:13:00\n439K\n\nFalse\nDirectory_Contents_ReadMe.pdf\nTrue\nhttps://www2.census.gov/geo/tiger/Directory_Co...\n\n\n2\nGENZ2010/\n2013-07-24 12:46:00\n-\n\nTrue\nGENZ2010\nFalse\nhttps://www2.census.gov/geo/tiger/GENZ2010\n\n\n3\nGENZ2012/\n2013-07-24 12:47:00\n-\n\nTrue\nGENZ2012\nFalse\nhttps://www2.census.gov/geo/tiger/GENZ2012\n\n\n4\nGENZ2013/\n2014-07-02 08:28:00\n-\n\nTrue\nGENZ2013\nFalse\nhttps://www2.census.gov/geo/tiger/GENZ2013\n\n\n\n\n\n\n\n\n\nCode\nprint(f\"Files on the top-level TIGER dataset page:                {all_tiger_vintages_df['is_file'].sum():&gt;3}\")\nprint(f\"TIGER data offerings on the top-level TIGER dataset page: {all_tiger_vintages_df['is_dir'].sum():&gt;3}\")\n\n\nFiles on the top-level TIGER dataset page:                  1\nTIGER data offerings on the top-level TIGER dataset page:  59\n\n\nThe GENZyyyy TIGER data offerings are interesting, but the real wealth of geospatial files can be found in the TIGER offerings with names matching the TIGERyyyy pattern, and I implemented the get_tiger_vintages_metadata() function to get the metadata for these offerings, or vintages.\n\n\nCode\ndef get_tiger_vintages_metadata() -&gt; pd.DataFrame:\n    all_tiger_vintages_df = scrape_census_ftp_metadata_page(\n        metadata_url=\"https://www2.census.gov/geo/tiger/\"\n    )\n    tiger_vintages_df = all_tiger_vintages_df.loc[\n        all_tiger_vintages_df[\"name\"].str.contains(\"^TIGER\\d{4}/\", regex=True)\n    ].copy()\n    tiger_vintages_df = tiger_vintages_df.sort_values(by=\"name\", ignore_index=True)\n    return tiger_vintages_df\n\ntiger_vintages_df = get_tiger_vintages_metadata()\nprint(f\"Available TIGER vintages:\")\nnames = textwrap.wrap(\", \".join(list(tiger_vintages_df[\"clean_name\"].values)), width=95)\nfor line in names:\n    print(f\"    {line}\")\ndisplay(tiger_vintages_df.head(3))\n\n\nAvailable TIGER vintages:\n    TIGER1992, TIGER1999, TIGER2002, TIGER2003, TIGER2008, TIGER2009, TIGER2010, TIGER2011,\n    TIGER2012, TIGER2013, TIGER2014, TIGER2015, TIGER2016, TIGER2017, TIGER2018, TIGER2019,\n    TIGER2020, TIGER2021, TIGER2022\n\n\n\n\n\n\n\n\n\nname\nlast_modified\nsize\ndescription\nis_dir\nclean_name\nis_file\nmetadata_url\n\n\n\n\n0\nTIGER1992/\n2011-12-19 07:56:00\n-\n\nTrue\nTIGER1992\nFalse\nhttps://www2.census.gov/geo/tiger/TIGER1992\n\n\n1\nTIGER1999/\n2012-02-13 11:19:00\n-\n\nTrue\nTIGER1999\nFalse\nhttps://www2.census.gov/geo/tiger/TIGER1999\n\n\n2\nTIGER2002/\n2015-05-05 18:37:00\n-\n\nTrue\nTIGER2002\nFalse\nhttps://www2.census.gov/geo/tiger/TIGER2002\n\n\n\n\n\n\n\nNow that we have tools for scraping the any page in the Census’s file server, we can use those tools to retrieve data on the geographic entities in a given TIGER vintage.\n\n\nCode\nclass TIGERCatalog:\n    def __init__(self):\n        self.dataset_vintages = get_tiger_vintages_metadata()\n\n    def get_vintage_metadata(self, year: str) -&gt; pd.DataFrame:\n        return self.dataset_vintages.loc[self.dataset_vintages[\"name\"] == f\"TIGER{year}/\"].copy()\n\nclass TIGERVintageCatalog:\n    def __init__(self, year: str, catalog: Optional[TIGERCatalog] = None):\n        self.year = str(year)\n        self.set_catalog(catalog=catalog)\n\n    def set_catalog(self, catalog: Optional[TIGERCatalog]) -&gt; None:\n        if catalog is None:\n            self.catalog = TIGERCatalog()\n        else:\n            self.catalog = catalog\n\n    @property\n    def vintage_metadata(self):\n        return self.catalog.get_vintage_metadata(year=self.year)\n\n    @property\n    def vintage_entities(self):\n        if len(self.vintage_metadata) == 1:\n            tiger_vintage_url = self.vintage_metadata[\"metadata_url\"].values[0]\n            return scrape_census_ftp_metadata_page(metadata_url=tiger_vintage_url)\n        else:\n            raise Exception(\n                f\"Failed to get unambiguous metadata (got {self.vintage_metadata})\"\n            )\n\n    def get_entity_metadata(self, entity_name: str) -&gt; pd.DataFrame:\n        return self.vintage_entities.loc[self.vintage_entities[\"clean_name\"] == entity_name].copy()\n\n    def print_entity_names(self):\n        entity_names = self.vintage_entities.loc[\n            self.vintage_entities[\"is_dir\"], \"clean_name\"\n        ].values\n        print(f\"TIGER Entity options for the {self.year} TIGER vintage:\")\n        for entity_name in entity_names:\n            print(f\"  - {entity_name}\")\n        print(f\"Entity count: {len(entity_names)}\")\n\n\n\n\nCode\ntiger_catalog = TIGERCatalog()\nvintage_entity_catalog = TIGERVintageCatalog(year=\"2022\", catalog=tiger_catalog)\nvintage_entity_catalog.print_entity_names()\n\n\nTIGER Entity options for the 2022 TIGER vintage:\n  - ADDR\n  - ADDRFEAT\n  - ADDRFN\n  - AIANNH\n  - AITSN\n  - ANRC\n  - AREALM\n  - AREAWATER\n  - BG\n  - CD\n  - COASTLINE\n  - CONCITY\n  - COUNTY\n  - COUSUB\n  - EDGES\n  - ELSD\n  - ESTATE\n  - FACES\n  - FACESAH\n  - FACESAL\n  - FACESMIL\n  - FEATNAMES\n  - LINEARWATER\n  - MIL\n  - PLACE\n  - POINTLM\n  - PRIMARYROADS\n  - PRISECROADS\n  - PUMA\n  - RAILS\n  - ROADS\n  - SCSD\n  - SDADM\n  - SLDL\n  - SLDU\n  - STATE\n  - SUBBARRIO\n  - TABBLOCK20\n  - TBG\n  - TRACT\n  - TTRACT\n  - UAC\n  - UNSD\n  - ZCTA520\nEntity count: 44\n\n\nLet’s examine Census Tracts.\nI’ll need some tooling to collect information on a given entity in a given TIGER vintage. I know this object will need data that’s in the relevant TIGERVintageCatalog instance, so I’ll make that an attribute of the entity vintage class. I could require that the use passes in a TIGERVintageCatalog instance (which would reduce the number of calls to the same Census resource in the usecase where a user is interactively working using these classes), but ultimately I’m going to build out pipelines that only collect one TIGER entity at a from a given vintage (as I don’t need most of the available entities listed above).\n\n\nCode\nclass TIGERGeographicEntityVintage:\n    def __init__(self, entity_name: str, year: str, catalog: Optional[TIGERCatalog] = None):\n        self.entity_name = entity_name\n        self.year = str(year)\n        self.vintage_catalog = TIGERVintageCatalog(year=year, catalog=catalog)\n        self.entity_metadata = self.vintage_catalog.get_entity_metadata(entity_name=self.entity_name)\n\n    @property\n    def entity_url(self):\n        return self.entity_metadata[\"metadata_url\"].values[0]\n\ntiger_tract22_obj = TIGERGeographicEntityVintage(entity_name=\"TRACT\", year=\"2022\", catalog=tiger_catalog)\ndisplay(tiger_tract22_obj.entity_metadata)\nentity_df = scrape_census_ftp_metadata_page(metadata_url=tiger_tract22_obj.entity_url)\nprint(entity_df.shape)\ndisplay(entity_df.head(2))\n\n\n\n\n\n\n\n\n\nname\nlast_modified\nsize\ndescription\nis_dir\nclean_name\nis_file\nmetadata_url\n\n\n\n\n41\nTRACT/\n2022-09-30 22:39:00\n-\n\nTrue\nTRACT\nFalse\nhttps://www2.census.gov/geo/tiger/TIGER2022/TRACT\n\n\n\n\n\n\n\n(56, 8)\n\n\n\n\n\n\n\n\n\nname\nlast_modified\nsize\ndescription\nis_dir\nclean_name\nis_file\nmetadata_url\n\n\n\n\n1\ntl_2022_01_tract.zip\n2022-10-31 19:42:00\n11M\n\nFalse\ntl_2022_01_tract.zip\nTrue\nhttps://www2.census.gov/geo/tiger/TIGER2022/TR...\n\n\n2\ntl_2022_02_tract.zip\n2022-10-31 19:42:00\n3.0M\n\nFalse\ntl_2022_02_tract.zip\nTrue\nhttps://www2.census.gov/geo/tiger/TIGER2022/TR...\n\n\n\n\n\n\n\nLooking at the names, I see that the Census groups tracts by state FIPS code (Federal Information Processing Series code). I know the FIPS code for Illinois is “17” (you can review the FIPS codes for other geographic entities here). I also know I don’t always want to pull data for all states, so I need to add a method that allows the user to filter the entity files. Also, I should build in the step of getting the entity files metadata.\n\n\nCode\nclass TIGERGeographicEntityVintage:\n    def __init__(self, entity_name: str, year: str, catalog: Optional[TIGERCatalog] = None):\n        self.entity_name = entity_name\n        self.year = str(year)\n        self.vintage_catalog = TIGERVintageCatalog(year=year, catalog=catalog)\n        self.entity_metadata = self.vintage_catalog.get_entity_metadata(entity_name=self.entity_name)\n\n    @property\n    def entity_url(self):\n        return self.entity_metadata[\"metadata_url\"].values[0]\n\n    @property\n    def entity_files_metadata(self):\n        return scrape_census_ftp_metadata_page(metadata_url=self.entity_url)\n\n    def get_entity_file_metadata(self, filter_str: str) -&gt; pd.DataFrame:\n        return self.entity_files_metadata.loc[self.entity_files_metadata[\"name\"].str.contains(filter_str)].copy()\n\ntiger_tract22_obj = TIGERGeographicEntityVintage(entity_name=\"TRACT\", year=\"2022\", catalog=tiger_catalog)\nil_tracts22_metadata = tiger_tract22_obj.get_entity_file_metadata(filter_str=\"_17_\")\ndisplay(il_tracts22_metadata)\nprint(f\"IL Tracts archive download Url: {il_tracts22_metadata['metadata_url'].values[0]}\")\n\n\n\n\n\n\n\n\n\nname\nlast_modified\nsize\ndescription\nis_dir\nclean_name\nis_file\nmetadata_url\n\n\n\n\n14\ntl_2022_17_tract.zip\n2022-10-31 19:43:00\n9.5M\n\nFalse\ntl_2022_17_tract.zip\nTrue\nhttps://www2.census.gov/geo/tiger/TIGER2022/TR...\n\n\n\n\n\n\n\nIL Tracts archive download Url: https://www2.census.gov/geo/tiger/TIGER2022/TRACT/tl_2022_17_tract.zip\n\n\nGeopandas provides some extremely convenient functionality for loading data. I can provide the URL to a zipped archive (of geospatial files) to geopandas’ read_file() function and it handles the network request and unzipping for me.\n\n\nCode\nil_tracts_gdf = gpd.read_file(il_tracts22_metadata[\"metadata_url\"].values[0])\n\n\n\n\nCode\nprint(il_tracts_gdf.shape)\nil_tracts_gdf.head(2)\n\n\n(3265, 13)\n\n\n\n\n\n\n\n\n\nSTATEFP\nCOUNTYFP\nTRACTCE\nGEOID\nNAME\nNAMELSAD\nMTFCC\nFUNCSTAT\nALAND\nAWATER\nINTPTLAT\nINTPTLON\ngeometry\n\n\n\n\n0\n17\n019\n010701\n17019010701\n107.01\nCensus Tract 107.01\nG5020\nS\n5266000\n30553\n+40.1150269\n-088.0329549\nPOLYGON ((-88.05240 40.11923, -88.05238 40.119...\n\n\n1\n17\n019\n005902\n17019005902\n59.02\nCensus Tract 59.02\nG5020\nS\n962402\n4892\n+40.1087344\n-088.2247204\nPOLYGON ((-88.22891 40.11271, -88.22882 40.112...\n\n\n\n\n\n\n\nAnd now I have plottable, spatially-joinable geospatial data ready to ingest into a data warehouse table or to plot out.\n\n\nCode\nfig_width = 14\n\nfig, ax = plt.subplots(figsize=(fig_width, fig_width))\nax = il_tracts_gdf.plot(facecolor=\"none\", edgecolor=\"black\", linewidth=0.015 * fig_width, ax=ax)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html",
    "href": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html",
    "title": "Data Quality Monitoring with Great Expectations",
    "section": "",
    "text": "Imports and path-definition\nfrom collections import Counter\nimport datetime as dt\nfrom pathlib import Path\nfrom urllib.request import urlretrieve\n\nimport geopandas as gpd\nimport pandas as pd\n\nPROJECT_DIR = Path(\".\").resolve()\nPROJECT_DATA_DIR = PROJECT_DIR.joinpath(\"data\")\nGreat Expectations (or GX for short) is an open-source Python-based library that brings the idea of “testing” to your data. It enables you to define expectations for properties of your datasets (like records per batch, distribution of values in a column, columns in a table, etc) and check that the data meets those expectations when the data is updated."
  },
  {
    "objectID": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html#step-0-great-expectations-setup",
    "href": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html#step-0-great-expectations-setup",
    "title": "Data Quality Monitoring with Great Expectations",
    "section": "Step 0: Great Expectations Setup",
    "text": "Step 0: Great Expectations Setup\nFirst, you’ll need to install the great_expectations. If you already have conda installed on your machine, you can easily set up a conda env just like the one used to run this notebook by: 1. copying the gx_env_environment.yml file in the same dir as this notebook file to your machine, 2. open a terminal and navigate to the dir with that new file, and 3. run command conda env create -f environment.yml\nIf you don’t have conda but would like to, check out my opinionated conda install and configuration post.\n\n\nCollecting and preprocessing sample data for this post\nPROJECT_DATA_DIR.mkdir(exist_ok=True)\n\n# First, we need to download the data to our local machine.\nurl = \"https://data.cityofchicago.org/api/geospatial/4ijn-s7e5?method=export&format=GeoJSON\"\nfull_file_path = PROJECT_DATA_DIR.joinpath(\"full_food_inspections.geojson\")\nif not full_file_path.is_file():\n    urlretrieve(url=url, filename=full_file_path)\nfood_inspection_gdf = gpd.read_file(full_file_path)\n\n# For some reason, Socrata adds on these four always-null location columns on\n#   to geospatial exports. I'm going to remove them.\nlocation_cols = [\"location_state\", \"location_zip\", \"location_address\", \"location_city\"]\n# uncomment the lines below to confirm those columns are always empty\n# print(\"Rows with a non-null value in these location_xxx columns:\")\n# display(food_inspection_gdf[location_cols].notnull().sum())\nfood_inspection_gdf = food_inspection_gdf.drop(columns=location_cols)\n\n# That column ordering is a bit chaotic, so I'll reorder them (for readability).\ncol_order = [\n    \"inspection_id\", \"inspection_date\", \"dba_name\", \"aka_name\", \"license_\", \"facility_type\",\n    \"risk\", \"inspection_type\", \"results\", \"address\", \"city\", \"state\", \"zip\", \"violations\",\n    \"longitude\", \"latitude\", \"geometry\"\n]\nfood_inspection_gdf = food_inspection_gdf[col_order].copy()\n\n# I also want to break this into batches based on the dates, so I need to cast\n#   the `inspection_date` to a datetime type.\nfood_inspection_gdf[\"inspection_date\"] = pd.to_datetime(\n    food_inspection_gdf[\"inspection_date\"]\n)\n\n# I'll also cast string and numeric features to their proper dtypes.\n# food_inspection_gdf = food_inspection_gdf.convert_dtypes()\nfood_inspection_gdf[\"inspection_id\"] = food_inspection_gdf[\"inspection_id\"].astype(\"Int64\")\nfood_inspection_gdf[\"longitude\"] = food_inspection_gdf[\"longitude\"].astype(float)\nfood_inspection_gdf[\"latitude\"] = food_inspection_gdf[\"latitude\"].astype(float)\n\n# I'll also just make all string uppercase (to reduce cardinality)\nstr_cols = list(food_inspection_gdf.head(2).select_dtypes(include=\"object\").columns)\nfood_inspection_gdf[str_cols] = food_inspection_gdf[str_cols].apply(lambda x: x.str.upper())\n\n\nIn the (folded up) cell below, we split the dataset into batches and write each batch to file in this post’s ./data directory.\n\n\nAnd here we split the dataset into batches and write each batch to file in this post’s ./data directory.\n# I want to split the data into 1-month batches, so I need to get the first day of the month\n#   for every month between the earliest inspection and the month after the latest inspection\n#   in our food inspection dataset.\nmonth_start_dates = pd.date_range(\n    start=food_inspection_gdf[\"inspection_date\"].min() + pd.DateOffset(months=-1),\n    end=food_inspection_gdf[\"inspection_date\"].max(),\n    freq=\"MS\",\n)\n\n# Here, we'll iterate through each of those month_start_dates, extract the batch of data,\n#   format a filename containing the month_start_date, and write the batch to file.\nfor month_start_date in month_start_dates:\n    batch_period = pd.to_datetime(month_start_date).strftime(\"%Y_%m\")\n    batch_data = food_inspection_gdf.loc[\n        food_inspection_gdf[\"inspection_date\"].between(\n            left=month_start_date,\n            right=month_start_date + pd.DateOffset(months=1),\n            inclusive=\"left\")\n    ].copy()\n    batch_file_path = PROJECT_DATA_DIR.joinpath(f\"food_inspection_batch_{batch_period}.parquet\")\n    if not batch_file_path.is_file():\n        batch_data.to_parquet(batch_file_path, index=False)"
  },
  {
    "objectID": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html#step-1-create-or-load-great-expectations-datacontext",
    "href": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html#step-1-create-or-load-great-expectations-datacontext",
    "title": "Data Quality Monitoring with Great Expectations",
    "section": "Step 1: Create or Load Great Expectations DataContext",
    "text": "Step 1: Create or Load Great Expectations DataContext\nA DataContext is your primary tool for configuring your project and accessing project resources or GX methods. When you first create a DataContext for your project, GX will create a directory named /great_expectations in the project_root_dir directory.\nThe code below will create a new DataContext if one doesn’t already exist in the PROJECT_DIR directory, and then load a DataContext instance from that PROJECT_DIR. Great Expectations defaults to collecting anonymized usage statistics, but you can disable that for your context by setting usage_statistics_enabled=False.\n\nimport great_expectations as gx\nfrom great_expectations.data_context import FileDataContext\n\ncontext = FileDataContext.create(project_root_dir=PROJECT_DIR, usage_statistics_enabled=False)\n\nThis tutorial uses a local FileDataContext, but GX also supports CloudDataContexts and EphemeralDataContexts.\n\n\nKinds of DataContexts\n[el for el in dir(gx.data_context) if el.endswith(\"Context\")]\n\n\n['AbstractDataContext',\n 'BaseDataContext',\n 'CloudDataContext',\n 'DataContext',\n 'EphemeralDataContext',\n 'FileDataContext']"
  },
  {
    "objectID": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html#step-2-create-or-load-a-datasource",
    "href": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html#step-2-create-or-load-a-datasource",
    "title": "Data Quality Monitoring with Great Expectations",
    "section": "Step 2: Create or load a Datasource",
    "text": "Step 2: Create or load a Datasource\nA GX Datasource connects you to a source of data and gives you methods to define and access DataAssets.\nThe code below will check the DataContext context for a Datasource with the given datasource_name, and either load or create a local filesystem Datasource instance.\n\ndatasource_name = \"food_inspection_datasource\"\n\nif any(el[\"name\"] == datasource_name for el in context.list_datasources()):\n    print(f\"Datasource with name '{datasource_name}' found; loading now\")\n    datasource = context.get_datasource(datasource_name)\nelse:\n    print(f\"No Datasource with name '{datasource_name}' found; creating now\")\n    datasource = context.sources.add_pandas_filesystem(\n        name=datasource_name,\n        base_directory=PROJECT_DATA_DIR\n    )\n\nNo Datasource with name 'food_inspection_datasource' found; creating now\n\n\n\n\nOther kinds of GX Datasources\n[el for el in dir(context.sources) if el.startswith(\"add_\") and \"_update_\" not in el]\n\n\n['add_pandas',\n 'add_pandas_abs',\n 'add_pandas_dbfs',\n 'add_pandas_filesystem',\n 'add_pandas_gcs',\n 'add_pandas_s3',\n 'add_postgres',\n 'add_spark',\n 'add_spark_abs',\n 'add_spark_dbfs',\n 'add_spark_filesystem',\n 'add_spark_gcs',\n 'add_spark_s3',\n 'add_sql',\n 'add_sqlite']"
  },
  {
    "objectID": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html#step-3-define-dataassets-in-that-datasource",
    "href": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html#step-3-define-dataassets-in-that-datasource",
    "title": "Data Quality Monitoring with Great Expectations",
    "section": "Step 3: Define DataAssets in that Datasource",
    "text": "Step 3: Define DataAssets in that Datasource\nA GX DataAsset specifies a collection of records in a Datasource and the method for accessing those records.\nThe code below checks if a DataAsset with the given name exists in the datasource, loading it if it exists, or specifying it if not. In the part that specifies the DataAsset, note that we set the name of the asset, specify that the data is in parquet files, and provide a regex pattern for the file_names and also defines variable-names for the year and month parts each file_name. We can use those year and month variables to specify how DataAssets should be split into batches and the order of those batches.\n\ndata_asset_name = \"food_inspections_asset\"\n\nif data_asset_name not in datasource.get_asset_names():\n    print(f\"Creating data asset {data_asset_name}\")\n    data_asset = datasource.add_parquet_asset(\n        name=data_asset_name,\n        batching_regex = r\"food_inspection_batch_(?P&lt;year&gt;\\d{4})_(?P&lt;month&gt;\\d{2})\\.parquet\"\n    )\nelse:\n    data_asset = datasource.get_asset(data_asset_name)\ndata_asset = data_asset.add_sorters([\"+year\", \"+month\"])\n\nCreating data asset food_inspections_asset\n\n\n\n\nOther data file formats GX supports\n[el for el in dir(datasource) if el.startswith(\"add_\")]\n\n\n['add_csv_asset',\n 'add_excel_asset',\n 'add_feather_asset',\n 'add_fwf_asset',\n 'add_hdf_asset',\n 'add_html_asset',\n 'add_json_asset',\n 'add_orc_asset',\n 'add_parquet_asset',\n 'add_pickle_asset',\n 'add_sas_asset',\n 'add_spss_asset',\n 'add_stata_asset',\n 'add_xml_asset']"
  },
  {
    "objectID": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html#step-4-create-expectations-for-a-dataasset",
    "href": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html#step-4-create-expectations-for-a-dataasset",
    "title": "Data Quality Monitoring with Great Expectations",
    "section": "Step 4: Create Expectations for a DataAsset",
    "text": "Step 4: Create Expectations for a DataAsset\nA GX Expectation is a verifiable assertion about some property of a DataAsset, and defining Expectations both enables GX to check that data meets expectations and enables domain experts to explicitly represent and communicate Expectations for data.\nGX supports hundreds of different Expectations and catalogs them in the Expectation Gallery (although not all Expectations are implemented for all kinds of Datasources). GX also provides tools to aid in several workflows for defining suites of Expectations, including the GX Data Assistant workflow (used below), which builds a suite of Expectations by profiling batches of data.\nIn the code below, we create a new Expectation suite (on lines 3-5), organize batches of data (on lines 6-7), and use the data assistant to profile the DataAsset based on our batches of data (on lines 8-11).\n\nexpectation_suite_name = \"food_inspections_suite\"\n\nexpectation_suite = context.add_or_update_expectation_suite(\n    expectation_suite_name=expectation_suite_name\n)\nbatch_request = data_asset.build_batch_request()\nbatches = data_asset.get_batch_list_from_batch_request(batch_request)\ndata_assistant_result = context.assistants.onboarding.run(\n    batch_request=batch_request,\n    exclude_column_names=[\"inspection_date\", \"geometry\"],\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe profiler will sequentially generate a lot of progress bars (like these) as it profiles dataset features.\n\n\n\nProfiler output\n\n\n\ndata_assistant_result.plot_expectations_and_metrics()\n\n64 Expectations produced, 23 Expectation and Metric plots implemented\nUse DataAssistantResult.show_expectations_by_domain_type() or\nDataAssistantResult.show_expectations_by_expectation_type() to show all produced Expectations\n\n\n\n                \n                \n\n\n\n                \n            \n\n\n\n                \n            \n\n\n\n\n\n\n\n\n\nData Assistant Plot Inspector plots\nAfter the Data Assistant finishes profiling, it outputs results to a variable we named data_assistant_result, and you can explore the results across batches by calling data_assistant_result.plot_expectations_and_metrics() and selecting the expectation and column you’re interested in.\n   \n\n\nExtracting, [optionally] Editing, and Committing our Expectation Suite to our DataContext\nIf we’re content with the Expectations generated by the Data Assistant’s profiler, we can simply extract the Expectations and add them to our context via\nexpectation_suite = data_assistant_result.get_expectation_suite(\n    expectation_suite_name=expectation_suite_name\n)\nsaved_suite = context.add_or_update_expectation_suite(expectation_suite=expectation_suite)\nIn a future post I’ll go into further depth on methods for editing Expectations, but here I’ll show how to inspect and remove Expectations.\n\nexpectation_suite = data_assistant_result.get_expectation_suite(\n    expectation_suite_name=expectation_suite_name\n)\n\n\n\nCounts of Expectations by Type\nprint(f\"Counts of Expectations by Expectation-type:\")\nexpecs_by_type = expectation_suite.get_grouped_and_ordered_expectations_by_expectation_type()\ndisplay(Counter([ex._expectation_type for ex in expecs_by_type]))\n\n\nCounts of Expectations by Expectation-type:\n\n\nCounter({'expect_column_value_lengths_to_be_between': 12,\n         'expect_column_values_to_match_regex': 11,\n         'expect_column_proportion_of_unique_values_to_be_between': 7,\n         'expect_column_unique_value_count_to_be_between': 7,\n         'expect_column_values_to_be_in_set': 7,\n         'expect_column_values_to_not_be_null': 4,\n         'expect_column_max_to_be_between': 2,\n         'expect_column_mean_to_be_between': 2,\n         'expect_column_median_to_be_between': 2,\n         'expect_column_min_to_be_between': 2,\n         'expect_column_quantile_values_to_be_between': 2,\n         'expect_column_stdev_to_be_between': 2,\n         'expect_column_values_to_be_between': 2,\n         'expect_table_columns_to_match_set': 1,\n         'expect_table_row_count_to_be_between': 1})\n\n\n\n\nCounts of Expectations by Column\nprint(f\"Counts of Expectations by Column-name:\")\nexpecs_by_col = expectation_suite.get_grouped_and_ordered_expectations_by_column()\nexpec_count_by_col = {col: len(col_expecs) for col, col_expecs in expecs_by_col[0].items()}\ndisplay(sorted(expec_count_by_col.items(), key=lambda x: x[1], reverse=True))\n\n\nCounts of Expectations by Column-name:\n\n\n[('longitude', 7),\n ('latitude', 7),\n ('inspection_type', 6),\n ('results', 6),\n ('facility_type', 5),\n ('risk', 5),\n ('city', 5),\n ('state', 5),\n ('zip', 5),\n ('dba_name', 3),\n ('_nocolumn', 2),\n ('address', 2),\n ('aka_name', 2),\n ('license_', 2),\n ('violations', 2)]\n\n\n\n\nExpectation-related methods on our expectation_suite\n[el for el in dir(expectation_suite) if \"_expectation\" in el]\n\n\n['_add_expectation',\n '_get_expectations_by_domain_using_accessor_method',\n '_validate_expectation_configuration_before_adding',\n 'add_expectation',\n 'add_expectation_configurations',\n 'append_expectation',\n 'find_expectation_indexes',\n 'find_expectations',\n 'get_column_expectations',\n 'get_column_pair_expectations',\n 'get_grouped_and_ordered_expectations_by_column',\n 'get_grouped_and_ordered_expectations_by_domain_type',\n 'get_grouped_and_ordered_expectations_by_expectation_type',\n 'get_multicolumn_expectations',\n 'get_table_expectations',\n 'patch_expectation',\n 'remove_all_expectations_of_type',\n 'remove_expectation',\n 'replace_expectation',\n 'show_expectations_by_domain_type',\n 'show_expectations_by_expectation_type']\n\n\n\n\nInspecting Expectation types for a given column\ncol_name = \"longitude\"\n[ex[\"expectation_type\"] for ex in expectation_suite.get_column_expectations() if ex[\"kwargs\"][\"column\"] == col_name]\n\n\n['expect_column_min_to_be_between',\n 'expect_column_max_to_be_between',\n 'expect_column_values_to_be_between',\n 'expect_column_quantile_values_to_be_between',\n 'expect_column_median_to_be_between',\n 'expect_column_mean_to_be_between',\n 'expect_column_stdev_to_be_between']\n\n\nSome Expectations are redundant, such as expect_column_min_to_be_between and expect_column_max_to_be_between. I’ll remove them.\n\ncol_name = \"longitude\"\nexpectation_types_to_remove = [\n    \"expect_column_min_to_be_between\", \"expect_column_max_to_be_between\"\n]\ncol_expectations_w_type = [\n    ex for ex in expectation_suite.get_column_expectations()\n    if (ex[\"kwargs\"][\"column\"] == col_name) and (ex[\"expectation_type\"] in expectation_types_to_remove)\n]\ncol_expectations_w_type\n\n[{\"kwargs\": {\"column\": \"longitude\", \"strict_min\": false, \"min_value\": -87.91442843927047, \"strict_max\": false, \"max_value\": -87.81649552747085}, \"meta\": {\"profiler_details\": {\"metric_configuration\": {\"metric_name\": \"column.min\", \"domain_kwargs\": {\"column\": \"longitude\"}, \"metric_value_kwargs\": null}, \"num_batches\": 162}}, \"expectation_type\": \"expect_column_min_to_be_between\"},\n {\"kwargs\": {\"column\": \"longitude\", \"strict_min\": false, \"min_value\": -87.5510612280602, \"strict_max\": false, \"max_value\": -87.5250941359867}, \"meta\": {\"profiler_details\": {\"metric_configuration\": {\"metric_name\": \"column.max\", \"domain_kwargs\": {\"column\": \"longitude\"}, \"metric_value_kwargs\": null}, \"num_batches\": 162}}, \"expectation_type\": \"expect_column_max_to_be_between\"}]\n\n\n\nprint(f\"Expectations prior to removal: {len(expectation_suite.expectations)}\")\nfor expectation_to_remove in col_expectations_w_type:\n    removed_expec = expectation_suite.remove_expectation(expectation_to_remove)\nprint(f\"Expectations after removal:    {len(expectation_suite.expectations)}\")\n\nExpectations prior to removal: 64\nExpectations after removal:    62\n\n\nWe can also get rid of every instance of an Expectation type.\n\nprint(f\"Removing Expectation types:\")\nfor expec_type in expectation_types_to_remove:\n    print(f\"  - {expec_type}\")\nprint(f\"Expectations prior to removal: {len(expectation_suite.expectations)}\")\nremoved_expecs = expectation_suite.remove_all_expectations_of_type(expectation_types=expectation_types_to_remove)\nprint(f\"Expectations after removal:    {len(expectation_suite.expectations)}\")\n\nRemoving Expectation types:\n  - expect_column_min_to_be_between\n  - expect_column_max_to_be_between\nExpectations prior to removal: 62\nExpectations after removal:    60\n\n\nAfter reviewing and editing Expectations, the Expectation Suite must be committed to the DataContext.\n\nsaved_suite = context.add_or_update_expectation_suite(expectation_suite=expectation_suite)"
  },
  {
    "objectID": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html#step-5-setup-a-checkpoint-to-check-expectations",
    "href": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html#step-5-setup-a-checkpoint-to-check-expectations",
    "title": "Data Quality Monitoring with Great Expectations",
    "section": "Step 5: Setup a Checkpoint to check Expectations",
    "text": "Step 5: Setup a Checkpoint to check Expectations\nA GX Checkpoint configures the validation process for an Expectation Suite.\nSpecifically, a Checkpoint defines: * the Expectation Suite to evaluate, * the data Batches to evaluate against, and * the actions to take after evaluation.\nWe’ll take the actions of compiling a report of results and committing our Checkpoint to our DataContext, but you can also configure a Checkpoint to send results via a email or Slack notification.\n\ncheckpoint_name = \"food_inspections_checkpoint\"\n\ncheckpoint = gx.checkpoint.SimpleCheckpoint(\n    name=checkpoint_name,\n    data_context=context,\n    validations=[\n        {\n            \"batch_request\": batch_request,\n            \"expectation_suite_name\": expectation_suite_name,\n        },\n    ],\n)\ncheckpoint_result = checkpoint.run()\n\n\n\n\n\ncontext.build_data_docs()\n\n{'local_site': 'file:///home/matt/projects/blogs/quarto_blog/posts/006_great_expectations_setup/great_expectations/uncommitted/data_docs/local_site/index.html'}\n\n\nTo view the generated validation report (or Data Docs), open the file .../great_expectations/uncommitted/data_docs/local_site/index.html and select the validation run you want to review. You may have to click Trust HTML (upper left corner in Jupyterlab) to navigate the document.\n \n\ncontext.add_checkpoint(checkpoint=checkpoint)\n\n{\n  \"action_list\": [\n    {\n      \"name\": \"store_validation_result\",\n      \"action\": {\n        \"class_name\": \"StoreValidationResultAction\"\n      }\n    },\n    {\n      \"name\": \"store_evaluation_params\",\n      \"action\": {\n        \"class_name\": \"StoreEvaluationParametersAction\"\n      }\n    },\n    {\n      \"name\": \"update_data_docs\",\n      \"action\": {\n        \"class_name\": \"UpdateDataDocsAction\"\n      }\n    }\n  ],\n  \"batch_request\": {},\n  \"class_name\": \"SimpleCheckpoint\",\n  \"config_version\": 1.0,\n  \"evaluation_parameters\": {},\n  \"module_name\": \"great_expectations.checkpoint\",\n  \"name\": \"food_inspections_checkpoint\",\n  \"profilers\": [],\n  \"runtime_configuration\": {},\n  \"validations\": [\n    {\n      \"batch_request\": {\n        \"datasource_name\": \"food_inspection_datasource\",\n        \"data_asset_name\": \"food_inspections_asset\",\n        \"options\": {}\n      },\n      \"expectation_suite_name\": \"food_inspections_suite\"\n    }\n  ]\n}\n\n\nYou can easily integrate a defined Checkpoint into a pipeline with just a few lines of code (and another dependency).\n\nimport great_expectations as gx\n\ncontext = gx.get_context(context_root_dir=PROJECT_DIR.joinpath(\"great_expectations\"))\nretrieved_checkpoint = context.get_checkpoint(name=\"food_inspections_checkpoint\")\nretrieved_checkpoint_result = retrieved_checkpoint.run()\nif not retrieved_checkpoint_result[\"success\"]:\n    print(f\"Failed Validation Checkpoint!\")\n    # or raise Exception(\"if you'd rather handle validation failures that way\")"
  },
  {
    "objectID": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html#next-steps",
    "href": "posts/006_great_expectations_setup/data_monitoring_w_gx_1_setup.html#next-steps",
    "title": "Data Quality Monitoring with Great Expectations",
    "section": "Next Steps",
    "text": "Next Steps\nIn future posts, I’ll dive deeper into the Expectation-setting process, demonstrate a workflow with a PostgreSQL Datasource and DataAssets (where GX really shines), and explore strategies for integrating data monitoring into production ETL/ELT pipelines (like those in my personal data warehousing platform)."
  },
  {
    "objectID": "posts/008_aerial_imagery/Aerial_Imagery_experiments.html",
    "href": "posts/008_aerial_imagery/Aerial_Imagery_experiments.html",
    "title": "Collecting High Resolution Satellite Imagery",
    "section": "",
    "text": "A few months ago, Facebook Research released a model they named the Segment Anything Model (or SAM for short) for image segmentation, either taking a textual prompt and segmenting areas related to the prompt, or autmatically segmenting every discrete contiguous body of pixels.\nIt would be pretty neat to be able to engineer features like “trees per block”, “cars per street”, etc. To attempt that, I’ll need very high resolution imagery. Fortunately, the NOAA freely provides such image data. They don’t offer an image dataset that’s limited just to Chicago. I could download all of the image tiles from their latest Illinois release, but each of these images is gigantic, so I’ll have to figure out a way to find the URLs to just the image tiles I want.\n\n\nImports, Path definitions, and defining basic functions\nfrom collections import Counter\nimport datetime as dt\nfrom pathlib import Path\nfrom typing import List, Tuple\nfrom urllib.request import urlretrieve\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom pyproj import CRS, Transformer\nimport rasterio\nfrom rasterio.plot import show\nimport requests\n\n\nPROJECT_DIR = Path(\".\").resolve()\nPROJECT_DATA_DIR = PROJECT_DIR.joinpath(\"data\")\nPROJECT_DATA_DIR.mkdir(exist_ok=True)\n\noutput_dir = PROJECT_DATA_DIR.joinpath(\"IL_NAIP_2021_9599\")\noutput_dir.mkdir(exist_ok=True)\n\ndef convert_image_bounds_to_4326(image_crs: rasterio.crs.CRS, image_bounds: rasterio.coords.BoundingBox) -&gt; Tuple:\n    transformer = Transformer.from_crs(CRS(image_crs), CRS(\"epsg:4326\"))\n    left, top = transformer.transform(image_bounds.left, image_bounds.top)\n    right, bottom = transformer.transform(image_bounds.right, image_bounds.bottom)\n    print(f\"Lat, Lon of the upper left corner:   {left, top}\")\n    print(f\"Lat, Lon of the bottom right corner: {right, bottom}\")\n    return (left, bottom, right, top)\n\n\ndef download_img_file(img_urls: List[str], output_dir: Path = output_dir) -&gt; None:\n    for img_url in img_urls:\n        file_name = img_url.split(\"/\")[-1]\n        file_path = output_dir.joinpath(file_name)\n        if not file_path.is_file():\n            print(f\"File {file_name} doesn't exist; downloading now\")\n            urlretrieve(img_url, file_path)\n        else:\n            print(f\"File {file_name} already downloaded. Skipping redownload.\")\n\n\n\n\nExamining NOAA’s data file list for the 2021-Illinois-4band-imagery dataset\nil_2021_img_urls_url = \"https://coastalimagery.blob.core.windows.net/digitalcoast/IL_NAIP_2021_9599/urllist_2021_4BandImagery_Illinois_m9599.txt\"\nresp = requests.get(il_2021_img_urls_url)\nif resp.status_code == 200:\n    il_2021_img_urls = resp.text.split(\"\\n\")\n\nprint(f'.tif file urls:  {len([x for x in il_2021_img_urls if x.endswith(\".tif\")])}')\nprint(f\"Total file urls: {len(il_2021_img_urls)}\")\nfile_extension_counts = Counter([x.split(\".\")[-1] for x in il_2021_img_urls])\nsorted_counts = sorted(file_extension_counts.items(), key=lambda ext: ext[1], reverse=True)\nprint(\"Counts of URLs by file extension (or content following a period)\")\nfor file_ext, url_count  in sorted_counts:\n    print(f\"  - File extension: {file_ext: &gt;22}, URL count: {url_count:&gt;4}\")\n\n\n.tif file urls:  4131\nTotal file urls: 8285\nCounts of URLs by file extension (or content following a period)\n  - File extension:                    xml, URL count: 4149\n  - File extension:                    tif, URL count: 4131\n  - File extension:                    vrt, URL count:    2\n  - File extension:                    zip, URL count:    1\n  - File extension:  gov/inport/item/68085, URL count:    1\n  - File extension:                       , URL count:    1\n\n\n\n\nURLs for the non .tif or .xml files\nprint(\"Non .tif or .xml URLs:\")\nnon_tif_or_xml_file_urls = [el for el in il_2021_img_urls if all(not el.endswith(ext) for ext in [\".tif\", \".xml\"])]\nfor url in non_tif_or_xml_file_urls:\n    print(f\" - '{url}'\")\n\n\nNon .tif or .xml URLs:\n - 'https://coastalimagery.blob.core.windows.net/digitalcoast/IL_NAIP_2021_9599/il_naip_2021_15.vrt'\n - 'https://coastalimagery.blob.core.windows.net/digitalcoast/IL_NAIP_2021_9599/il_naip_2021_16.vrt'\n - 'https://coastalimagery.blob.core.windows.net/digitalcoast/IL_NAIP_2021_9599/tile_index_IL_NAIP_2021_9599.zip'\n - 'https://www.fisheries.noaa.gov/inport/item/68085'\n - ''\n\n\n.vrt files are Virtual Format files used by GDAL (the Geospatial Data Abstraction Library). I haven’t looked at one before, and this full Illinois aerial imagery dataset is ~75GB, so let’s take a look and see if we can’t determine some pattern to the .tif filenaming that would enable me to avoid a massive download. And if the .vrt files aren’t useful, I guess I can explore those … 4149 .xml files for meaning.\n\n\nDownloading a few .tif image files\ndl_urls = [img_url for img_url in il_2021_img_urls if img_url.endswith(\".tif\")][0:3]\ndl_file_names = [url.split(\"/\")[-1] for url in dl_urls]\ndownload_img_file(img_urls=dl_urls)\n\n\nFile m_3608906_ne_16_060_20210622.tif already downloaded. Skipping redownload.\nFile m_3608907_ne_16_060_20210617.tif already downloaded. Skipping redownload.\nFile m_3608907_nw_16_060_20210617.tif already downloaded. Skipping redownload.\n\n\n\n\nExamining the size and names of those downloaded .tif files\n!ls -lshtr {output_dir} | head -n 6\n\n\ntotal 31G\n1.6M -rw-rw-r-- 1 matt matt 1.6M Jul  1 20:31 il_naip_2021_15.vrt\n5.1M -rw-rw-r-- 1 matt matt 5.1M Jul  1 20:31 il_naip_2021_16.vrt\n454M -rw-rw-r-- 1 matt matt 454M Jul  1 20:31 m_3608906_ne_16_060_20210622.tif\n431M -rw-rw-r-- 1 matt matt 431M Jul  1 20:31 m_3608907_ne_16_060_20210617.tif\n422M -rw-rw-r-- 1 matt matt 422M Jul  1 20:31 m_3608907_nw_16_060_20210617.tif\nls: write error: Broken pipe\n\n\nOof.mp3, ~450MB per .tif (based on looking at the first 3), and there are 4131 .tif files. I guess before I try to figure out the naming structure, I should see if the image data is adequate to resolve buildings.\n\n\n\n\nExamining assorted metadata in one of these .tif image files\nfile_path = output_dir.joinpath(dl_file_names[2])\nwith rasterio.open(file_path) as src:\n    orig_crs = src.crs\n    orig_bounds = src.bounds\n    bands = src.read()\n    print(f\"File name: {file_path.name}\")\n    print(f\"Transforms: {src.transform}\")\n    print(f\"CRS:        {orig_crs}\")\n    print(f\"Resolution: {src.res}\")\n    print(f\"units:      {src.crs.linear_units}\")\n    print(f\"bounds:     {orig_bounds}\")\n    print(f\"indexes:    {src.indexes}\")\n    print(f\"# of bands: {src.count}\")\n    print(f\"Shape of imagery array: {bands.shape}\")\n    _ = convert_image_bounds_to_4326(image_crs=orig_crs, image_bounds=orig_bounds)\n\n\nFile name: m_3608907_nw_16_060_20210617.tif\nTransforms: | 0.60, 0.00, 299327.40|\n| 0.00,-0.60, 4097538.60|\n| 0.00, 0.00, 1.00|\nCRS:        EPSG:26916\nResolution: (0.6, 0.6)\nunits:      metre\nbounds:     BoundingBox(left=299327.4, bottom=4089928.2, right=305696.4, top=4097538.6)\nindexes:    (1, 2, 3, 4)\n# of bands: 4\nShape of imagery array: (4, 12684, 10615)\nLat, Lon of the upper left corner:   (37.002598910956365, -89.25526907292884)\nLat, Lon of the bottom right corner: (36.93538410568418, -89.18177942773526)\n\n\nFrom the above printout, we see:\n\nthe rasters in this dataset use projected coordinate reference system (CRS) EPSG 26916,\nthat projected CRS uses units of meters,\none pixel represents a 0.6m x 0.6m area (i.e. the resolution is 0.6m x 0.6m), and\nthe bands variable contains four stacked image arrays that are 12684 pixels by 10615 pixels\n\nSo each image should show a ~7.5 km by ~6.5 km area and have more than enough resolution to distinguish buildings from surrounding easments and infrastructure.\n\n\nShowing the .tif image\nplt.figure(figsize=(10,10))\n_ = show(bands)\n\n\n\n\n\nThat image is pretty faded. Let’s look at the color-interpretation metadata and make prettier maps.\n\n\nExamining the color-interpretation metadata in the .tif image\nwith rasterio.open(file_path) as src:\n    print(f\"Color interpretation for bands:\\n  {src.colorinterp}\")\n\n\nColor interpretation for bands:\n  (&lt;ColorInterp.red: 3&gt;, &lt;ColorInterp.green: 4&gt;, &lt;ColorInterp.blue: 5&gt;, &lt;ColorInterp.undefined: 0&gt;)\n\n\nOk, so the 4 bands represent [red, green, blue, non-color-data]. Let’s account for that.\n\n\nDeveloping a display function with proper color-interpretation\nfile_path=file_path\nfig_width = 10\n\nfig, ax = plt.subplots(figsize=(fig_width, fig_width))\nwith rasterio.open(file_path) as src:\n    r = src.read(1)\n    g = src.read(2)\n    b = src.read(3)\n    rgb = np.stack((r, g, b))\n    show(rgb, ax=ax)\n\n\n\n\n\nWe saw above that a pixel corresponds to about 0.6m of linear distance, so we should definately be able to see buildings, but many human-scale things (like cars) may only a few pixels wide. Let’s blow up an image and really get a sense for the max resolution.\n\n\nZooming in on the north-south cluster of buildings\nfile_path=file_path\nfig_width = 10\n\nfig, ax = plt.subplots(figsize=(fig_width, fig_width))\nwith rasterio.open(file_path) as src:\n    window = rasterio.windows.Window(col_off=5000, row_off=6000, width=4000, height=4000)\n    r = src.read(1, window=window)\n    g = src.read(2, window=window)\n    b = src.read(3, window=window)\n    rgb = np.stack((r, g, b))\n    show(rgb, ax=ax)\n\n\n\n\n\n\n\nZooming in much tighter on the north-south cluster of buildings\nfile_path=file_path\nfig_width = 10\n\nfig, ax = plt.subplots(figsize=(fig_width, fig_width))\nwith rasterio.open(file_path) as src:\n    window = rasterio.windows.Window(col_off=6500, row_off=7600, width=750, height=750)\n    r = src.read(1, window=window)\n    g = src.read(2, window=window)\n    b = src.read(3, window=window)\n    rgb = np.stack((r, g, b))\n    show(rgb, ax=ax)\n\n\n\n\n\n\n\nZooming in to the extent of much tighter on the north-south cluster of buildings\nfile_path=file_path\nfig_width = 10\n\nfig, ax = plt.subplots(figsize=(fig_width, fig_width))\nwith rasterio.open(file_path) as src:\n    window = rasterio.windows.Window(col_off=6800, row_off=8000, width=300, height=300)\n    r = src.read(1, window=window)\n    g = src.read(2, window=window)\n    b = src.read(3, window=window)\n    rgb = np.stack((r, g, b))\n    show(rgb, ax=ax)\n\n\n\n\n\n\n\nCross-referencing with Google maps, we see that cars (like the red one in the shadow of the structure top-center in the above image) are barely discernable, but we can clearly make out buildings and trees.\n\n\n\nEncapsulating logic for downloading, extracting, and displaying .tifs\ndef download_tif_and_extract_bands(dl_filename: str, full_url_list: List = il_2021_img_urls, output_dir: Path = output_dir) -&gt; np.ndarray:\n    filename_subset = [el for el in full_url_list if el.endswith(dl_filename)]\n    download_img_file(output_dir=output_dir, img_urls=filename_subset)\n    file_path = output_dir.joinpath(dl_filename)\n\n    with rasterio.open(file_path) as src:\n        orig_crs = src.crs\n        orig_bounds = src.bounds\n        bands = src.read()\n        print(f\"File name:  {file_path.name}\")\n        print(f\"bounds:     {orig_bounds}\")\n        print(f\"Shape of imagery array: {bands.shape}\")\n        _ = convert_image_bounds_to_4326(image_crs=orig_crs, image_bounds=orig_bounds)\n    return bands\n\ndef plot_raster_image(file_path: Path, fig_width: int = 10) -&gt; None:\n    fig, ax = plt.subplots(figsize=(fig_width, fig_width))\n    with rasterio.open(file_path) as src:\n        r = src.read(1)\n        g = src.read(2)\n        b = src.read(3)\n        rgb = np.stack((r, g, b))\n        show(rgb, ax=ax)\n\n\nNow that we know that the data can support the research task, let’s try to find images relevant to the research goal (namely, let’s find images of Chicago). These .tif files are gigantic, so let’s explore the metadata for order we can exploit to guide us. From the counts of file-extentions above, ~99.9% of the URLs in this dataset’s manifest were either .tif or .xml files, and there were a few other URLs, two for .vrt files and one .zip file.\n\n\n\n\n\n\nExamining the first ~20 lines in one of the .vrt files\nwith open(output_dir.joinpath(\"il_naip_2021_15.vrt\")) as f:\n    vrt_lines = f.readlines()\nprint(\"\".join(vrt_lines[0:20]))\n\n\n&lt;VRTDataset rasterXSize=\"236571\" rasterYSize=\"857074\"&gt;\n  &lt;SRS&gt;PROJCS[\"NAD83 / UTM zone 15N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-93],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26915\"]]&lt;/SRS&gt;\n  &lt;GeoTransform&gt;  6.2200080000000005e+05,  6.0000000000001086e-01,  0.0000000000000000e+00,  4.7169515999999996e+06,  0.0000000000000000e+00, -6.0000000000001086e-01&lt;/GeoTransform&gt;\n  &lt;VRTRasterBand dataType=\"Byte\" band=\"1\"&gt;\n    &lt;ColorInterp&gt;Red&lt;/ColorInterp&gt;\n    &lt;SimpleSource&gt;\n      &lt;SourceFilename relativeToVRT=\"1\"&gt;m_3709008_ne_15_060_20210616.tif&lt;/SourceFilename&gt;\n      &lt;SourceBand&gt;1&lt;/SourceBand&gt;\n      &lt;SourceProperties RasterXSize=\"10445\" RasterYSize=\"12759\" DataType=\"Byte\" BlockXSize=\"10445\" BlockYSize=\"1\" /&gt;\n      &lt;SrcRect xOff=\"0\" yOff=\"0\" xSize=\"10445\" ySize=\"12759\" /&gt;\n      &lt;DstRect xOff=\"226126\" yOff=\"844315\" xSize=\"10445\" ySize=\"12759\" /&gt;\n    &lt;/SimpleSource&gt;\n    &lt;SimpleSource&gt;\n      &lt;SourceFilename relativeToVRT=\"1\"&gt;m_3809003_ne_15_060_20210704.tif&lt;/SourceFilename&gt;\n      &lt;SourceBand&gt;1&lt;/SourceBand&gt;\n      &lt;SourceProperties RasterXSize=\"10249\" RasterYSize=\"12700\" DataType=\"Byte\" BlockXSize=\"10249\" BlockYSize=\"1\" /&gt;\n      &lt;SrcRect xOff=\"0\" yOff=\"0\" xSize=\"10249\" ySize=\"12700\" /&gt;\n      &lt;DstRect xOff=\"129996\" yOff=\"661987\" xSize=\"10249\" ySize=\"12700\" /&gt;\n    &lt;/SimpleSource&gt;\n    &lt;SimpleSource&gt;\n\n\n\nThat looks like XML, which is very structured. After the opening VRTDataset tag, we see tags &lt;SRS&gt; (with CRS, projection, unit, orientation, etc metadata for the image data), &lt;GEOTRANSFORM&gt; (presumably providing the affine transformation matrix to transform from some reference), and then the start tag of a &lt;VRTRasterBand&gt; set (presumably for the band describing the red pixel mask values) of &lt;SimpleSource&gt; tags.\nLet’s try parsing those &lt;SimpleSource&gt; elements to an easier-to-search data structure, the DataFrame.\n\n\nCode to extract and structure data from these .vrt files\nimport xml.etree.ElementTree as ET\n\ndef parse_simple_sources_from_vrt_file(vrt_file_path: Path) -&gt; pd.DataFrame:\n    tree = ET.parse(vrt_file_path)\n    root = tree.getroot()\n\n    vrt_data = []\n    for source in root.iter(\"SimpleSource\"):\n        src_filename = source.find(\"SourceFilename\").text\n        src_band = source.find(\"SourceBand\").text\n        src_properties = source.find(\"SourceProperties\").attrib\n        src_rect = source.find(\"SrcRect\").attrib\n        dst_rect = source.find(\"DstRect\").attrib\n        vrt_data.append({\n            \"SourceFilename\": src_filename,\n            \"SourceBand\": int(src_band),\n            \"RasterXSize\": int(src_properties[\"RasterXSize\"]),\n            \"RasterYSize\": int(src_properties[\"RasterYSize\"]),\n            \"DataType\": src_properties[\"DataType\"],\n            \"BlockXSize\": int(src_properties[\"BlockXSize\"]),\n            \"BlockYSize\": int(src_properties[\"BlockYSize\"]),\n            \"src_x_off\": int(src_rect[\"xOff\"]),\n            \"src_y_off\": int(src_rect[\"yOff\"]),\n            \"src_x_size\": int(src_rect[\"xSize\"]),\n            \"src_y_size\": int(src_rect[\"ySize\"]),\n            \"dst_x_off\": int(dst_rect[\"xOff\"]),\n            \"dst_y_off\": int(dst_rect[\"yOff\"]),\n            \"dst_x_size\": int(dst_rect[\"xSize\"]),\n            \"dst_y_size\": int(dst_rect[\"ySize\"]),\n        })\n    return pd.DataFrame(vrt_data)\n\ndef filter_vrt_df_to_offset_spans(\n    min_x: int, max_x: int, min_y: int, max_y: int, vrt_df: pd.DataFrame,\n    keep_cols = [\"SourceFilename\", \"dst_x_off\", \"dst_y_off\"]\n) -&gt; pd.DataFrame:\n    df_subset = vrt_df.loc[\n        (\n            (vrt_df[\"dst_x_off\"] &gt;= min_x) & (vrt_df[\"dst_x_off\"] &lt;= max_x) &\n            (vrt_df[\"dst_y_off\"] &gt;= min_y) & (vrt_df[\"dst_y_off\"] &lt;= max_y)\n        ),\n        keep_cols\n    ].sort_values(by=\"dst_x_off\")\n    return df_subset\n\n\n\n\nExamining the structured data from vrt files\nvrt_15_df = parse_simple_sources_from_vrt_file(\n    vrt_file_path=output_dir.joinpath(\"il_naip_2021_15.vrt\")\n)\nprint(f\"Source files referenced in the '15' vrt file: {len(vrt_15_df)}\")\ndisplay(vrt_15_df.head(2))\n\nvrt_16_df = parse_simple_sources_from_vrt_file(\n    vrt_file_path=output_dir.joinpath(\"il_naip_2021_16.vrt\")\n)\nprint(f\"Source files referenced in the '16' vrt file: {len(vrt_16_df)}\")\ndisplay(vrt_16_df.head(2))\n\n\nSource files referenced in the '15' vrt file: 3868\nSource files referenced in the '16' vrt file: 12656\n\n\n\n\n\n\n\n\n\nSourceFilename\nSourceBand\nRasterXSize\nRasterYSize\nDataType\nBlockXSize\nBlockYSize\nsrc_x_off\nsrc_y_off\nsrc_x_size\nsrc_y_size\ndst_x_off\ndst_y_off\ndst_x_size\ndst_y_size\n\n\n\n\n0\nm_3709008_ne_15_060_20210616.tif\n1\n10445\n12759\nByte\n10445\n1\n0\n0\n10445\n12759\n226126\n844315\n10445\n12759\n\n\n1\nm_3809003_ne_15_060_20210704.tif\n1\n10249\n12700\nByte\n10249\n1\n0\n0\n10249\n12700\n129996\n661987\n10249\n12700\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSourceFilename\nSourceBand\nRasterXSize\nRasterYSize\nDataType\nBlockXSize\nBlockYSize\nsrc_x_off\nsrc_y_off\nsrc_x_size\nsrc_y_size\ndst_x_off\ndst_y_off\ndst_x_size\ndst_y_size\n\n\n\n\n0\nm_3608906_ne_16_060_20210622.tif\n1\n10475\n12686\nByte\n10475\n1\n0\n0\n10475\n12686\n96991\n1032135\n10475\n12686\n\n\n1\nm_3608907_ne_16_060_20210617.tif\n1\n10459\n12674\nByte\n10459\n1\n0\n0\n10459\n12674\n115547\n1032573\n10459\n12674\n\n\n\n\n\n\n\n\n\nVarying offsets to find images bounding the corners of Chicago\ndf_subset = filter_vrt_df_to_offset_spans(\n    min_x=0, max_x=31000, min_y=0, max_y=10000, vrt_df=vrt_16_df\n)\ndisplay(df_subset.drop_duplicates(subset=\"SourceFilename\"))\nfile_name = df_subset[\"SourceFilename\"].unique()[0]\nfile_path = output_dir.joinpath(file_name)\n_ = download_tif_and_extract_bands(dl_filename=file_name)\nplot_raster_image(file_path=file_path, fig_width=10)\n\n\n\n\n\n\n\n\n\nSourceFilename\ndst_x_off\ndst_y_off\n\n\n\n\n3026\nm_4208925_sw_16_060_20210918.tif\n29303\n0\n\n\n\n\n\n\n\nFile m_4208925_sw_16_060_20210918.tif already downloaded. Skipping redownload.\nFile name:  m_4208925_sw_16_060_20210918.tif\nbounds:     BoundingBox(left=253192.2, bottom=4709173.8, right=259211.40000000002, top=4716951.6)\nShape of imagery array: (4, 12963, 10032)\nLat, Lon of the upper left corner:   (42.56552458440836, -90.00678751628385)\nLat, Lon of the bottom right corner: (42.49747091858195, -89.93027728345706)\n\n\n\n\n\nChicago is roughly bounded by (42.05, -87.95) to (41.65, -87.55), so filtering to the minimum y-offset in the vrt_16 file gets us pretty close, but from inspection, that level of ruralness is pretty far from Chicago.\n\n\nVarying offsets to find images bounding the corners of Chicago\ndf_subset = filter_vrt_df_to_offset_spans(\n    min_x=300000, max_x=310000, min_y=110000, max_y=115000, vrt_df=vrt_16_df\n)\ndisplay(df_subset.drop_duplicates(subset=\"SourceFilename\"))\nfile_name = df_subset[\"SourceFilename\"].unique()[0]\nfile_path = output_dir.joinpath(file_name)\n_ = download_tif_and_extract_bands(dl_filename=file_name)\nplot_raster_image(file_path=file_path, fig_width=10)\n\n\n\n\n\n\n\n\n\nSourceFilename\ndst_x_off\ndst_y_off\n\n\n\n\n2226\nm_4108701_nw_16_060_20210908.tif\n301986\n110654\n\n\n\n\n\n\n\nFile m_4108701_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile name:  m_4108701_nw_16_060_20210908.tif\nbounds:     BoundingBox(left=416802.0, bottom=4643016.600000001, right=422700.0, top=4650559.2)\nShape of imagery array: (4, 12571, 9830)\nLat, Lon of the upper left corner:   (42.00265573776309, -88.00462897145327)\nLat, Lon of the bottom right corner: (41.93533185561142, -87.93242799924842)\n\n\n\n\n\nNow that we have a few (dst_x_off, dst_y_off) + (longitude, latitude) pairs, let’s do a little back-of-the-envelope math to figure out how 1 unit of dst_x_off or dst_y_off corresponds to longitude or latitude respectively.\nFrom middle school algebra, we know that (for linear relationships) slope is given by rise over run.\n\\[ m = \\frac{\\Delta y }{\\Delta x} = \\frac{y_2 - y_1}{x_2 - x_1} \\]\nHere, rise is the change in latitude, run is the change in longitude. As we have two images with two sets of latitude and longitude pairs, we can calculate the slope. And as we know the latitude and longitude of Chicago, we can use that slope and one of our known (lat, long) pairs to estimate the approximate dst_x_off and dst_y_off values for corners bounding Chicago.\ndst_x_off: 29303, dst_y_off: 0\n\nLat, Lon of the upper left corner: (42.56552458440836, -90.00678751628385)\nLat, Lon of the bottom right corner: (42.49747091858195, -89.93027728345706)\n\ndst_x_off: 301986, dst_y_off: 110654\n\nLat, Lon of the upper left corner: (42.00265573776309, -88.00462897145327)\nLat, Lon of the bottom right corner: (41.93533185561142, -87.93242799924842)\n\n\n\nBack of the envelope math to estimate offsets for Chicago’s bounding box\ndst_x_off_1 = 301986\ndst_y_off_1 = 110654\nll_tl_1 = (42.00265573776309, -88.00462897145327)\nll_lb_1 = (41.93533185561142, -87.93242799924842)\nlat_1 = (ll_tl_1[0] + ll_lb_1[0]) / 2\nlon_1 = (ll_tl_1[1] + ll_lb_1[1]) / 2\n\ndst_x_off_2 = 29303\ndst_y_off_2 = 0\nll_tl_2 = (42.56552458440836, -90.00678751628385)\nll_lb_2 = (42.49747091858195, -89.93027728345706)\nlat_2 = (ll_tl_2[0] + ll_lb_2[0]) / 2\nlon_2 = (ll_tl_2[1] + ll_lb_2[1]) / 2\n\ndelta_x_off = dst_x_off_2 - dst_x_off_1\ndelta_y_off = dst_y_off_2 - dst_y_off_1\ndelta_lat = lat_2 - lat_1\ndelta_lon = lon_2 - lon_1\n\nx_slope = delta_lon / delta_x_off\ny_slope = delta_lat / delta_y_off\n\nprint(f\"Change in longitude per 1 unit of dst_x_off: {x_slope}\")\nprint(f\"Change in latitude per 1 unit of dst_y_off:  {y_slope}\")\n\nfor x_offset in range(250000, 400000, 10000):\n    print(f\"longitude w dst_x_off {x_offset}: {lon_2 + x_slope * x_offset}\")\nprint(\"------------------------------------------------ \")\nfor y_offset in range(100000, 200000, 10000):\n    print(f\"latitude w dst_y_off {y_offset}: {lat_2 + y_slope * y_offset}\")\n\n\nChange in longitude per 1 unit of dst_x_off: 7.334538326626925e-06\nChange in latitude per 1 unit of dst_y_off:  -5.083448902054101e-06\nlongitude w dst_x_off 250000: -88.13489781821373\nlongitude w dst_x_off 260000: -88.06155243494746\nlongitude w dst_x_off 270000: -87.98820705168119\nlongitude w dst_x_off 280000: -87.91486166841491\nlongitude w dst_x_off 290000: -87.84151628514864\nlongitude w dst_x_off 300000: -87.76817090188237\nlongitude w dst_x_off 310000: -87.69482551861611\nlongitude w dst_x_off 320000: -87.62148013534984\nlongitude w dst_x_off 330000: -87.54813475208357\nlongitude w dst_x_off 340000: -87.4747893688173\nlongitude w dst_x_off 350000: -87.40144398555103\nlongitude w dst_x_off 360000: -87.32809860228477\nlongitude w dst_x_off 370000: -87.2547532190185\nlongitude w dst_x_off 380000: -87.18140783575222\nlongitude w dst_x_off 390000: -87.10806245248595\n------------------------------------------------ \nlatitude w dst_y_off 100000: 42.023152861289745\nlatitude w dst_y_off 110000: 41.9723183722692\nlatitude w dst_y_off 120000: 41.92148388324866\nlatitude w dst_y_off 130000: 41.87064939422812\nlatitude w dst_y_off 140000: 41.81981490520758\nlatitude w dst_y_off 150000: 41.768980416187034\nlatitude w dst_y_off 160000: 41.718145927166496\nlatitude w dst_y_off 170000: 41.66731143814596\nlatitude w dst_y_off 180000: 41.61647694912541\nlatitude w dst_y_off 190000: 41.565642460104876\n\n\n\n\nUsing our estimates to try to find the offsets for the northwest corner of Chicago\ndf_subset = filter_vrt_df_to_offset_spans(\n    min_x=270000, max_x=310000, min_y=110000, max_y=110400, vrt_df=vrt_16_df\n)\ndisplay(df_subset.drop_duplicates(subset=\"SourceFilename\"))\nfile_name = df_subset[\"SourceFilename\"].unique()[0]\nfile_path = output_dir.joinpath(file_name)\n_ = download_tif_and_extract_bands(dl_filename=file_name)\nplot_raster_image(file_path=file_path, fig_width=10)\n\n\n\n\n\n\n\n\n\nSourceFilename\ndst_x_off\ndst_y_off\n\n\n\n\n2373\nm_4108807_ne_16_060_20210928.tif\n276149\n110324\n\n\n\n\n\n\n\nFile m_4108807_ne_16_060_20210928.tif already downloaded. Skipping redownload.\nFile name:  m_4108807_ne_16_060_20210928.tif\nbounds:     BoundingBox(left=401299.8, bottom=4643203.8, right=407130.0, top=4650757.2)\nShape of imagery array: (4, 12589, 9717)\nLat, Lon of the upper left corner:   (42.00264796207355, -88.19181782437538)\nLat, Lon of the bottom right corner: (41.93533894952825, -88.12023834528422)\n\n\n\n\n\nOk, our calculations got us pretty close, although clearly we were a bit short in the x-direction.\nDing ding ding! That’s Montrose Beach! We’re in Chicago with {dst_x_off: 345232, dst_y_off: 111079}\n\n\nUsing our estimates to try to find the offsets for the northwest corner of Chicago\ndf_subset = filter_vrt_df_to_offset_spans(\n    min_x=340000, max_x=350000, min_y=110000, max_y=120000, vrt_df=vrt_16_df\n)\ndisplay(df_subset.drop_duplicates(subset=\"SourceFilename\"))\nfile_name = df_subset[\"SourceFilename\"].unique()[0]\nfile_path = output_dir.joinpath(file_name)\n_ = download_tif_and_extract_bands(dl_filename=file_name)\nplot_raster_image(file_path=file_path, fig_width=10)\n\n\n\n\n\n\n\n\n\nSourceFilename\ndst_x_off\ndst_y_off\n\n\n\n\n2233\nm_4108703_ne_16_060_20210908.tif\n345232\n111079\n\n\n\n\n\n\n\nFile m_4108703_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile name:  m_4108703_ne_16_060_20210908.tif\nbounds:     BoundingBox(left=442749.6, bottom=4642780.8, right=448539.6, top=4650304.2)\nShape of imagery array: (4, 12539, 9650)\nLat, Lon of the upper left corner:   (42.002673723730645, -87.69130950207042)\nLat, Lon of the bottom right corner: (41.935316313647476, -87.62074015029482)\n\n\n\n\n\nOh rats, O’Hare is split in two. Well, O’Hare marks the western-most point in Chicago, and it’s nearly the northern-most point.\n\n\nAdjusting offsets to get O’Hare International Airport, the northwest corner of Chicago\ndf_subset = filter_vrt_df_to_offset_spans(\n    min_x=310000, max_x=315000, min_y=90000, max_y=120000, vrt_df=vrt_16_df\n)\ndisplay(df_subset.drop_duplicates(subset=\"SourceFilename\"))\nfile_name1 = df_subset[\"SourceFilename\"].unique()[1]\nfile_path1 = output_dir.joinpath(file_name1)\n_ = download_tif_and_extract_bands(dl_filename=file_name1)\n\nfile_name0 = df_subset[\"SourceFilename\"].unique()[0]\nfile_path0 = output_dir.joinpath(file_name0)\n_ = download_tif_and_extract_bands(dl_filename=file_name0)\n\nplot_raster_image(file_path=file_path1, fig_width=10)\nplot_raster_image(file_path=file_path0, fig_width=10)\n\n\n\n\n\n\n\n\n\nSourceFilename\ndst_x_off\ndst_y_off\n\n\n\n\n2225\nm_4108701_ne_16_060_20210908.tif\n310691\n110752\n\n\n2887\nm_4208757_se_16_060_20210908.tif\n310816\n99094\n\n\n\n\n\n\n\nFile m_4208757_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile name:  m_4208757_se_16_060_20210908.tif\nbounds:     BoundingBox(left=422100.0, bottom=4649845.8, right=427906.2, top=4657495.2)\nShape of imagery array: (4, 12749, 9677)\nLat, Lon of the upper left corner:   (42.06565922520393, -87.9415848800517)\nLat, Lon of the bottom right corner: (41.99732626080149, -87.8704724306422)\nFile m_4108701_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile name:  m_4108701_ne_16_060_20210908.tif\nbounds:     BoundingBox(left=422025.0, bottom=4642962.0, right=427834.8, top=4650500.4)\nShape of imagery array: (4, 12564, 9683)\nLat, Lon of the upper left corner:   (42.002660830466866, -87.94156106696074)\nLat, Lon of the bottom right corner: (41.93532640993883, -87.87049010245049)\n\n\n\n\n\n\n\n\nAnd there’s Lake Calumet (that oddly-shaped body of water near the top). While not exactly the southeastern corner of Chicago, it’s very close, so we know the extents of Chicago are roughly 310000 to 360000 in dst_x_off units, and 90000 to 170000 in dst_y_off units.\n\n\nAdjusting offsets to get Lake Calumet, (very nearly) the southeast corner of Chicago\ndf_subset = filter_vrt_df_to_offset_spans(\n    min_x=350000, max_x=360000, min_y=160000, max_y=170000, vrt_df=vrt_16_df\n)\ndisplay(df_subset.drop_duplicates(subset=\"SourceFilename\"))\nfile_name = df_subset[\"SourceFilename\"].unique()[0]\nfile_path = output_dir.joinpath(file_name)\n_ = download_tif_and_extract_bands(dl_filename=file_name)\nplot_raster_image(file_path=file_path, fig_width=10)\n\n\n\n\n\n\n\n\n\nSourceFilename\ndst_x_off\ndst_y_off\n\n\n\n\n2268\nm_4108720_sw_16_060_20210908.tif\n353377\n168879\n\n\n\n\n\n\n\nFile m_4108720_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile name:  m_4108720_sw_16_060_20210908.tif\nbounds:     BoundingBox(left=447636.6, bottom=4607994.0, right=453530.39999999997, top=4615624.2)\nShape of imagery array: (4, 12717, 9823)\nLat, Lon of the upper left corner:   (41.69067319541816, -87.62923384329923)\nLat, Lon of the bottom right corner: (41.62231527376006, -87.5578195678046)\n\n\n\n\n\nAnd that’s probably the best image of downtown.\n\n\nAdjusting offsets to get downtown Chicago\ndf_subset = filter_vrt_df_to_offset_spans(\n    min_x=340000, max_x=350000, min_y=120000, max_y=130000, vrt_df=vrt_16_df\n)\ndisplay(df_subset.drop_duplicates(subset=\"SourceFilename\"))\nfile_name = df_subset[\"SourceFilename\"].unique()[0]\nfile_path = output_dir.joinpath(file_name)\n_ = download_tif_and_extract_bands(dl_filename=file_name)\nplot_raster_image(file_path=file_path, fig_width=10)\n\n\n\n\n\n\n\n\n\nSourceFilename\ndst_x_off\ndst_y_off\n\n\n\n\n2235\nm_4108703_se_16_060_20210908.tif\n345139\n122552\n\n\n\n\n\n\n\nFile m_4108703_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile name:  m_4108703_se_16_060_20210908.tif\nbounds:     BoundingBox(left=442693.8, bottom=4635786.0, right=448489.2, top=4643420.4)\nShape of imagery array: (4, 12724, 9659)\nLat, Lon of the upper left corner:   (41.940673761594084, -87.69131260636372)\nLat, Lon of the bottom right corner: (41.87231581185974, -87.62073763881713)\n\n\n\n\n\n\n\nDownloading the images in the offsets bounded by the northwest and southeast corners\nchicago_subset = filter_vrt_df_to_offset_spans(\n    min_x=310000, max_x=360000, min_y=90000, max_y=170000, vrt_df=vrt_16_df\n)\nchicago_img_urls = [\n    url for url in il_2021_img_urls if any(url.endswith(fn) for fn in chicago_subset[\"SourceFilename\"])\n]\nprint(f\"Number of images in the Chicago dst_xy_offset bounds: {len(chicago_img_urls)}\")\ndownload_img_file(img_urls=chicago_img_urls)\n\n\nNumber of images in the Chicago dst_xy_offset bounds: 40\nFile m_4108701_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108701_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108702_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108702_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108702_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108702_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108703_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108703_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108703_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108703_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108704_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108709_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108709_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108710_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108710_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108710_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108710_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108711_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108711_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108711_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108711_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108712_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108712_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108717_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108717_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108718_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108718_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108718_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108718_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108719_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108719_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108719_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108719_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108720_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108720_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4208757_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4208758_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4208758_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4208759_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4208759_sw_16_060_20210908.tif already downloaded. Skipping redownload.\n\n\n\n\n\n\n\n\nWhile not really necessary anymore, let’s take a look at the zipped file. Based on the file name, I suspect I should have gone with this one first.\n\n\nExamining the contents of the tile-index file\nfrom zipfile import ZipFile\n\nzip_file_name = non_tif_or_xml_file_urls[2].split(\"/\")[-1]\nzip_file_path = output_dir.joinpath(zip_file_name)\nwith ZipFile(zip_file_path) as zf:\n    for filename in zf.namelist():\n        print(f\"File Name: {zf.getinfo(filename)}\")\n\n\nFile Name: &lt;ZipInfo filename='tmp/tmpuejxrveu/tile_index_IL_NAIP_2021_9599.shp' filemode='-rw-rw-r--' file_size=561916&gt;\nFile Name: &lt;ZipInfo filename='tmp/tmpuejxrveu/tile_index_IL_NAIP_2021_9599.dbf' filemode='-rw-rw-r--' file_size=582569&gt;\nFile Name: &lt;ZipInfo filename='tmp/tmpuejxrveu/tile_index_IL_NAIP_2021_9599.shx' filemode='-rw-rw-r--' file_size=33148&gt;\nFile Name: &lt;ZipInfo filename='tmp/tmpuejxrveu/tile_index_IL_NAIP_2021_9599.prj' filemode='-rw-rw-r--' file_size=167&gt;\n\n\nOh, it’s a shapefile.\n\n\nLoading the tile-index shapefile file\nimport geopandas as gpd\n\ngdf = gpd.read_file(f\"zip://{zip_file_path}!tmp/tmpuejxrveu/tile_index_IL_NAIP_2021_9599.shp\")\nprint(f\"Image tiles in all of Illinois: {len(gdf)}\")\ndisplay(gdf.head(3))\n\n\nImage tiles in all of Illinois: 4131\n\n\n\n\n\n\n\n\n\nfilename\nurl\ngeometry\n\n\n\n\n0\nm_3608906_ne_16_060_20210622.tif\nhttps://coastalimagery.blob.core.windows.net/d...\nPOLYGON ((-89.24674 36.93539, -89.31525 36.935...\n\n\n1\nm_3608907_ne_16_060_20210617.tif\nhttps://coastalimagery.blob.core.windows.net/d...\nPOLYGON ((-89.12173 36.93538, -89.19025 36.935...\n\n\n2\nm_3608907_nw_16_060_20210617.tif\nhttps://coastalimagery.blob.core.windows.net/d...\nPOLYGON ((-89.18374 36.93539, -89.25325 36.935...\n\n\n\n\n\n\n\n\n\nMapping out tile boundaries and coloring Chicago tiles\nfig_width = 20\nchicago_tiles_gdf = gdf.loc[\n    (gdf.geometry.centroid.x &gt;= -88) & (gdf.geometry.centroid.x &lt;= -87.50) &\n    (gdf.geometry.centroid.y &gt;= 41.60) & (gdf.geometry.centroid.y &lt;= 42.05)\n].copy()\n\nprint(f\"Images corresponding to the Chicago blue area: {len(chicago_tiles_gdf)}\")\n\nfig, ax = plt.subplots(figsize=(fig_width, fig_width))\nax = gdf.plot(facecolor=\"none\", linewidth=fig_width*0.01, ax=ax)\nax = chicago_tiles_gdf.plot(facecolor=\"#B3DDF2\", alpha=0.6, ax=ax)\n\n\nImages corresponding to the Chicago blue area: 50\n\n\n\n\n\nOh man, that’s was much easier.\n\n\nI’m really kicking myself for not checking the zip file first; the name really hinted at the purpose. But in addition to learning the hard way that NOAA provides helpful shapefiles that map out tiles, we’ve collected the images that cover Chicago, and learned a bit about the .vrt file type.\nThat’s enough for this post, but in the near future, I’ll see if I can segment these images with a model like SAM or FastSAM. Even if these images do prove to be too much to segment in a reasonable amount of time (with my hardware; a many-cored system with a 12GB VRAM CUDA-enabled GPU and 64 GB DRAM), it’s just a matter of time until even more performant implementations emerge."
  },
  {
    "objectID": "posts/008_aerial_imagery/Aerial_Imagery_experiments.html#question-1-is-the-image-resolution-fine-enough-that-we-can-resolve-buildings",
    "href": "posts/008_aerial_imagery/Aerial_Imagery_experiments.html#question-1-is-the-image-resolution-fine-enough-that-we-can-resolve-buildings",
    "title": "Collecting High Resolution Satellite Imagery",
    "section": "",
    "text": "Examining assorted metadata in one of these .tif image files\nfile_path = output_dir.joinpath(dl_file_names[2])\nwith rasterio.open(file_path) as src:\n    orig_crs = src.crs\n    orig_bounds = src.bounds\n    bands = src.read()\n    print(f\"File name: {file_path.name}\")\n    print(f\"Transforms: {src.transform}\")\n    print(f\"CRS:        {orig_crs}\")\n    print(f\"Resolution: {src.res}\")\n    print(f\"units:      {src.crs.linear_units}\")\n    print(f\"bounds:     {orig_bounds}\")\n    print(f\"indexes:    {src.indexes}\")\n    print(f\"# of bands: {src.count}\")\n    print(f\"Shape of imagery array: {bands.shape}\")\n    _ = convert_image_bounds_to_4326(image_crs=orig_crs, image_bounds=orig_bounds)\n\n\nFile name: m_3608907_nw_16_060_20210617.tif\nTransforms: | 0.60, 0.00, 299327.40|\n| 0.00,-0.60, 4097538.60|\n| 0.00, 0.00, 1.00|\nCRS:        EPSG:26916\nResolution: (0.6, 0.6)\nunits:      metre\nbounds:     BoundingBox(left=299327.4, bottom=4089928.2, right=305696.4, top=4097538.6)\nindexes:    (1, 2, 3, 4)\n# of bands: 4\nShape of imagery array: (4, 12684, 10615)\nLat, Lon of the upper left corner:   (37.002598910956365, -89.25526907292884)\nLat, Lon of the bottom right corner: (36.93538410568418, -89.18177942773526)\n\n\nFrom the above printout, we see:\n\nthe rasters in this dataset use projected coordinate reference system (CRS) EPSG 26916,\nthat projected CRS uses units of meters,\none pixel represents a 0.6m x 0.6m area (i.e. the resolution is 0.6m x 0.6m), and\nthe bands variable contains four stacked image arrays that are 12684 pixels by 10615 pixels\n\nSo each image should show a ~7.5 km by ~6.5 km area and have more than enough resolution to distinguish buildings from surrounding easments and infrastructure.\n\n\nShowing the .tif image\nplt.figure(figsize=(10,10))\n_ = show(bands)\n\n\n\n\n\nThat image is pretty faded. Let’s look at the color-interpretation metadata and make prettier maps.\n\n\nExamining the color-interpretation metadata in the .tif image\nwith rasterio.open(file_path) as src:\n    print(f\"Color interpretation for bands:\\n  {src.colorinterp}\")\n\n\nColor interpretation for bands:\n  (&lt;ColorInterp.red: 3&gt;, &lt;ColorInterp.green: 4&gt;, &lt;ColorInterp.blue: 5&gt;, &lt;ColorInterp.undefined: 0&gt;)\n\n\nOk, so the 4 bands represent [red, green, blue, non-color-data]. Let’s account for that.\n\n\nDeveloping a display function with proper color-interpretation\nfile_path=file_path\nfig_width = 10\n\nfig, ax = plt.subplots(figsize=(fig_width, fig_width))\nwith rasterio.open(file_path) as src:\n    r = src.read(1)\n    g = src.read(2)\n    b = src.read(3)\n    rgb = np.stack((r, g, b))\n    show(rgb, ax=ax)\n\n\n\n\n\nWe saw above that a pixel corresponds to about 0.6m of linear distance, so we should definately be able to see buildings, but many human-scale things (like cars) may only a few pixels wide. Let’s blow up an image and really get a sense for the max resolution.\n\n\nZooming in on the north-south cluster of buildings\nfile_path=file_path\nfig_width = 10\n\nfig, ax = plt.subplots(figsize=(fig_width, fig_width))\nwith rasterio.open(file_path) as src:\n    window = rasterio.windows.Window(col_off=5000, row_off=6000, width=4000, height=4000)\n    r = src.read(1, window=window)\n    g = src.read(2, window=window)\n    b = src.read(3, window=window)\n    rgb = np.stack((r, g, b))\n    show(rgb, ax=ax)\n\n\n\n\n\n\n\nZooming in much tighter on the north-south cluster of buildings\nfile_path=file_path\nfig_width = 10\n\nfig, ax = plt.subplots(figsize=(fig_width, fig_width))\nwith rasterio.open(file_path) as src:\n    window = rasterio.windows.Window(col_off=6500, row_off=7600, width=750, height=750)\n    r = src.read(1, window=window)\n    g = src.read(2, window=window)\n    b = src.read(3, window=window)\n    rgb = np.stack((r, g, b))\n    show(rgb, ax=ax)\n\n\n\n\n\n\n\nZooming in to the extent of much tighter on the north-south cluster of buildings\nfile_path=file_path\nfig_width = 10\n\nfig, ax = plt.subplots(figsize=(fig_width, fig_width))\nwith rasterio.open(file_path) as src:\n    window = rasterio.windows.Window(col_off=6800, row_off=8000, width=300, height=300)\n    r = src.read(1, window=window)\n    g = src.read(2, window=window)\n    b = src.read(3, window=window)\n    rgb = np.stack((r, g, b))\n    show(rgb, ax=ax)\n\n\n\n\n\n\n\nCross-referencing with Google maps, we see that cars (like the red one in the shadow of the structure top-center in the above image) are barely discernable, but we can clearly make out buildings and trees.\n\n\n\nEncapsulating logic for downloading, extracting, and displaying .tifs\ndef download_tif_and_extract_bands(dl_filename: str, full_url_list: List = il_2021_img_urls, output_dir: Path = output_dir) -&gt; np.ndarray:\n    filename_subset = [el for el in full_url_list if el.endswith(dl_filename)]\n    download_img_file(output_dir=output_dir, img_urls=filename_subset)\n    file_path = output_dir.joinpath(dl_filename)\n\n    with rasterio.open(file_path) as src:\n        orig_crs = src.crs\n        orig_bounds = src.bounds\n        bands = src.read()\n        print(f\"File name:  {file_path.name}\")\n        print(f\"bounds:     {orig_bounds}\")\n        print(f\"Shape of imagery array: {bands.shape}\")\n        _ = convert_image_bounds_to_4326(image_crs=orig_crs, image_bounds=orig_bounds)\n    return bands\n\ndef plot_raster_image(file_path: Path, fig_width: int = 10) -&gt; None:\n    fig, ax = plt.subplots(figsize=(fig_width, fig_width))\n    with rasterio.open(file_path) as src:\n        r = src.read(1)\n        g = src.read(2)\n        b = src.read(3)\n        rgb = np.stack((r, g, b))\n        show(rgb, ax=ax)\n\n\nNow that we know that the data can support the research task, let’s try to find images relevant to the research goal (namely, let’s find images of Chicago). These .tif files are gigantic, so let’s explore the metadata for order we can exploit to guide us. From the counts of file-extentions above, ~99.9% of the URLs in this dataset’s manifest were either .tif or .xml files, and there were a few other URLs, two for .vrt files and one .zip file."
  },
  {
    "objectID": "posts/008_aerial_imagery/Aerial_Imagery_experiments.html#question-2-what-does-.vrt-file-data-look-like-and-can-i-use-it-to-determine-the-images-covering-chicago",
    "href": "posts/008_aerial_imagery/Aerial_Imagery_experiments.html#question-2-what-does-.vrt-file-data-look-like-and-can-i-use-it-to-determine-the-images-covering-chicago",
    "title": "Collecting High Resolution Satellite Imagery",
    "section": "",
    "text": "Examining the first ~20 lines in one of the .vrt files\nwith open(output_dir.joinpath(\"il_naip_2021_15.vrt\")) as f:\n    vrt_lines = f.readlines()\nprint(\"\".join(vrt_lines[0:20]))\n\n\n&lt;VRTDataset rasterXSize=\"236571\" rasterYSize=\"857074\"&gt;\n  &lt;SRS&gt;PROJCS[\"NAD83 / UTM zone 15N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-93],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26915\"]]&lt;/SRS&gt;\n  &lt;GeoTransform&gt;  6.2200080000000005e+05,  6.0000000000001086e-01,  0.0000000000000000e+00,  4.7169515999999996e+06,  0.0000000000000000e+00, -6.0000000000001086e-01&lt;/GeoTransform&gt;\n  &lt;VRTRasterBand dataType=\"Byte\" band=\"1\"&gt;\n    &lt;ColorInterp&gt;Red&lt;/ColorInterp&gt;\n    &lt;SimpleSource&gt;\n      &lt;SourceFilename relativeToVRT=\"1\"&gt;m_3709008_ne_15_060_20210616.tif&lt;/SourceFilename&gt;\n      &lt;SourceBand&gt;1&lt;/SourceBand&gt;\n      &lt;SourceProperties RasterXSize=\"10445\" RasterYSize=\"12759\" DataType=\"Byte\" BlockXSize=\"10445\" BlockYSize=\"1\" /&gt;\n      &lt;SrcRect xOff=\"0\" yOff=\"0\" xSize=\"10445\" ySize=\"12759\" /&gt;\n      &lt;DstRect xOff=\"226126\" yOff=\"844315\" xSize=\"10445\" ySize=\"12759\" /&gt;\n    &lt;/SimpleSource&gt;\n    &lt;SimpleSource&gt;\n      &lt;SourceFilename relativeToVRT=\"1\"&gt;m_3809003_ne_15_060_20210704.tif&lt;/SourceFilename&gt;\n      &lt;SourceBand&gt;1&lt;/SourceBand&gt;\n      &lt;SourceProperties RasterXSize=\"10249\" RasterYSize=\"12700\" DataType=\"Byte\" BlockXSize=\"10249\" BlockYSize=\"1\" /&gt;\n      &lt;SrcRect xOff=\"0\" yOff=\"0\" xSize=\"10249\" ySize=\"12700\" /&gt;\n      &lt;DstRect xOff=\"129996\" yOff=\"661987\" xSize=\"10249\" ySize=\"12700\" /&gt;\n    &lt;/SimpleSource&gt;\n    &lt;SimpleSource&gt;\n\n\n\nThat looks like XML, which is very structured. After the opening VRTDataset tag, we see tags &lt;SRS&gt; (with CRS, projection, unit, orientation, etc metadata for the image data), &lt;GEOTRANSFORM&gt; (presumably providing the affine transformation matrix to transform from some reference), and then the start tag of a &lt;VRTRasterBand&gt; set (presumably for the band describing the red pixel mask values) of &lt;SimpleSource&gt; tags.\nLet’s try parsing those &lt;SimpleSource&gt; elements to an easier-to-search data structure, the DataFrame.\n\n\nCode to extract and structure data from these .vrt files\nimport xml.etree.ElementTree as ET\n\ndef parse_simple_sources_from_vrt_file(vrt_file_path: Path) -&gt; pd.DataFrame:\n    tree = ET.parse(vrt_file_path)\n    root = tree.getroot()\n\n    vrt_data = []\n    for source in root.iter(\"SimpleSource\"):\n        src_filename = source.find(\"SourceFilename\").text\n        src_band = source.find(\"SourceBand\").text\n        src_properties = source.find(\"SourceProperties\").attrib\n        src_rect = source.find(\"SrcRect\").attrib\n        dst_rect = source.find(\"DstRect\").attrib\n        vrt_data.append({\n            \"SourceFilename\": src_filename,\n            \"SourceBand\": int(src_band),\n            \"RasterXSize\": int(src_properties[\"RasterXSize\"]),\n            \"RasterYSize\": int(src_properties[\"RasterYSize\"]),\n            \"DataType\": src_properties[\"DataType\"],\n            \"BlockXSize\": int(src_properties[\"BlockXSize\"]),\n            \"BlockYSize\": int(src_properties[\"BlockYSize\"]),\n            \"src_x_off\": int(src_rect[\"xOff\"]),\n            \"src_y_off\": int(src_rect[\"yOff\"]),\n            \"src_x_size\": int(src_rect[\"xSize\"]),\n            \"src_y_size\": int(src_rect[\"ySize\"]),\n            \"dst_x_off\": int(dst_rect[\"xOff\"]),\n            \"dst_y_off\": int(dst_rect[\"yOff\"]),\n            \"dst_x_size\": int(dst_rect[\"xSize\"]),\n            \"dst_y_size\": int(dst_rect[\"ySize\"]),\n        })\n    return pd.DataFrame(vrt_data)\n\ndef filter_vrt_df_to_offset_spans(\n    min_x: int, max_x: int, min_y: int, max_y: int, vrt_df: pd.DataFrame,\n    keep_cols = [\"SourceFilename\", \"dst_x_off\", \"dst_y_off\"]\n) -&gt; pd.DataFrame:\n    df_subset = vrt_df.loc[\n        (\n            (vrt_df[\"dst_x_off\"] &gt;= min_x) & (vrt_df[\"dst_x_off\"] &lt;= max_x) &\n            (vrt_df[\"dst_y_off\"] &gt;= min_y) & (vrt_df[\"dst_y_off\"] &lt;= max_y)\n        ),\n        keep_cols\n    ].sort_values(by=\"dst_x_off\")\n    return df_subset\n\n\n\n\nExamining the structured data from vrt files\nvrt_15_df = parse_simple_sources_from_vrt_file(\n    vrt_file_path=output_dir.joinpath(\"il_naip_2021_15.vrt\")\n)\nprint(f\"Source files referenced in the '15' vrt file: {len(vrt_15_df)}\")\ndisplay(vrt_15_df.head(2))\n\nvrt_16_df = parse_simple_sources_from_vrt_file(\n    vrt_file_path=output_dir.joinpath(\"il_naip_2021_16.vrt\")\n)\nprint(f\"Source files referenced in the '16' vrt file: {len(vrt_16_df)}\")\ndisplay(vrt_16_df.head(2))\n\n\nSource files referenced in the '15' vrt file: 3868\nSource files referenced in the '16' vrt file: 12656\n\n\n\n\n\n\n\n\n\nSourceFilename\nSourceBand\nRasterXSize\nRasterYSize\nDataType\nBlockXSize\nBlockYSize\nsrc_x_off\nsrc_y_off\nsrc_x_size\nsrc_y_size\ndst_x_off\ndst_y_off\ndst_x_size\ndst_y_size\n\n\n\n\n0\nm_3709008_ne_15_060_20210616.tif\n1\n10445\n12759\nByte\n10445\n1\n0\n0\n10445\n12759\n226126\n844315\n10445\n12759\n\n\n1\nm_3809003_ne_15_060_20210704.tif\n1\n10249\n12700\nByte\n10249\n1\n0\n0\n10249\n12700\n129996\n661987\n10249\n12700\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSourceFilename\nSourceBand\nRasterXSize\nRasterYSize\nDataType\nBlockXSize\nBlockYSize\nsrc_x_off\nsrc_y_off\nsrc_x_size\nsrc_y_size\ndst_x_off\ndst_y_off\ndst_x_size\ndst_y_size\n\n\n\n\n0\nm_3608906_ne_16_060_20210622.tif\n1\n10475\n12686\nByte\n10475\n1\n0\n0\n10475\n12686\n96991\n1032135\n10475\n12686\n\n\n1\nm_3608907_ne_16_060_20210617.tif\n1\n10459\n12674\nByte\n10459\n1\n0\n0\n10459\n12674\n115547\n1032573\n10459\n12674\n\n\n\n\n\n\n\n\n\nVarying offsets to find images bounding the corners of Chicago\ndf_subset = filter_vrt_df_to_offset_spans(\n    min_x=0, max_x=31000, min_y=0, max_y=10000, vrt_df=vrt_16_df\n)\ndisplay(df_subset.drop_duplicates(subset=\"SourceFilename\"))\nfile_name = df_subset[\"SourceFilename\"].unique()[0]\nfile_path = output_dir.joinpath(file_name)\n_ = download_tif_and_extract_bands(dl_filename=file_name)\nplot_raster_image(file_path=file_path, fig_width=10)\n\n\n\n\n\n\n\n\n\nSourceFilename\ndst_x_off\ndst_y_off\n\n\n\n\n3026\nm_4208925_sw_16_060_20210918.tif\n29303\n0\n\n\n\n\n\n\n\nFile m_4208925_sw_16_060_20210918.tif already downloaded. Skipping redownload.\nFile name:  m_4208925_sw_16_060_20210918.tif\nbounds:     BoundingBox(left=253192.2, bottom=4709173.8, right=259211.40000000002, top=4716951.6)\nShape of imagery array: (4, 12963, 10032)\nLat, Lon of the upper left corner:   (42.56552458440836, -90.00678751628385)\nLat, Lon of the bottom right corner: (42.49747091858195, -89.93027728345706)\n\n\n\n\n\nChicago is roughly bounded by (42.05, -87.95) to (41.65, -87.55), so filtering to the minimum y-offset in the vrt_16 file gets us pretty close, but from inspection, that level of ruralness is pretty far from Chicago.\n\n\nVarying offsets to find images bounding the corners of Chicago\ndf_subset = filter_vrt_df_to_offset_spans(\n    min_x=300000, max_x=310000, min_y=110000, max_y=115000, vrt_df=vrt_16_df\n)\ndisplay(df_subset.drop_duplicates(subset=\"SourceFilename\"))\nfile_name = df_subset[\"SourceFilename\"].unique()[0]\nfile_path = output_dir.joinpath(file_name)\n_ = download_tif_and_extract_bands(dl_filename=file_name)\nplot_raster_image(file_path=file_path, fig_width=10)\n\n\n\n\n\n\n\n\n\nSourceFilename\ndst_x_off\ndst_y_off\n\n\n\n\n2226\nm_4108701_nw_16_060_20210908.tif\n301986\n110654\n\n\n\n\n\n\n\nFile m_4108701_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile name:  m_4108701_nw_16_060_20210908.tif\nbounds:     BoundingBox(left=416802.0, bottom=4643016.600000001, right=422700.0, top=4650559.2)\nShape of imagery array: (4, 12571, 9830)\nLat, Lon of the upper left corner:   (42.00265573776309, -88.00462897145327)\nLat, Lon of the bottom right corner: (41.93533185561142, -87.93242799924842)\n\n\n\n\n\nNow that we have a few (dst_x_off, dst_y_off) + (longitude, latitude) pairs, let’s do a little back-of-the-envelope math to figure out how 1 unit of dst_x_off or dst_y_off corresponds to longitude or latitude respectively.\nFrom middle school algebra, we know that (for linear relationships) slope is given by rise over run.\n\\[ m = \\frac{\\Delta y }{\\Delta x} = \\frac{y_2 - y_1}{x_2 - x_1} \\]\nHere, rise is the change in latitude, run is the change in longitude. As we have two images with two sets of latitude and longitude pairs, we can calculate the slope. And as we know the latitude and longitude of Chicago, we can use that slope and one of our known (lat, long) pairs to estimate the approximate dst_x_off and dst_y_off values for corners bounding Chicago.\ndst_x_off: 29303, dst_y_off: 0\n\nLat, Lon of the upper left corner: (42.56552458440836, -90.00678751628385)\nLat, Lon of the bottom right corner: (42.49747091858195, -89.93027728345706)\n\ndst_x_off: 301986, dst_y_off: 110654\n\nLat, Lon of the upper left corner: (42.00265573776309, -88.00462897145327)\nLat, Lon of the bottom right corner: (41.93533185561142, -87.93242799924842)\n\n\n\nBack of the envelope math to estimate offsets for Chicago’s bounding box\ndst_x_off_1 = 301986\ndst_y_off_1 = 110654\nll_tl_1 = (42.00265573776309, -88.00462897145327)\nll_lb_1 = (41.93533185561142, -87.93242799924842)\nlat_1 = (ll_tl_1[0] + ll_lb_1[0]) / 2\nlon_1 = (ll_tl_1[1] + ll_lb_1[1]) / 2\n\ndst_x_off_2 = 29303\ndst_y_off_2 = 0\nll_tl_2 = (42.56552458440836, -90.00678751628385)\nll_lb_2 = (42.49747091858195, -89.93027728345706)\nlat_2 = (ll_tl_2[0] + ll_lb_2[0]) / 2\nlon_2 = (ll_tl_2[1] + ll_lb_2[1]) / 2\n\ndelta_x_off = dst_x_off_2 - dst_x_off_1\ndelta_y_off = dst_y_off_2 - dst_y_off_1\ndelta_lat = lat_2 - lat_1\ndelta_lon = lon_2 - lon_1\n\nx_slope = delta_lon / delta_x_off\ny_slope = delta_lat / delta_y_off\n\nprint(f\"Change in longitude per 1 unit of dst_x_off: {x_slope}\")\nprint(f\"Change in latitude per 1 unit of dst_y_off:  {y_slope}\")\n\nfor x_offset in range(250000, 400000, 10000):\n    print(f\"longitude w dst_x_off {x_offset}: {lon_2 + x_slope * x_offset}\")\nprint(\"------------------------------------------------ \")\nfor y_offset in range(100000, 200000, 10000):\n    print(f\"latitude w dst_y_off {y_offset}: {lat_2 + y_slope * y_offset}\")\n\n\nChange in longitude per 1 unit of dst_x_off: 7.334538326626925e-06\nChange in latitude per 1 unit of dst_y_off:  -5.083448902054101e-06\nlongitude w dst_x_off 250000: -88.13489781821373\nlongitude w dst_x_off 260000: -88.06155243494746\nlongitude w dst_x_off 270000: -87.98820705168119\nlongitude w dst_x_off 280000: -87.91486166841491\nlongitude w dst_x_off 290000: -87.84151628514864\nlongitude w dst_x_off 300000: -87.76817090188237\nlongitude w dst_x_off 310000: -87.69482551861611\nlongitude w dst_x_off 320000: -87.62148013534984\nlongitude w dst_x_off 330000: -87.54813475208357\nlongitude w dst_x_off 340000: -87.4747893688173\nlongitude w dst_x_off 350000: -87.40144398555103\nlongitude w dst_x_off 360000: -87.32809860228477\nlongitude w dst_x_off 370000: -87.2547532190185\nlongitude w dst_x_off 380000: -87.18140783575222\nlongitude w dst_x_off 390000: -87.10806245248595\n------------------------------------------------ \nlatitude w dst_y_off 100000: 42.023152861289745\nlatitude w dst_y_off 110000: 41.9723183722692\nlatitude w dst_y_off 120000: 41.92148388324866\nlatitude w dst_y_off 130000: 41.87064939422812\nlatitude w dst_y_off 140000: 41.81981490520758\nlatitude w dst_y_off 150000: 41.768980416187034\nlatitude w dst_y_off 160000: 41.718145927166496\nlatitude w dst_y_off 170000: 41.66731143814596\nlatitude w dst_y_off 180000: 41.61647694912541\nlatitude w dst_y_off 190000: 41.565642460104876\n\n\n\n\nUsing our estimates to try to find the offsets for the northwest corner of Chicago\ndf_subset = filter_vrt_df_to_offset_spans(\n    min_x=270000, max_x=310000, min_y=110000, max_y=110400, vrt_df=vrt_16_df\n)\ndisplay(df_subset.drop_duplicates(subset=\"SourceFilename\"))\nfile_name = df_subset[\"SourceFilename\"].unique()[0]\nfile_path = output_dir.joinpath(file_name)\n_ = download_tif_and_extract_bands(dl_filename=file_name)\nplot_raster_image(file_path=file_path, fig_width=10)\n\n\n\n\n\n\n\n\n\nSourceFilename\ndst_x_off\ndst_y_off\n\n\n\n\n2373\nm_4108807_ne_16_060_20210928.tif\n276149\n110324\n\n\n\n\n\n\n\nFile m_4108807_ne_16_060_20210928.tif already downloaded. Skipping redownload.\nFile name:  m_4108807_ne_16_060_20210928.tif\nbounds:     BoundingBox(left=401299.8, bottom=4643203.8, right=407130.0, top=4650757.2)\nShape of imagery array: (4, 12589, 9717)\nLat, Lon of the upper left corner:   (42.00264796207355, -88.19181782437538)\nLat, Lon of the bottom right corner: (41.93533894952825, -88.12023834528422)\n\n\n\n\n\nOk, our calculations got us pretty close, although clearly we were a bit short in the x-direction.\nDing ding ding! That’s Montrose Beach! We’re in Chicago with {dst_x_off: 345232, dst_y_off: 111079}\n\n\nUsing our estimates to try to find the offsets for the northwest corner of Chicago\ndf_subset = filter_vrt_df_to_offset_spans(\n    min_x=340000, max_x=350000, min_y=110000, max_y=120000, vrt_df=vrt_16_df\n)\ndisplay(df_subset.drop_duplicates(subset=\"SourceFilename\"))\nfile_name = df_subset[\"SourceFilename\"].unique()[0]\nfile_path = output_dir.joinpath(file_name)\n_ = download_tif_and_extract_bands(dl_filename=file_name)\nplot_raster_image(file_path=file_path, fig_width=10)\n\n\n\n\n\n\n\n\n\nSourceFilename\ndst_x_off\ndst_y_off\n\n\n\n\n2233\nm_4108703_ne_16_060_20210908.tif\n345232\n111079\n\n\n\n\n\n\n\nFile m_4108703_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile name:  m_4108703_ne_16_060_20210908.tif\nbounds:     BoundingBox(left=442749.6, bottom=4642780.8, right=448539.6, top=4650304.2)\nShape of imagery array: (4, 12539, 9650)\nLat, Lon of the upper left corner:   (42.002673723730645, -87.69130950207042)\nLat, Lon of the bottom right corner: (41.935316313647476, -87.62074015029482)\n\n\n\n\n\nOh rats, O’Hare is split in two. Well, O’Hare marks the western-most point in Chicago, and it’s nearly the northern-most point.\n\n\nAdjusting offsets to get O’Hare International Airport, the northwest corner of Chicago\ndf_subset = filter_vrt_df_to_offset_spans(\n    min_x=310000, max_x=315000, min_y=90000, max_y=120000, vrt_df=vrt_16_df\n)\ndisplay(df_subset.drop_duplicates(subset=\"SourceFilename\"))\nfile_name1 = df_subset[\"SourceFilename\"].unique()[1]\nfile_path1 = output_dir.joinpath(file_name1)\n_ = download_tif_and_extract_bands(dl_filename=file_name1)\n\nfile_name0 = df_subset[\"SourceFilename\"].unique()[0]\nfile_path0 = output_dir.joinpath(file_name0)\n_ = download_tif_and_extract_bands(dl_filename=file_name0)\n\nplot_raster_image(file_path=file_path1, fig_width=10)\nplot_raster_image(file_path=file_path0, fig_width=10)\n\n\n\n\n\n\n\n\n\nSourceFilename\ndst_x_off\ndst_y_off\n\n\n\n\n2225\nm_4108701_ne_16_060_20210908.tif\n310691\n110752\n\n\n2887\nm_4208757_se_16_060_20210908.tif\n310816\n99094\n\n\n\n\n\n\n\nFile m_4208757_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile name:  m_4208757_se_16_060_20210908.tif\nbounds:     BoundingBox(left=422100.0, bottom=4649845.8, right=427906.2, top=4657495.2)\nShape of imagery array: (4, 12749, 9677)\nLat, Lon of the upper left corner:   (42.06565922520393, -87.9415848800517)\nLat, Lon of the bottom right corner: (41.99732626080149, -87.8704724306422)\nFile m_4108701_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile name:  m_4108701_ne_16_060_20210908.tif\nbounds:     BoundingBox(left=422025.0, bottom=4642962.0, right=427834.8, top=4650500.4)\nShape of imagery array: (4, 12564, 9683)\nLat, Lon of the upper left corner:   (42.002660830466866, -87.94156106696074)\nLat, Lon of the bottom right corner: (41.93532640993883, -87.87049010245049)\n\n\n\n\n\n\n\n\nAnd there’s Lake Calumet (that oddly-shaped body of water near the top). While not exactly the southeastern corner of Chicago, it’s very close, so we know the extents of Chicago are roughly 310000 to 360000 in dst_x_off units, and 90000 to 170000 in dst_y_off units.\n\n\nAdjusting offsets to get Lake Calumet, (very nearly) the southeast corner of Chicago\ndf_subset = filter_vrt_df_to_offset_spans(\n    min_x=350000, max_x=360000, min_y=160000, max_y=170000, vrt_df=vrt_16_df\n)\ndisplay(df_subset.drop_duplicates(subset=\"SourceFilename\"))\nfile_name = df_subset[\"SourceFilename\"].unique()[0]\nfile_path = output_dir.joinpath(file_name)\n_ = download_tif_and_extract_bands(dl_filename=file_name)\nplot_raster_image(file_path=file_path, fig_width=10)\n\n\n\n\n\n\n\n\n\nSourceFilename\ndst_x_off\ndst_y_off\n\n\n\n\n2268\nm_4108720_sw_16_060_20210908.tif\n353377\n168879\n\n\n\n\n\n\n\nFile m_4108720_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile name:  m_4108720_sw_16_060_20210908.tif\nbounds:     BoundingBox(left=447636.6, bottom=4607994.0, right=453530.39999999997, top=4615624.2)\nShape of imagery array: (4, 12717, 9823)\nLat, Lon of the upper left corner:   (41.69067319541816, -87.62923384329923)\nLat, Lon of the bottom right corner: (41.62231527376006, -87.5578195678046)\n\n\n\n\n\nAnd that’s probably the best image of downtown.\n\n\nAdjusting offsets to get downtown Chicago\ndf_subset = filter_vrt_df_to_offset_spans(\n    min_x=340000, max_x=350000, min_y=120000, max_y=130000, vrt_df=vrt_16_df\n)\ndisplay(df_subset.drop_duplicates(subset=\"SourceFilename\"))\nfile_name = df_subset[\"SourceFilename\"].unique()[0]\nfile_path = output_dir.joinpath(file_name)\n_ = download_tif_and_extract_bands(dl_filename=file_name)\nplot_raster_image(file_path=file_path, fig_width=10)\n\n\n\n\n\n\n\n\n\nSourceFilename\ndst_x_off\ndst_y_off\n\n\n\n\n2235\nm_4108703_se_16_060_20210908.tif\n345139\n122552\n\n\n\n\n\n\n\nFile m_4108703_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile name:  m_4108703_se_16_060_20210908.tif\nbounds:     BoundingBox(left=442693.8, bottom=4635786.0, right=448489.2, top=4643420.4)\nShape of imagery array: (4, 12724, 9659)\nLat, Lon of the upper left corner:   (41.940673761594084, -87.69131260636372)\nLat, Lon of the bottom right corner: (41.87231581185974, -87.62073763881713)\n\n\n\n\n\n\n\nDownloading the images in the offsets bounded by the northwest and southeast corners\nchicago_subset = filter_vrt_df_to_offset_spans(\n    min_x=310000, max_x=360000, min_y=90000, max_y=170000, vrt_df=vrt_16_df\n)\nchicago_img_urls = [\n    url for url in il_2021_img_urls if any(url.endswith(fn) for fn in chicago_subset[\"SourceFilename\"])\n]\nprint(f\"Number of images in the Chicago dst_xy_offset bounds: {len(chicago_img_urls)}\")\ndownload_img_file(img_urls=chicago_img_urls)\n\n\nNumber of images in the Chicago dst_xy_offset bounds: 40\nFile m_4108701_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108701_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108702_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108702_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108702_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108702_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108703_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108703_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108703_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108703_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108704_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108709_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108709_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108710_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108710_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108710_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108710_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108711_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108711_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108711_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108711_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108712_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108712_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108717_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108717_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108718_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108718_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108718_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108718_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108719_ne_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108719_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108719_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108719_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108720_nw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4108720_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4208757_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4208758_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4208758_sw_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4208759_se_16_060_20210908.tif already downloaded. Skipping redownload.\nFile m_4208759_sw_16_060_20210908.tif already downloaded. Skipping redownload."
  },
  {
    "objectID": "posts/008_aerial_imagery/Aerial_Imagery_experiments.html#question-3-what-is-in-the-zipped-tile-index-file-and-can-i-use-it-to-determine-the-images-covering-chicago",
    "href": "posts/008_aerial_imagery/Aerial_Imagery_experiments.html#question-3-what-is-in-the-zipped-tile-index-file-and-can-i-use-it-to-determine-the-images-covering-chicago",
    "title": "Collecting High Resolution Satellite Imagery",
    "section": "",
    "text": "While not really necessary anymore, let’s take a look at the zipped file. Based on the file name, I suspect I should have gone with this one first.\n\n\nExamining the contents of the tile-index file\nfrom zipfile import ZipFile\n\nzip_file_name = non_tif_or_xml_file_urls[2].split(\"/\")[-1]\nzip_file_path = output_dir.joinpath(zip_file_name)\nwith ZipFile(zip_file_path) as zf:\n    for filename in zf.namelist():\n        print(f\"File Name: {zf.getinfo(filename)}\")\n\n\nFile Name: &lt;ZipInfo filename='tmp/tmpuejxrveu/tile_index_IL_NAIP_2021_9599.shp' filemode='-rw-rw-r--' file_size=561916&gt;\nFile Name: &lt;ZipInfo filename='tmp/tmpuejxrveu/tile_index_IL_NAIP_2021_9599.dbf' filemode='-rw-rw-r--' file_size=582569&gt;\nFile Name: &lt;ZipInfo filename='tmp/tmpuejxrveu/tile_index_IL_NAIP_2021_9599.shx' filemode='-rw-rw-r--' file_size=33148&gt;\nFile Name: &lt;ZipInfo filename='tmp/tmpuejxrveu/tile_index_IL_NAIP_2021_9599.prj' filemode='-rw-rw-r--' file_size=167&gt;\n\n\nOh, it’s a shapefile.\n\n\nLoading the tile-index shapefile file\nimport geopandas as gpd\n\ngdf = gpd.read_file(f\"zip://{zip_file_path}!tmp/tmpuejxrveu/tile_index_IL_NAIP_2021_9599.shp\")\nprint(f\"Image tiles in all of Illinois: {len(gdf)}\")\ndisplay(gdf.head(3))\n\n\nImage tiles in all of Illinois: 4131\n\n\n\n\n\n\n\n\n\nfilename\nurl\ngeometry\n\n\n\n\n0\nm_3608906_ne_16_060_20210622.tif\nhttps://coastalimagery.blob.core.windows.net/d...\nPOLYGON ((-89.24674 36.93539, -89.31525 36.935...\n\n\n1\nm_3608907_ne_16_060_20210617.tif\nhttps://coastalimagery.blob.core.windows.net/d...\nPOLYGON ((-89.12173 36.93538, -89.19025 36.935...\n\n\n2\nm_3608907_nw_16_060_20210617.tif\nhttps://coastalimagery.blob.core.windows.net/d...\nPOLYGON ((-89.18374 36.93539, -89.25325 36.935...\n\n\n\n\n\n\n\n\n\nMapping out tile boundaries and coloring Chicago tiles\nfig_width = 20\nchicago_tiles_gdf = gdf.loc[\n    (gdf.geometry.centroid.x &gt;= -88) & (gdf.geometry.centroid.x &lt;= -87.50) &\n    (gdf.geometry.centroid.y &gt;= 41.60) & (gdf.geometry.centroid.y &lt;= 42.05)\n].copy()\n\nprint(f\"Images corresponding to the Chicago blue area: {len(chicago_tiles_gdf)}\")\n\nfig, ax = plt.subplots(figsize=(fig_width, fig_width))\nax = gdf.plot(facecolor=\"none\", linewidth=fig_width*0.01, ax=ax)\nax = chicago_tiles_gdf.plot(facecolor=\"#B3DDF2\", alpha=0.6, ax=ax)\n\n\nImages corresponding to the Chicago blue area: 50\n\n\n\n\n\nOh man, that’s was much easier.\n\n\nI’m really kicking myself for not checking the zip file first; the name really hinted at the purpose. But in addition to learning the hard way that NOAA provides helpful shapefiles that map out tiles, we’ve collected the images that cover Chicago, and learned a bit about the .vrt file type.\nThat’s enough for this post, but in the near future, I’ll see if I can segment these images with a model like SAM or FastSAM. Even if these images do prove to be too much to segment in a reasonable amount of time (with my hardware; a many-cored system with a 12GB VRAM CUDA-enabled GPU and 64 GB DRAM), it’s just a matter of time until even more performant implementations emerge."
  },
  {
    "objectID": "posts/000_setting_up_miniconda/Setting_up_Miniconda.html",
    "href": "posts/000_setting_up_miniconda/Setting_up_Miniconda.html",
    "title": "Setting up Conda",
    "section": "",
    "text": "conda is a language-agnostic package manager and environment management system. conda’s environment management functionality makes it possible for a user to easily switch between environments (where an environment consists of the hardware and software used to execute code) and makes it possible to export a specification of that environment that can be used to reproduce that environment on another system.\nIn this post, I’ll show my opinionated conda installation and configuration process.\n\n\nconda is primarily installable via two distributions; the Anaconda distribution, which includes the conda executable along with over 700 additional conda packages from the Anaconda repository, and the Miniconda distribution, which consists of the conda executable with the minimal number of packages needed for conda to run. Install a miniconda distribution."
  },
  {
    "objectID": "posts/000_setting_up_miniconda/Setting_up_Miniconda.html#conda-installation",
    "href": "posts/000_setting_up_miniconda/Setting_up_Miniconda.html#conda-installation",
    "title": "Setting up Conda",
    "section": "",
    "text": "conda is primarily installable via two distributions; the Anaconda distribution, which includes the conda executable along with over 700 additional conda packages from the Anaconda repository, and the Miniconda distribution, which consists of the conda executable with the minimal number of packages needed for conda to run. Install a miniconda distribution."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Experiments, how-tos, and gifts to my future self",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nCollecting High Resolution Satellite Imagery\n\n\n\n\n\n\n\nrasterio\n\n\nGIS\n\n\ndata collection\n\n\n\n\nPreparing for image segmentation experiments\n\n\n\n\n\n\nJul 23, 2023\n\n\nMatt Triano\n\n\n\n\n\n\n  \n\n\n\n\nHow to Manually Reproduce a Conda Env\n\n\n\n\n\n\n\nconda\n\n\ntutorial\n\n\nhowto\n\n\n\n\nHow to reverse engineer an old env and rerun old work\n\n\n\n\n\n\nJul 13, 2023\n\n\nMatt Triano\n\n\n\n\n\n\n  \n\n\n\n\nMidjourney Experiments\n\n\n\n\n\n\n\ngenerative AI\n\n\nmidjourney\n\n\nprompt eng\n\n\n\n\nHow to get started playing with Midjourney\n\n\n\n\n\n\nJul 1, 2023\n\n\nMatt Triano\n\n\n\n\n\n\n  \n\n\n\n\nData Quality Monitoring with Great Expectations\n\n\n\n\n\n\n\ngreat_expectations\n\n\ntutorial\n\n\nlong\n\n\n\n\nA full tutorial of a basic workflow\n\n\n\n\n\n\nJun 23, 2023\n\n\nMatt Triano\n\n\n\n\n\n\n  \n\n\n\n\nCensus TIGER Dataset Collector Dev\n\n\n\n\n\nDocumenting the synthesis stage of development\n\n\n\n\n\n\nJun 14, 2023\n\n\nMatt Triano\n\n\n\n\n\n\n  \n\n\n\n\nWorking with Notebooks\n\n\n\n\n\nHow to develop a post in a notebook\n\n\n\n\n\n\nJun 12, 2023\n\n\nMatt Triano\n\n\n\n\n\n\n  \n\n\n\n\nSetting up Conda\n\n\n\n\n\n\n\nconda\n\n\nsetup\n\n\ntutorial\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2022\n\n\nMatt Triano\n\n\n\n\n\n\n  \n\n\n\n\nExploration in Criminal Justice and Corrections Data, Part 3\n\n\n\n\n\n\n\npandas\n\n\nanalysis\n\n\nold\n\n\n\n\nExploring prisoner data up through 2016\n\n\n\n\n\n\nJun 28, 2018\n\n\nMatt Triano\n\n\n\n\n\n\n  \n\n\n\n\nExploration in Criminal Justice and Corrections Data, Part 2\n\n\n\n\n\n\n\npandas\n\n\nbokeh\n\n\nanalysis\n\n\nold\n\n\n\n\nExploring prisoner data up through 2016\n\n\n\n\n\n\nJun 27, 2018\n\n\nMatt Triano\n\n\n\n\n\n\n  \n\n\n\n\nExploration in Criminal Justice and Corrections Data, Part 1\n\n\n\n\n\n\n\npandas\n\n\nanalysis\n\n\nold\n\n\n\n\nExploring prisoner data up through 2016\n\n\n\n\n\n\nJun 26, 2018\n\n\nMatt Triano\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html",
    "href": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html",
    "title": "How to Manually Reproduce a Conda Env",
    "section": "",
    "text": "This post will demonstrate how to reproduce an old conda env (that wasn’t exported to an environment.yml file at the time of analysis/usage) needed to rerun old analysis1."
  },
  {
    "objectID": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#step-0.-configure-conda",
    "href": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#step-0.-configure-conda",
    "title": "How to Manually Reproduce a Conda Env",
    "section": "2.1 Step 0. Configure conda",
    "text": "2.1 Step 0. Configure conda\nInstall conda and configure it as shown in steps 3 & 4 here."
  },
  {
    "objectID": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#step-1.-determine-packages-used-in-the-old-work",
    "href": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#step-1.-determine-packages-used-in-the-old-work",
    "title": "How to Manually Reproduce a Conda Env",
    "section": "2.2 Step 1. Determine packages used in the old work",
    "text": "2.2 Step 1. Determine packages used in the old work\nLook at the old analysis and any available metadata to determine:\n\nWhen was the analysis run?\nWhat packages were used?\n\nFor this demonstration, I’m reproducing an env I used to analyze crime and prison data back in 2018. Specifically, I want to produce an env that enables me to rerun these notebooks:\n\nCrime and Prisons part 1\nCrime and Prisons part 2\nCrime and Prisons part 3\n\n\n2.2.1 Determining when the analysis was run\nLooking at the latest commits for these notebooks, we can set an upper bound on versions used. The latest commits for these notebooks are:\n\nPart 1: June 26, 2018\nPart 2: Aug 16, 2018\nPart 3: June 15, 2018\n\nFrom the sidequest described in Section 4.1.1, I’ve decided on using June 15, 2018 as the upper-bound date for analysis.\n\n\n2.2.2 Determining used packages\nFor this, I simply look at the import statements, which are compiled below.\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nfrom IPython.core.display import display, HTML\nimport os\nfrom bokeh.sampledata.us_states import data as states\nfrom bokeh.plotting import figure, show, output_notebook\nfrom bokeh.models import HoverTool, ColumnDataSource\nfrom bokeh.models import LinearColorMapper, ColorBar, BasicTicker\nThis boils down to [pandas, numpy, seaborn, matplotlib, IPython, and bokeh] (there’s also os, but that’s a python built-in)."
  },
  {
    "objectID": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#step-2.-determine-max-versions-at-analysis-time",
    "href": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#step-2.-determine-max-versions-at-analysis-time",
    "title": "How to Manually Reproduce a Conda Env",
    "section": "2.3 Step 2. Determine max versions at analysis-time",
    "text": "2.3 Step 2. Determine max versions at analysis-time\nFirst, I want to determine the version of python to use. Looking at the release dates of python versions, we see that python v3.6 was released on 2016-12-23 and python v3.7 was released on 2018-06-27, so the it’s most likely that python v3.6 was used.\n\n\n\n\n\n\nCorroboration\n\n\n\n\n\nLooking at the raw file, specifically a few lines from the very bottom of the document, the metadata block indicates the kernel used python v3.6.4\n\n\n\nNext, I want to determine max versions for pandas, numpy, seaborn, matplotlib, IPython, and bokeh. I know pandas uses numpy and seaborn uses matplotlib, so I can ignore numpy and matplotlib.\nI’ll look at each package’s releases page to see the last version before the cutoff date.\n\npandas: v0.24.2\nseaborn: v0.8.1\nbokeh: v0.12.16\n\n\n\n\n\n\n\nCorroboration\n\n\n\n\n\nLooking at the raw file, specifically by ctrl+f searching “version”, we see that bokeh v0.12.16 was used.\n\n\n\nAlso, IPython was included as it’s a dependency of the (jupyter) notebook package (which I used to develop the notebooks). There will probably be several other infrastructural\n\njupyter notebook: v5.5.0"
  },
  {
    "objectID": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#step-3.-create-the-env-and-register-it-as-a-notebook-kernel",
    "href": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#step-3.-create-the-env-and-register-it-as-a-notebook-kernel",
    "title": "How to Manually Reproduce a Conda Env",
    "section": "2.4 Step 3. Create the env and register it as a notebook kernel",
    "text": "2.4 Step 3. Create the env and register it as a notebook kernel\nFrom the prior step, we determined the following version constraints.\n\npython=3.6.4\npandas&lt;=0.24.2\nseaborn&lt;=0.8.1\nbokeh==0.12.16\nnotebook&lt;=5.5.0\n\nI’ll run the command below to create a conda env named prisons_post_env that meets those constraints.\nconda create --name prisons_post_env \"python=3.6.4\" \"pandas&lt;=0.24.2\" \"seaborn&lt;=0.8.1\" \"bokeh=0.12.16\" \"notebook&lt;=5.5.0\"\nActivate that conda env\nconda activate prisons_post_env\nand register that conda env as a notebook kernel\n(prisons_post_env) ...$ python -m ipykernel install --user --name prisons_post_env --display-name \"(prisons_post_env)\""
  },
  {
    "objectID": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#step-4.-attempt-to-reproduce-prior-results-and-troubleshoot-issues",
    "href": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#step-4.-attempt-to-reproduce-prior-results-and-troubleshoot-issues",
    "title": "How to Manually Reproduce a Conda Env",
    "section": "2.5 Step 4. Attempt to reproduce prior results and troubleshoot issues",
    "text": "2.5 Step 4. Attempt to reproduce prior results and troubleshoot issues\nNow you can start up a notebook server (I’ve specified a port number as I’m already running a jupyterlab server on the default port, 8888)\njupyter notebook --port=9494\n\n2.5.1 Troubleshooting 1\nWhile trying to open up the part 2 notebook, the connection attempt hung and the terminal showed an error.\n...\n~/miniconda3/envs/prisons_post_env/lib/python3.6/site-packages/notebook/base/zmqhandlers.py:284:  RuntimeWarning: coroutine 'WebSocketHandler.get' was never awaited\nGoogling the error took me to a Stack Overflow question that indicates package tornado v6+ caused the issue, so let’s downgrade tornado in our env\n(prisons_post_env) ...$ conda install -c conda-forge \"tornado&lt;6\" --freeze-installed\nthen restart our notebook server (press ctrl+c in the terminal, shut it down, then start it back up with the earlier jupyter notebook command). When you reopen the Crime_and_Prisons_part2.ipynb notebook, you should find that it successfully connects to the kernel and you can run through cells. At least up until cell that calls the plot_male_v_female_by_state_sea() function.\n\n\n2.5.2 Troubleshooting 2\nUpon attempting to run that cell, you will see another error message.\n~/miniconda3/envs/prisons_post_env/lib/python3.6/site-packages/matplotlib/artist.py in update(self, props)\n...\nAttributeError: 'Rectangle' object has no property 'normed'\nAfter a few minutes of googling the error message along with the word matplotlib, I’ve determined that the problem is that the installed seaborn version’s distplot() function calls matplotlib’s hist() plotter function using a keyword argument, normed, that was changed in the matplotlib v3.2.0 release. And by running this\nimport matplotlib\nmatplotlib.__version__\nI see this env has matplotlib v3.3.2 installed. So let’s downgrade matplotlib.\n(prisons_post_env) ...$ conda install -c conda-forge \"matplotlib&lt;3.2\"\nLooking at the installation plan, I see that conda wants to upgrade a lot of packages in violation of the earlier constraints. I also tried adding the --freeze-installed option, but conda still wanted to make updates including these.\n  bokeh                                      0.12.16-py36_0 --&gt; 2.3.3-py36h5fab9bb_0\n  notebook                                     5.5.0-py36_0 --&gt; 6.3.0-py36h5fab9bb_0\n  pandas                              0.24.2-py36hb3f55d8_1 --&gt; 1.1.5-py36h284efc9_0\n  python                                            3.6.4-0 --&gt; 3.6.15-hb7a2778_0_cpython\n  seaborn                                        0.8.1-py_1 --&gt; 0.11.2-hd8ed1ab_0\n  tornado                           5.1.1-py36h14c3975_1000 --&gt; 6.1-py36h8f6f2f9_1\n  ...\nSo let’s just completely remove and remake the env with all of our constraints, old and new.\nAfter shutting down the jupyter notebook server and ensuring the env is not activated in any open terminal, remove the env directory\nrm -r ~/miniconda3/envs/prisons_post_env/\nthen recreate the env with our additional constraints. Through a fair bit of trial and error, I determined that one of my preferred configs (namely prioritizing the conda-forge channel) was making it impossible to reconcile these constraints, so I overrode the configured channels in favor of the default channel that I was probably using 5 years ago. I’ll also add on the xlrd package, as the part3 notebook loads a .xls file.\nconda create --name prisons_post_env --override-channels --channel defaults \"python=3.6.4\" \"pandas&lt;=0.24.2\" \"seaborn&lt;=0.8.1\" \"bokeh=0.12.16\" \"notebook&lt;=5.5.0\" \"tornado&lt;6\" \"matplotlib=2.2.2\" xlrd\nThen activate and re-register the env\nconda activate prisons_post_env\n(prisons_post_env) ...$ python -m ipykernel install --user --name prisons_post_env --display-name \"(prisons_post_env)\"\nand restart the notebook server.\nNow all three of those old notebooks can be run successfully (after collecting and locating the data in the right places).\n\n\n\n\n\n\nWhy did changing the conda channel make the dependencies solvable?\n\n\n\n\n\nYou may wonder “How could changing the package source (aka ‘channel’) make the env solvable? The package versions were the same!”\nThat’s a good observation and intuition! If converting a python package into a conda package was impossible to mess up, there wouldn’t be any difference in conda packages for a given python package version across channels. But conda isn’t just a tool for packaging python code; it’s a tool for packaging and distributing any executable, and that often means instructions for building the package and for resolving dependencies are needed. In essence, you need a recipe for making the package. In conda terms, that recipe is a package’s meta.yaml file, and the file provides places to point to build scripts and define dependencies. Each conda channel is maintained separately, so each can have different meta.yaml file for a given python package version. Consequently, if dependencies are inconsistent across channels, an env that’s consistent when pulling exclusively from one channel may be unresolvable when pulling exclusively from another channel."
  },
  {
    "objectID": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#step-5.-export-the-env",
    "href": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#step-5.-export-the-env",
    "title": "How to Manually Reproduce a Conda Env",
    "section": "2.6 Step 5. Export the env",
    "text": "2.6 Step 5. Export the env\nNow that we have a working env, let’s export both the full specification and a cross-platform specification (which only includes the explicitly requested packages).\n\n\nExport the full, OS specific env spec\n!conda env export -n prisons_post_env &gt; environment.yml\n\n\n\n\nExport the cross-platform env spec\n!conda env export -n prisons_post_env --from-history &gt; environment_cross_platform.yml"
  },
  {
    "objectID": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#side-projects",
    "href": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#side-projects",
    "title": "How to Manually Reproduce a Conda Env",
    "section": "4.1 Side Projects",
    "text": "4.1 Side Projects\nWhile working through technical projects, little problems tangential to the main task often pop out and block progress. Often these side quests can be ignored, but\n\n4.1.1 git diff side project\nI don’t recall why I updated Parts 1 and 2 after Part 3. I doubt I made substantive changes, but as I’m using metadata of git commits to determine changes, it only makes sense to look at the diffs. Unfortunately, while github indicates a relatively small number of lines were modified, the diffs are too large to display in browser and I have to review in a locally to see the diffs.\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis is a well-known drawback of jupyter notebooks; plots get represented by very long plaintext strings and rerunning a notebook often changes every line in version control, so diffs can be hard to review).\n\n\n\nSo I cloned the repo, copied down the hash of the commit I’m interested in (commit 0857e6c), and looked at the diffs of that file in that commit via\ngit diff 0857e6c^..0857e6c -- Crime_and_Prisons_part2.ipynb\nMost of the changes only changed the cell execution-order number or uuid-looking tags. There may also have been changes to the extremely long string representations used to render plots, but they were too long to crosscheck. In fact, those long strings took so long to page through that I stopped reviewing that way and just compared the rendered notebooks (pre-commit vs commit) and concluded there weren’t any substantive changes, so the timestamp from the earlier commit is adequate."
  },
  {
    "objectID": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#footnotes",
    "href": "posts/009_reproducing_a_conda_env/Manually_reproducing_an_old_env.html#footnotes",
    "title": "How to Manually Reproduce a Conda Env",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nContext: Over the years, I’ve writen up a number of posts for a number of different personal blogs, and I want to consolidate those posts into one platform. Many of my posts involved leveraging the capabilities of jupyter notebooks, and while I’ve always used conda envs to avoid polluting my base python environment, I didn’t reliably export my envs or keep separate envs for each project or purpose. So I occassionally run into a situation where I want to rerun old code on a new machine, but I have to go through extra steps to recreate the env.↩︎"
  },
  {
    "objectID": "posts/002_notebook_test/jupyter_quarto.html",
    "href": "posts/002_notebook_test/jupyter_quarto.html",
    "title": "Working with Notebooks",
    "section": "",
    "text": "Code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 4, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\nFigure 1: A line plot on a polar axis\n\n\n\n\n\nDevelop a notebook\nRender that notebook via\n(quarto_env) user@hostname:~/...$ quarto render notebook_name.ipynb\nPreview your document via\n(quarto_env) user@hostname:~/...$ quarto preview quarto_blog/\nNote: Make sure draft: false in your document, or it won’t render.\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/012_crime_and_prisons_p3/Crime_and_Prisons_part3.html",
    "href": "posts/012_crime_and_prisons_p3/Crime_and_Prisons_part3.html",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 3",
    "section": "",
    "text": "Update Note\n\n\n\n\n\nThe majority of code and analysis in this post was originally written back in mid-2018 (in this notebook). I’ve consolidated some cells, automated data retrieval, and added cell labels to make things render nicely, but otherwise I’ve left the work as-is. Compared to my current work products, this old code is very messy and unpolished, but like Eric Ma (creator of the networkx graph data analysis package), I believe in showing newer data analysts and scientists I mentor that no one in this field started off with mastery of git, pandas, bash, etc, and that everyone who lasts loves to keep learning and improving.\nAfter I integrate these old posts into this blog, I’ll write an EDA post that starts from scratch using up-to-date data."
  },
  {
    "objectID": "posts/012_crime_and_prisons_p3/Crime_and_Prisons_part3.html#data-source",
    "href": "posts/012_crime_and_prisons_p3/Crime_and_Prisons_part3.html#data-source",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 3",
    "section": "1.1 Data Source",
    "text": "1.1 Data Source\nThis data is from file p16t03.csv of the Bureau of Justice Statistics Prisoner Series data.\n\n\nImports, styling, and path definitions\nimport os\nfrom urllib.request import urlretrieve\nimport zipfile\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nfrom IPython.core.display import display, HTML\n%matplotlib inline\n\n# Importing modules from a visualization package.\n# from bokeh.sampledata.us_states import data as states|\nfrom bokeh.plotting import figure, show, output_notebook\nfrom bokeh.models import HoverTool, ColumnDataSource\nfrom bokeh.models import LinearColorMapper, ColorBar, BasicTicker\n\n# styling\npd.options.display.max_columns = None\ndisplay(HTML(\"&lt;style&gt;.container { width:100% !important; }&lt;/style&gt;\"))\npd.set_option('display.float_format',lambda x: '%.3f' % x)\nplt.rcParams['figure.figsize'] = 10,10\n\nDATA_DIR_PATH = os.path.join(\"..\", \"010_crime_and_prisons_p1\", 'data')\nPRISON_DATA_DIR = os.path.join(DATA_DIR_PATH, 'prison')\nPOP_DATA_DIR = os.path.join(DATA_DIR_PATH, \"population\")\n\n\n\n\n\n\n\nLoading and preprocessing the t03 dataset, Counts by Gender, Race, and Jurisdiction\nCSV_PATH = os.path.join(PRISON_DATA_DIR, 'p16t03.csv')\nrace_sex_raw = pd.read_csv(CSV_PATH, \n                           encoding='latin1',\n                           header=11, \n                           na_values=':',\n                           thousands=r',')\nrace_sex_raw.dropna(axis=0, thresh=3, inplace=True)\nrace_sex_raw.dropna(axis=1, thresh=3, inplace=True)\nrace_sex_raw.dropna(axis=0, inplace=True)\nfix = lambda x: x.split('/')[0]\nrace_sex_raw['Year'] = race_sex_raw['Year'].apply(fix)\nrace_sex_raw.columns = [x.split('/')[0] for x in race_sex_raw.columns]\nrace_sex_raw.set_index('Year', inplace=True)\n\ndisplay(race_sex_raw)\n\n\n\n\n\n\n\n\n\nTotal\nFederal\nState\nMale\nFemale\nWhite\nBlack\nHispanic\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n2006\n1504598.000\n173533.000\n1331065.000\n1401261.000\n103337.000\n507100.000\n590300.000\n313600.000\n\n\n2007\n1532851.000\n179204.000\n1353647.000\n1427088.000\n105763.000\n499800.000\n592900.000\n330400.000\n\n\n2008\n1547742.000\n182333.000\n1365409.000\n1441384.000\n106358.000\n499900.000\n592800.000\n329800.000\n\n\n2009\n1553574.000\n187886.000\n1365688.000\n1448239.000\n105335.000\n490000.000\n584800.000\n341200.000\n\n\n2010\n1552669.000\n190641.000\n1362028.000\n1447766.000\n104903.000\n484400.000\n572700.000\n345800.000\n\n\n2011\n1538847.000\n197050.000\n1341797.000\n1435141.000\n103706.000\n474300.000\n557100.000\n347800.000\n\n\n2012\n1512430.000\n196574.000\n1315856.000\n1411076.000\n101354.000\n466600.000\n537800.000\n340300.000\n\n\n2013\n1520403.000\n195098.000\n1325305.000\n1416102.000\n104301.000\n463900.000\n529900.000\n341200.000\n\n\n2014\n1507781.000\n191374.000\n1316407.000\n1401685.000\n106096.000\n461500.000\n518700.000\n338900.000\n\n\n2015\n1476847.000\n178688.000\n1298159.000\n1371879.000\n104968.000\n450200.000\n499400.000\n333200.000\n\n\n2016\n1458173.000\n171482.000\n1286691.000\n1352684.000\n105489.000\n439800.000\n486900.000\n339300.000\n\n\n\n\n\n\n\n\n\nMean annual inmate count by race\nprint('Average number of {:&gt;8s} people in prison from 2006 to 2016: {:6.0f}'\n      .format('black', race_sex_raw['Black'].mean()))\nprint('Average number of {:&gt;8s} people in prison from 2006 to 2016: {:6.0f}'\n      .format('white', race_sex_raw['White'].mean()))\nprint('Average number of {:&gt;8s} people in prison from 2006 to 2016: {:6.0f}'\n      .format('Hispanic', race_sex_raw['Hispanic'].mean()))\n\n\nAverage number of    black people in prison from 2006 to 2016: 551209\nAverage number of    white people in prison from 2006 to 2016: 476136\nAverage number of Hispanic people in prison from 2006 to 2016: 336500\n\n\n\n\nPlotting annual inmate counts by race\nwith sns.axes_style(\"whitegrid\"):\n    fig, ax = plt.subplots(figsize=(10,7))\n    ax.plot(race_sex_raw['White'])\n    ax.plot(race_sex_raw['Black'])\n    ax.plot(race_sex_raw['Hispanic'])\n    ax.set_title('Total Imprisonment Counts by Race (table: p16t03)',fontsize=14)\n    ax.set_xlabel('Year', fontsize=14)\n    ax.set_ylabel('Number of People imprisoned', fontsize=14)\n    ax.legend(fontsize=14)\n    ax.set_ylim([0, 1.1*max([race_sex_raw['White'].max(), \n                             race_sex_raw['Black'].max(),\n                             race_sex_raw['Hispanic'].max()])])\n\n\n\n\n\nLooking at this plot of total imprisonment counts, we see that: * At any given time, there are more non-Hispanic black people in prison than any other race. * At any given time, there are more non-Hispanic white people than Hispanic people in prison. * The numbers of imprisoned black people and white people decreased steadily from 2008 to 2016, while the number of imprisoned Hispanic people was been fairly flat over that time.\nThese numbers are raw counts, so they don’t account for the fact that the fact that these races make up different proportions of the entire US population. This motivates questions like:\n\nWhat percent of the population of each race is in prison?\n\nTo answer that, I’ll have to find population data broken down by race.\n\n1.1.1 Census Data\nThe Constitution requires that a full, national census is performed every 10 years that reaches every resident on American soil. This data is used to determine how much federal money is allocated to each district for things like schools, roadways, police, etc. and it determines how many congressional representatives will be allocated to each state. With the help of smaller surveys, the US Census bureau makes estimates of populations for the years between censuses.\ndata source\n\n\n(NEW CODE) automating data collection\nzip_pop_file_path = os.path.join(POP_DATA_DIR, \"PEP_2016_PEPSR6H.zip\")\nurl = \"https://www2.census.gov/programs-surveys/popest/tables/2010-2016/state/asrh/PEP_2016_PEPSR6H.zip\"\nif not os.path.isfile(zip_pop_file_path):\n    urlretrieve(url=url, filename=zip_pop_file_path)\n    with zipfile.ZipFile(zip_pop_file_path, 'r') as zf:\n        zf.extractall(POP_DATA_DIR)\n\n\n\n\nLoading, filtering, and preprocessing annual national pop. estimates by race and ethnicity\nCSV_PATH = os.path.join(POP_DATA_DIR, 'PEP_2016_PEPSR6H_with_ann.csv')\nrace_pop = pd.read_csv(CSV_PATH, header=[1], encoding='latin1')\nprint('\\nInitial Data Format:')\ndisplay(race_pop.head(3))\n# Only looking for national values\nrace_pop = race_pop[race_pop['Geography'] == 'United States']\n# Eliminating the actual census values\nrace_pop = race_pop[~race_pop['Year'].str.contains('April')]\n# Eliminating aggregated rows\nrace_pop = race_pop[race_pop['Hispanic Origin'] != 'Total']\n# race_pop = race_pop[race_pop['Sex'] != 'Both Sexes']  # for later\nrace_pop = race_pop[~race_pop['Sex'].isin(['Male','Female'])]\n\ndrop_cols = ['Id', 'Id.1', 'Id.2', 'Id2', 'Id.3', 'Geography', 'Sex',\n             'Race Alone - American Indian and Alaska Native', 'Race Alone - Asian',\n             'Race Alone - Native Hawaiian and Other Pacific Islander']\nrace_pop.drop(drop_cols, axis=1, inplace=True)\n\n# Reducing the size of long column names\ncol_map = {'Race Alone - Black or African American':'black_only_pop',\n           'Race Alone - White': 'white_only_pop'}\nrace_pop.rename(col_map, axis=1, inplace=True)\n\nprint('\\n\\nData Format after Processing:')\ndisplay(race_pop.head(3))\n\n\n\nInitial Data Format:\n\n\nData Format after Processing:\n\n\n\n\n\n\n\n\n\nId\nYear\nId.1\nSex\nId.2\nHispanic Origin\nId.3\nId2\nGeography\nTotal\nRace Alone - White\nRace Alone - Black or African American\nRace Alone - American Indian and Alaska Native\nRace Alone - Asian\nRace Alone - Native Hawaiian and Other Pacific Islander\nTwo or More Races\n\n\n\n\n0\ncen42010\nApril 1, 2010 Census\nfemale\nFemale\nhisp\nHispanic\n0100000US\nnan\nUnited States\n24858794\n21936806\n1191984\n702309\n249346\n85203\n693146\n\n\n1\ncen42010\nApril 1, 2010 Census\nfemale\nFemale\nnhisp\nNot Hispanic\n0100000US\nnan\nUnited States\n132105418\n100301335\n19853611\n1147502\n7691693\n246518\n2864759\n\n\n2\ncen42010\nApril 1, 2010 Census\nfemale\nFemale\ntothisp\nTotal\n0100000US\nnan\nUnited States\n156964212\n122238141\n21045595\n1849811\n7941039\n331721\n3557905\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nHispanic Origin\nTotal\nwhite_only_pop\nblack_only_pop\nTwo or More Races\n\n\n\n\n24\nJuly 1, 2010\nHispanic\n50754069\n44855529\n2343053\n1392607\n\n\n25\nJuly 1, 2010\nNot Hispanic\n258594124\n197394319\n38015461\n5647760\n\n\n33\nJuly 1, 2011\nHispanic\n51906353\n45841771\n2410490\n1445820\n\n\n\n\n\n\n\nBased on the aggregation of the data I pulled, there is a rather vague ‘Two or More Races’ column. The prisoner data I’ve been working with has not differentiated between multiracial people and single-race people, rather, the prison data only breaks races down to non-Hispanic white, non-Hispanic black, and Hispanic. It’s entirely possible for someone to be non-Hispanic, black, and multiracial, which would make it much more difficult and less accurate to use this population data with the prison data. Fortunately, however, the documentation for the prison data] includes footnotes indicating the data for white and black prison populations excludes persons of two or more races, so, conveniently, I must also exclude it.\n\n\nEngineering counts for Hispanic origin (any race), Non Hispanic White only, and Non Hispanic Black only\nrace_pop.drop('Two or More Races', axis=1, inplace=True)\nhisp = race_pop[race_pop['Hispanic Origin'] == 'Hispanic'].copy()\nnon_hisp = race_pop[race_pop['Hispanic Origin'] != 'Hispanic'].copy()\nnon_hisp.drop(['Hispanic Origin', 'Total'], axis=1, inplace=True)\nhisp.drop(['white_only_pop','black_only_pop', 'Hispanic Origin'], axis=1, inplace=True)\nhisp.rename({'Total':'Hispanic_pop'}, axis=1, inplace=True)\nus_race_pop = hisp.merge(non_hisp, on=['Year'])\nfix_yr = lambda x: x.split(' ')[-1]\nus_race_pop['Year'] = us_race_pop['Year'].apply(fix_yr)\nus_race_pop.set_index('Year', inplace=True)\n\ndisplay(us_race_pop.head(3))\n\n\n\n\n\n\n\n\n\nHispanic_pop\nwhite_only_pop\nblack_only_pop\n\n\nYear\n\n\n\n\n\n\n\n2010\n50754069\n197394319\n38015461\n\n\n2011\n51906353\n197519026\n38393758\n\n\n2012\n52993496\n197701109\n38776276\n\n\n\n\n\n\n\nThis provides population data from 2010 on, but not for the earlier years. To deal with earlier years, I need to handle another data set.\ndata source\n\n\n(NEW CODE) automating data collection\npop_file_path = os.path.join(POP_DATA_DIR, \"us-est00int-02.xls\")\nurl = \"https://www2.census.gov/programs-surveys/popest/tables/2000-2010/intercensal/national/us-est00int-02.xls\"\nif not os.path.isfile(pop_file_path):\n    urlretrieve(url=url, filename=pop_file_path)\n\n\n\n\nLoading, filtering, and preprocessing annual national pop. estimates by race and ethnicity\nrace_pop0010 = pd.read_excel(pop_file_path, header=None)\nprint('\\nInitial Data Format:')\ndisplay(race_pop0010.head())\n\nrace_pop0010.dropna(axis=0, thresh=6, inplace=True)\nrace_pop0010.drop([1],axis=1, inplace=True)\nrace_pop0010 = race_pop0010.T\nrace_pop0010.iloc[0,0] = 'Year'\nrace_pop0010.columns = race_pop0010.loc[0]\nrace_pop0010.drop(0, axis=0, inplace=True)\nrace_pop0010.dropna(axis=0, inplace=True)\nrace_pop0010['Year'] = race_pop0010['Year'].astype(int)\nrace_pop0010['Year'] = race_pop0010['Year'].astype(str)\nrace_pop0010.set_index('Year', inplace=True)\n\n# Code to help drop columns I'm not interested in\ndrop_cols = []\ndrop_stumps = ['AIAN','Asian','NHPI', 'One Race', 'Two or']\nfor col in race_pop0010.columns:\n    if any(x in col for x in drop_stumps):\n        drop_cols.append(col)\nrace_pop0010.drop(drop_cols, axis=1, inplace=True)\n\n# Code to facilitate merging this DataFrame with theother Population DataFrame\nboth0010 = race_pop0010.iloc[:,4:7].copy()\nname_map = {'...White'  : 'white_only_pop',\n            '...Black'  : 'black_only_pop',\n            '.HISPANIC' : 'Hispanic_pop'}\nboth0010.rename(name_map, axis=1, inplace=True)\nboth0010 = both0010.astype(int)\npop_span = pd.concat([both0010, us_race_pop], join='inner')\nrace_sex_pop = race_sex_raw.join(pop_span)\n\nprint('\\n\\nData Format after Processing:')\ndisplay(race_pop0010.head())\n\n\n\nInitial Data Format:\n\n\nData Format after Processing:\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n\n0\ntable with row headers in column A and column ...\nNaN\nNaN\nnan\nnan\nnan\nnan\nnan\nnan\nnan\nnan\nnan\nNaN\nNaN\n\n\n1\nTable 2. Intercensal Estimates of the Resident...\nNaN\nNaN\nnan\nnan\nnan\nnan\nnan\nnan\nnan\nnan\nnan\nNaN\nNaN\n\n\n2\nSex, Race, and Hispanic Origin\nApril 1, 20001\nIntercensal Estimates (as of July 1)\nnan\nnan\nnan\nnan\nnan\nnan\nnan\nnan\nnan\nApril 1, 20102\nJuly 1, 20103\n\n\n3\nNaN\nNaN\n2000\n2001.000\n2002.000\n2003.000\n2004.000\n2005.000\n2006.000\n2007.000\n2008.000\n2009.000\nNaN\nNaN\n\n\n4\nBOTH SEXES\n281424600\n282162411\n284968955.000\n287625193.000\n290107933.000\n292805298.000\n295516599.000\n298379912.000\n301231207.000\n304093966.000\n306771529.000\n308745538\n309349689\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBOTH SEXES\n..White\n..Black\n.NOT HISPANIC\n...White\n...Black\n.HISPANIC\n...White\n...Black\nMALE\n..White\n..Black\n.NOT HISPANIC\n...White\n...Black\n.HISPANIC\n...White\n...Black\nFEMALE\n..White\n..Black\n.NOT HISPANIC\n...White\n...Black\n.HISPANIC\n...White\n...Black\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2000\n282162411\n228530479\n35814706\n246500526\n195701752\n34405800\n35661885\n32828727\n1408906\n138443407\n112710885\n17027514\n120101363\n95778530\n16340639\n18342044\n16932355\n686875\n143719004\n115819594\n18787192\n126399163\n99923222\n18065161\n17319841\n15896372\n722031\n\n\n2001\n284968955.000\n230049196.000\n36263029.000\n247824859.000\n195974813.000\n34780280.000\n37144096.000\n34074383.000\n1482749.000\n139891492.000\n113534140.000\n17249678.000\n120806379.000\n95977450.000\n16526760.000\n19085113.000\n17556690.000\n722918.000\n145077463.000\n116515056.000\n19013351.000\n127018480.000\n99997363.000\n18253520.000\n18058983.000\n16517693.000\n759831.000\n\n\n2002\n287625193.000\n231446915.000\n36684650.000\n249007573.000\n196140540.000\n35130061.000\n38617620.000\n35306375.000\n1554589.000\n141230559.000\n114269447.000\n17454795.000\n121412514.000\n96101267.000\n16697032.000\n19818045.000\n18168180.000\n757763.000\n146394634.000\n117177468.000\n19229855.000\n127595059.000\n100039273.000\n18433029.000\n18799575.000\n17138195.000\n796826.000\n\n\n2003\n290107933.000\n232717191.000\n37066096.000\n250058504.000\n196232760.000\n35438251.000\n40049429.000\n36484431.000\n1627845.000\n142428897.000\n114897973.000\n17631747.000\n121910556.000\n96155748.000\n16839027.000\n20518341.000\n18742225.000\n792720.000\n147679036.000\n117819218.000\n19434349.000\n128147948.000\n100077012.000\n18599224.000\n19531088.000\n17742206.000\n835125.000\n\n\n2004\n292805298.000\n234120447.000\n37510582.000\n251303923.000\n196461761.000\n35797599.000\n41501375.000\n37658686.000\n1712983.000\n143828012.000\n115664854.000\n17856753.000\n122592198.000\n96345151.000\n17022156.000\n21235814.000\n19319703.000\n834597.000\n148977286.000\n118455593.000\n19653829.000\n128711725.000\n100116610.000\n18775443.000\n20265561.000\n18338983.000\n878386.000\n\n\n\n\n\n\n\nNow that I’ve got a full population data set, I can normalize the prisoner data.\n\n\nEngineering percent of total group population incarcerated features\nrace_sex_pop.loc[:,'White_pct'] = race_sex_pop.loc[:,'White']\\\n                .divide(race_sex_pop.loc[:,'white_only_pop']) * 100\nrace_sex_pop.loc[:,'Black_pct'] = race_sex_pop.loc[:,'Black']\\\n                .divide(race_sex_pop.loc[:,'black_only_pop']) * 100\nrace_sex_pop.loc[:,'Hispanic_pct'] = race_sex_pop.loc[:,'Hispanic']\\\n                .divide(race_sex_pop.loc[:,'Hispanic_pop']) * 100\n\ndisplay(race_sex_pop)\n\n\n\n\n\n\n\n\n\nTotal\nFederal\nState\nMale\nFemale\nWhite\nBlack\nHispanic\nwhite_only_pop\nblack_only_pop\nHispanic_pop\nWhite_pct\nBlack_pct\nHispanic_pct\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2006\n1504598.000\n173533.000\n1331065.000\n1401261.000\n103337.000\n507100.000\n590300.000\n313600.000\n196832697\n36520961\n44606305\n0.258\n1.616\n0.703\n\n\n2007\n1532851.000\n179204.000\n1353647.000\n1427088.000\n105763.000\n499800.000\n592900.000\n330400.000\n197011394\n36905758\n46196853\n0.254\n1.607\n0.715\n\n\n2008\n1547742.000\n182333.000\n1365409.000\n1441384.000\n106358.000\n499900.000\n592800.000\n329800.000\n197183535\n37290709\n47793785\n0.254\n1.590\n0.690\n\n\n2009\n1553574.000\n187886.000\n1365688.000\n1448239.000\n105335.000\n490000.000\n584800.000\n341200.000\n197274549\n37656592\n49327489\n0.248\n1.553\n0.692\n\n\n2010\n1552669.000\n190641.000\n1362028.000\n1447766.000\n104903.000\n484400.000\n572700.000\n345800.000\n197394319\n38015461\n50754069\n0.245\n1.506\n0.681\n\n\n2011\n1538847.000\n197050.000\n1341797.000\n1435141.000\n103706.000\n474300.000\n557100.000\n347800.000\n197519026\n38393758\n51906353\n0.240\n1.451\n0.670\n\n\n2012\n1512430.000\n196574.000\n1315856.000\n1411076.000\n101354.000\n466600.000\n537800.000\n340300.000\n197701109\n38776276\n52993496\n0.236\n1.387\n0.642\n\n\n2013\n1520403.000\n195098.000\n1325305.000\n1416102.000\n104301.000\n463900.000\n529900.000\n341200.000\n197777454\n39135988\n54064149\n0.235\n1.354\n0.631\n\n\n2014\n1507781.000\n191374.000\n1316407.000\n1401685.000\n106096.000\n461500.000\n518700.000\n338900.000\n197902336\n39507913\n55189962\n0.233\n1.313\n0.614\n\n\n2015\n1476847.000\n178688.000\n1298159.000\n1371879.000\n104968.000\n450200.000\n499400.000\n333200.000\n197964402\n39876758\n56338521\n0.227\n1.252\n0.591\n\n\n2016\n1458173.000\n171482.000\n1286691.000\n1352684.000\n105489.000\n439800.000\n486900.000\n339300.000\n197969608\n40229236\n57470287\n0.222\n1.210\n0.590\n\n\n\n\n\n\n\n\n\nPlotting percent of total group population incarcerated by year\nwith sns.axes_style(\"whitegrid\"):\n    fig, ax = plt.subplots(figsize=(10,7))\n    ax.plot(race_sex_pop['White_pct'])\n    ax.plot(race_sex_pop['Black_pct'])\n    ax.plot(race_sex_pop['Hispanic_pct'])\n    ax.set_title('% of Total US Racial Population in Prison',fontsize=14)\n    ax.set_xlabel('Year', fontsize=14)\n    ax.set_ylabel('Percent of Racial Population In Prison [%]', fontsize=14)\n    ax.legend(fontsize=14)\n    ax.set_ylim([0, 1.1*max([race_sex_pop['White_pct'].max(), \n                             race_sex_pop['Black_pct'].max(),\n                             race_sex_pop['Hispanic_pct'].max()])])\n\n\n\n\n\n\n\nDescriptive stats for percent of group incarcerated\nprint('Average percentage of total {:&gt;8s} population in prison: {:0.3f}%'\n      .format('black', race_sex_pop['Black_pct'].mean()))\nprint('Average percentage of total {:8s} population in prison: {:0.3f}%'\n      .format('Hispanic', race_sex_pop['Hispanic_pct'].mean()))\nprint('Average percentage of total {:&gt;8s} population in prison: {:0.3f}%'\n      .format('white', race_sex_pop['White_pct'].mean()))\n\nprint('Change in percentage of total {:&gt;8s} population in prison between 2006 to 2016: {:0.3f}%'\n      .format('black', race_sex_pop['Black_pct']['2016'] - race_sex_pop['Black_pct']['2006']))\nprint('Change in percentage of total {:&gt;8s} population in prison between 2006 to 2016: {:0.3f}%'\n      .format('Hispanic', race_sex_pop['Hispanic_pct']['2016'] - race_sex_pop['Hispanic_pct']['2006']))\nprint('Change in percentage of total {:&gt;8s} population in prison between 2006 to 2016: {:0.3f}%'\n      .format('white', race_sex_pop['White_pct']['2016'] - race_sex_pop['White_pct']['2006']))\n\n\nAverage percentage of total    black population in prison: 1.440%\nAverage percentage of total Hispanic population in prison: 0.656%\nAverage percentage of total    white population in prison: 0.241%\nChange in percentage of total    black population in prison between 2006 to 2016: -0.406%\nChange in percentage of total Hispanic population in prison between 2006 to 2016: -0.113%\nChange in percentage of total    white population in prison between 2006 to 2016: -0.035%\n\n\nThat’s an extremely large difference. A randomly selected black person is nearly 6 times more likely to be in prison than a randomly selected white person and more than twice as likely as a randomly selected Hispanic person.\nThat motivates the question: Why is there such a large difference between these populations?\nTo investigate that question, it would be useful to investigate other questions, such as: * Does the criminal justice system treat different racial groups differently? * Is the average quality of education comparable for different racial populations? * Is the distribution of quality of education comparable for different racial populations? * Is the average quality of employment opportunity comparable for different racial populations? * Is the distribution of quality of employment opportunities comparable for different racial populations? * Is there a causal relationship between the pervasive housing segregation across the US and these disparities? * What drove the significant reduction in the incarcerated proportion of black Americans from 2006-2016?\nTo Be Continued?"
  },
  {
    "objectID": "posts/011_crime_and_prisons_p2/Crime_and_Prisons_part2.html",
    "href": "posts/011_crime_and_prisons_p2/Crime_and_Prisons_part2.html",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 2",
    "section": "",
    "text": "Update Note\n\n\n\n\n\nThe majority of code and analysis in this post was originally written back in mid-2018 (in this notebook). I’ve consolidated some cells, automated data retrieval, and added cell labels to make things render nicely, but otherwise I’ve left the work as-is. Compared to my current work products, this old code is very messy and unpolished, but like Eric Ma (creator of the networkx graph data analysis package), I believe in showing newer data analysts and scientists I mentor that no one in this field started off with mastery of git, pandas, bash, etc, and that everyone who lasts loves to keep learning and improving.\nAfter I integrate these old posts into this blog, I’ll write an EDA post that starts from scratch using up-to-date data."
  },
  {
    "objectID": "posts/011_crime_and_prisons_p2/Crime_and_Prisons_part2.html#table-of-contents",
    "href": "posts/011_crime_and_prisons_p2/Crime_and_Prisons_part2.html#table-of-contents",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 2",
    "section": "1.1 Table of Contents",
    "text": "1.1 Table of Contents\n\nExploration in Criminal Justice and Corrections Data\nDatasets\nTotal Imprisonment Rates 3a. Visualization Pitfall 3b. Population Dataset 3c. Visualization Breakthrough, Observations, and interactive maps\nState Imprisonment Distributions by Gender 4a. Static Scatter Plots with Distributions 4b. Interactive Scatter Plots\n\nSummary\n\n\nPrevious Notebook: Part 1\nNext Notebook: Part 3"
  },
  {
    "objectID": "posts/011_crime_and_prisons_p2/Crime_and_Prisons_part2.html#visualization-pitfall",
    "href": "posts/011_crime_and_prisons_p2/Crime_and_Prisons_part2.html#visualization-pitfall",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 2",
    "section": "3.1 Visualization Pitfall! ",
    "text": "3.1 Visualization Pitfall! \nFrom this map, we see that the most populated states have the most prisoners (you can see the actual number of people in prison by hovering the mouse over a state). That’s approximately what we would expect, but it doesn’t really help us answer questions about the differences in imprisonment rates between States (with different policies on criminal justice). This information is useful for investigating some questions (e.g. Where could prison reform impact the most lives?), but it’s not as useful if we’re investigating the relationship between policies, crime rates, and imprisonment rates. If we want to actually compare imprisonment rates between states, we need to normalize (or scale) the prisoner counts to the population of the state. This requires getting a different data set.\n\n3.1.1 Population Dataset \nThe US Census tracks and publishes population data, including a data set that tracks estimates of annual state populations (by gender) from 2010 to 2016. I’ll use this data to normalize the raw prisoner counts by state.\n\n\n(NEW CODE) automating data collection\npop_file_path = os.path.join(POP_DATA_DIR, \"sc-est2016-agesex-civ.csv\")\nurl = \"https://www2.census.gov/programs-surveys/popest/datasets/2010-2016/state/asrh/sc-est2016-agesex-civ.csv\"\nif not os.path.isfile(pop_file_path):\n    urlretrieve(url=url, filename=pop_file_path)\n\n\n\n\nLoading and preprocessing the Census State and Gender pop. estimates\nstate_pop_sex_df = pd.read_csv(pop_file_path, encoding='latin1', header=0)\nprint('\\nRaw Population Data Set Format')\ndisplay(state_pop_sex_df.head())\nstate_pop_sex_df = state_pop_sex_df[state_pop_sex_df['SEX'].isin([1,2])]\nstate_code = get_state_code()\nmap_state_codes = lambda x: state_code[x]\nfix_sex = lambda x: 'Male' if x == 1 else 'Female'\nstate_pop_sex_df['SEX'] = state_pop_sex_df['SEX'].apply(fix_sex)\nstate_pop_sex_df.drop(['SUMLEV','REGION','DIVISION','STATE','AGE', \n                       'ESTBASE2010_CIV', 'POPEST2010_CIV', 'POPEST2011_CIV',\n                       'POPEST2012_CIV', 'POPEST2013_CIV', 'POPEST2014_CIV'], \n                      axis=1, inplace=True)\nstate_pop_sex_df.rename({'POPEST2015_CIV':'2015_pop',\n                         'POPEST2016_CIV':'2016_pop'},\n                        axis=1, inplace=True)\nstate_pop_sex_df['Code'] = state_pop_sex_df['NAME'].apply(map_state_codes)\nstate_pop_sex_df = state_pop_sex_df.groupby(['SEX', 'Code']).sum()\nstate_pop_sex_df = state_pop_sex_df.unstack(0)\nprint('\\n\\nPopulation Data Set Format After Reformatting')\nstate_pop_sex_df.head()\n\n\n\nRaw Population Data Set Format\n\n\nPopulation Data Set Format After Reformatting\n\n\n\n\n\n\n\n\n\nSUMLEV\nREGION\nDIVISION\nSTATE\nNAME\nSEX\nAGE\nESTBASE2010_CIV\nPOPEST2010_CIV\nPOPEST2011_CIV\nPOPEST2012_CIV\nPOPEST2013_CIV\nPOPEST2014_CIV\nPOPEST2015_CIV\nPOPEST2016_CIV\n\n\n\n\n0\n10\n0\n0\n0\nUnited States\n0\n0\n3944160\n3951400\n3963239\n3926677\n3931346\n3955374\n3975414\n3970145\n\n\n1\n10\n0\n0\n0\nUnited States\n0\n1\n3978090\n3957847\n3966617\n3978101\n3943114\n3950083\n3974980\n3995008\n\n\n2\n10\n0\n0\n0\nUnited States\n0\n2\n4096939\n4090856\n3971363\n3980016\n3992752\n3959663\n3967361\n3992154\n\n\n3\n10\n0\n0\n0\nUnited States\n0\n3\n4119051\n4111929\n4102483\n3982920\n3992660\n4006960\n3974468\n3982074\n\n\n4\n10\n0\n0\n0\nUnited States\n0\n4\n4063186\n4077557\n4122286\n4112795\n3994261\n4005464\n4020276\n3987656\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2015_pop\n2016_pop\n\n\nSEX\nFemale\nMale\nFemale\nMale\n\n\nCode\n\n\n\n\n\n\n\n\nAK\n697258\n734122\n701214\n739176\n\n\nAL\n4998694\n4681748\n5011344\n4687956\n\n\nAR\n3028428\n2916226\n3039182\n2926812\n\n\nAZ\n6854628\n6744392\n6970496\n6853282\n\n\nCA\n39205974\n38470174\n39466330\n38716576\n\n\n\n\n\n\n\nNow that I’ve reformatted the population data to match the format of the state prisoner counts, I want to merge these two DataFrames together so that I can calculate the normalized rates of imprisonment.\n\n\nJoining state pop. estimates with state inmate counts\nstate_sex_join_df = state_sex_df.join(state_pop_sex_df)\ndisplay(state_sex_join_df.head())\n\n\n\n\n\n\n\n\n\n2015\n2016\n2015_pop\n2016_pop\n\n\nSEX\nTotal\nMale\nFemale\nTotal\nMale\nFemale\nFemale\nMale\nFemale\nMale\n\n\nCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAL\n30810.00000\n28220.00000\n2590.00000\n28883.00000\n26506.00000\n2377.00000\n4998694\n4681748\n5011344\n4687956\n\n\nAK\n5338.00000\n4761.00000\n577.00000\n4434.00000\n4024.00000\n410.00000\n697258\n734122\n701214\n739176\n\n\nAZ\n42719.00000\n38738.00000\n3981.00000\n42320.00000\n38323.00000\n3997.00000\n6854628\n6744392\n6970496\n6853282\n\n\nAR\n17707.00000\n16305.00000\n1402.00000\n17537.00000\n16161.00000\n1376.00000\n3028428\n2916226\n3039182\n2926812\n\n\nCA\n129593.00000\n123808.00000\n5785.00000\n130390.00000\n124487.00000\n5903.00000\n39205974\n38470174\n39466330\n38716576\n\n\n\n\n\n\n\nNow that I’ve merged the state prisoner counts with population data, I have to divide male prisoner counts by state population (of that gender) and store that information for use later.\n\n\nEngineering per-capita inmate count features\n# This Cell normalizes prisoner counts to be per 100k\n#   state population for that year.\nyrs = ['2015','2016']\nsexes = ['Male','Female']\n\nfor yr in yrs:\n    for sex in sexes:\n        state_sex_join_df.loc[:,(yr, sex + '_rate')] = \\\n            state_sex_join_df.loc[:,(yr, sex)]\\\n            .divide(state_sex_join_df.loc[:,(yr + '_pop', sex)]/100000)\ndisplay(state_sex_join_df.head(3))\n\n\n\n\n\n\n\n\n\n2015\n2016\n2015_pop\n2016_pop\n2015\n2016\n\n\nSEX\nTotal\nMale\nFemale\nTotal\nMale\nFemale\nFemale\nMale\nFemale\nMale\nMale_rate\nFemale_rate\nMale_rate\nFemale_rate\n\n\nCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAL\n30810.00000\n28220.00000\n2590.00000\n28883.00000\n26506.00000\n2377.00000\n4998694\n4681748\n5011344\n4687956\n602.76632\n51.81353\n565.40633\n47.43239\n\n\nAK\n5338.00000\n4761.00000\n577.00000\n4434.00000\n4024.00000\n410.00000\n697258\n734122\n701214\n739176\n648.52981\n82.75273\n544.38997\n58.47002\n\n\nAZ\n42719.00000\n38738.00000\n3981.00000\n42320.00000\n38323.00000\n3997.00000\n6854628\n6744392\n6970496\n6853282\n574.37349\n58.07755\n559.19193\n57.34169\n\n\n\n\n\n\n\n\n\nEncapsulating Bokeh Choropleth Plotting code in a function\n# I'm going to generate more choropleths, so I'll encapsulate the code\n#   I prototyped above into this function.\ndef make_choropleth(df, level1, level2, title, colors=COLORS):\n    \"\"\"Generates a choropleth with tooltips\n\n    Args:\n        df:        The DataFrame containing the relevant data. df should be\n                 formatted such that it has a 2 level column-header\n        level1:    The top column-header name (eg '2015' in examples above)\n        level2:    The next-lower column header name (eg 'Male)\n        title:     A title for the Choropleth\n        colors:    An ordered list of color codes to use in mapping data.\n    \"\"\"\n    state_names = []\n    data = []\n    min_val = df.loc[:,level1][level2].min()\n    max_val = df.loc[:,level1][level2].max()\n    bins = len(colors)\n    TOOLS = \"pan,wheel_zoom,reset,hover,save\"\n    for state_code in states:\n        try:\n            num_imprisoned = df.loc[state_code,level1][level2]\n            state_names.append(state_code)\n            data.append(num_imprisoned)\n        except KeyError:\n            state_names.append(' ')\n            data.append(0)\n\n    # Loading up Bokeh's special data structure\n    source = ColumnDataSource(data=dict(\n        x=state_xs,\n        y=state_ys,\n        name=state_names,\n        imp_count = data\n    ))\n\n    # Maps the data value to a color\n    color_mapper = LinearColorMapper(palette=colors,\n                                     low=min(data),\n                                     high=max(data))\n\n    # Instantiating the figure\n    p = figure(\n        title=title, toolbar_location=\"left\",\n        plot_width=800, plot_height=450, tools=TOOLS\n    )\n\n    # Plotting the state-polygons on the figure\n    p.patches('x', 'y', source=source,\n              fill_color={'field': 'imp_count',\n                          'transform': color_mapper},\n              fill_alpha=1.0,\n              line_color=\"#884444\",\n              line_width=2,\n              line_alpha=0.3)\n\n    # Setting the legend for colors\n    color_bar = ColorBar(color_mapper=color_mapper,\n                         ticker=BasicTicker(),\n                         label_standoff=12,\n                         border_line_color=None,\n                         location=(0,0))\n\n    p.add_layout(color_bar, 'right')\n    hover = p.select_one(HoverTool)\n    hover.point_policy = \"follow_mouse\"\n    hover.tooltips = [\n        (\"State\", \"@name\"),\n        (\"Imprisonment rate (per 100k state pop)\", \"@imp_count\")\n    ]\n    output_notebook()\n    show(p)"
  },
  {
    "objectID": "posts/011_crime_and_prisons_p2/Crime_and_Prisons_part2.html#visualization-breakthrough",
    "href": "posts/011_crime_and_prisons_p2/Crime_and_Prisons_part2.html#visualization-breakthrough",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 2",
    "section": "3.2 Visualization Breakthrough!",
    "text": "3.2 Visualization Breakthrough!\nNow that we’ve normalized the number of imprisoned people to the state populations, we can compare rates between states. From looking at these choropleths, it’s clear that there are massive differences between states. ### Observations * For both men and women over the two included years, Massachusetts has the lowest imprisonment rates (below 145 men per 100k state male pop. and below 10 women per 100k state female pop). * For men, Louisiana has the highest imprisonment rate (at least 740 men per 100k state male pop.). * Delaware stands out as having a much higher imprisonment rate that its neighbors. Delaware imprisons at least 660 men per 100k state male pop., which is 2 to 3 times more than any neighboring state. * Oklahoma has the highest imprisonment rate for women at over 75 womek per 100k state female pop. * In general, southern states have higher male imprisonment rates than the north. * Except for Delaware, New England and the Midwest have lower than average female imprisonment rates. * Bokeh’s built-in state geometries are convenient, but they’re not great (just look at Michigan and the Great Lakes).\n\n\nCalling our Choropleth-plotting function\ntitle = \"Number of Imprisoned Females per 100k Female State Population (2015)\"\nmake_choropleth(state_sex_join_df, '2015', 'Female_rate', title)\n\n\n\n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\n\n\n\n    \n\n\n\n\n\n\n\n\nCalling our Choropleth-plotting function\ntitle = \"Number of Imprisoned Females per 100k Female State Population (2016)\"\nmake_choropleth(state_sex_join_df, '2016', 'Female_rate', title)\n\n\n\n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\n\n\n\n    \n\n\n\n\n\n\n\n\nCalling our Choropleth-plotting function\ntitle = \"Number of Imprisoned Males per 100k State Male Population (2015)\"\nmake_choropleth(state_sex_join_df, '2015', 'Male_rate', title)\n\n\n\n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\n\n\n\n    \n\n\n\n\n\n\n\n\nCalling our Choropleth-plotting function\ntitle = \"Number of Imprisoned Males per 100k State Male Population (2016)\"\nmake_choropleth(state_sex_join_df, '2016', 'Male_rate', title)\n\n\n\n    \n        \n        Loading BokehJS ..."
  },
  {
    "objectID": "posts/011_crime_and_prisons_p2/Crime_and_Prisons_part2.html#state-imprisonment-distributions-by-gender",
    "href": "posts/011_crime_and_prisons_p2/Crime_and_Prisons_part2.html#state-imprisonment-distributions-by-gender",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 2",
    "section": "3.3 State Imprisonment Distributions by Gender ",
    "text": "3.3 State Imprisonment Distributions by Gender \nFrom the choropleths above (and from the prior notebook), we see that women are imprisoned at a far lower rate than men. But how does the ratio of female-to-male imprisonment rates vary by state?\nWe could get a sense of that by checking values between different states in same-year-different-gender choropleths above, but that’s slow and difficult, which means it’s a bad way to visualize this data. Scatter plots are much better at visualizing ratios for many different cases, and histograms are much better at quickly expressing the distribution of many observations of a single data feature (eg male imprisonment rates across states).\n\n\nEncapsulating Seaborn plot-generating code in a function\ndef plot_male_v_female_by_state_sea(yr, df):\n    with sns.axes_style(\"darkgrid\"):\n        tmp_df = df.loc[:,(yr, ['Male_rate','Female_rate'])][yr]\n        g = sns.JointGrid(x=\"Male_rate\", y=\"Female_rate\", data=tmp_df, size=8) \n        g.plot_joint(sns.regplot, order=2) \n        g.plot_marginals(sns.distplot)\n        plt.subplots_adjust(top=0.93)\n        title = 'Female vs Male State Imprisonment Rates in {}'.format(yr)\n        g.fig.suptitle(title, fontsize=16)\n        g.set_axis_labels('Male Imprisonment Rate [per 100k State male pop.]',\n                          'Female Imprisonment Rate [per 100k State female pop.]', \n                          fontsize=13)\n\n\n\n3.3.1 Static Scatter Plots with Distributions \nThe plots below (Seaborn’s JointGrid layout) combine both of these plots into a single visualization.\nFor both 2015 and 2016, we see that the bulk of imprisonment rates for women fall between 15 and 60 per 100k of respective state female population with a median rate of about 32 (per 100k state female pop.) and the bulk of imprisonment rates for men fall between 100 and 500 per 100k of respective state male pop. with a median rate around 350 (per 100k state male pop.).\nWe also see that there’s a fairly linear trend between the ratios of female-to-male imprisonment rates, meaning states that have a high male imprisonment rate also have a high female imprisonment rate, which could indicate that states’ criminal justice systems are consistent in how they treat women relative to how they treat men, or it could indicate actual differences in the rates at which men and women commit crime in different states. We would have to gather and explore more detailed data to explore these questions and possibly identify causal relationships.\n\n\nCalling our plotting function to plot data for 2016 and 2016\nplot_male_v_female_by_state_sea('2015', state_sex_join_df)\nplot_male_v_female_by_state_sea('2016', state_sex_join_df)\n\n\n/home/matt/miniconda3/envs/prisons_post_env/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n\n\n\n\n\n\n\n\n\n\nEncapsulating Bokeh plot-generating code in a function\ndef plot_male_v_female_by_state(yr, df):\n    mf_df = df.loc[:,(yr, ['Male_rate','Female_rate'])][yr]\n    cdf = ColumnDataSource(mf_df)\n    p = figure(plot_height=500, plot_width=500, tools=\"\", toolbar_location=None,\n               title=\"Female Imprisonment Rates vs Male Imprisonment Rates in {}\"\n               .format(yr))\n    p.background_fill_color=\"#f5f5f5\"\n    p.grid.grid_line_color=\"white\"\n    p.xaxis.axis_label = 'Male Imprisonment Rate [per 100k State male pop.]'\n    p.yaxis.axis_label = 'Female Imprisonment Rate [per 100k State female pop.]'\n    p.scatter(x='Male_rate',\n              y='Female_rate',\n              source=cdf,\n              fill_alpha=0.6,\n              size=12,\n              line_color=None)\n\n    p.add_tools(HoverTool(\n        tooltips=[\n            ('State', '@Code'),\n            ('Male Rate', '@Male_rate'),\n            ('Female Rate', '@Female_rate'),\n        ],\n    ))\n\n    output_notebook()\n    show(p)\n\n\n\n\n3.3.2 Interactive Scatter Plots \nThe plots above also show a regression curve that appears to deflect downward near the high end of the male imprisonment rates (mildly for 2015, and more significantly in 2016). From inspection, we see the state with the highest male imprisonment rate has a fairly average female imprisonment rate. From the choropleths above, we could (correctly) guess that this is Louisiana, but this highlights the fact that we have to cross-reference other data to identify the states, but that’s inconvenient if you’re just reading through this notebook on NBViewer. So I’ll replicate these plots with a library that allows me to reveal more information when you hover over a data point.\nNow we can confirm the outlier data point is Louisiana. You can also see that, in 2015, Alaska (AK) had the highest female imprisonment rate, which was not revealed in the choropleth maps above because I removed Alaska and Hawaii to make the maps more compact. Comparing between years, we can see that Alaska’s imprisonment rates for both men and women dropped significantly while the ratio remained fairly average.\n\n\nCalling our plotting function to plot data for 2016 and 2016\nplot_male_v_female_by_state('2015', state_sex_join_df)\nplot_male_v_female_by_state('2016', state_sex_join_df)\n\n\n\n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\n\n\n\n    \n\n\n\n\n\n\n\n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\n\n\n\n    \n\n\n\n\n\n\n\n\n3.3.3 Summary \nGood visualizations allow us to quickly see interesting trends and outliers that would otherwise be hidden in data. For example, while it is somewhat useful to know where the bulk of prisoners are located (Texas, California, and Florida), it’s more useful and interesting to see this data after we’ve controlled for state population. Interestingly, we see that Louisiana has a significantly higher imprisonment rate than any other state. Knowing this, we can target further research and questions about this. Per some brief independent research, I’ve found that Louisiana is one of two states that allow people to be convicted of felonies when only 10 of 12 jurors agree on guilt. This lower bar for conviction may be one of several causal factors driving Louisiana’s imprisonment rate, but it will take more data and research to strengthen that hypothesis."
  },
  {
    "objectID": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html",
    "href": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 1",
    "section": "",
    "text": "Update Note\n\n\n\n\n\nThe majority of code and analysis in this post was originally written back in mid-2018 (in this notebook). I’ve consolidated some cells, automated data retrieval, and added cell labels to make things render nicely, but otherwise I’ve left the work as-is. Compared to my current work products, this old code is very messy and unpolished, but like Eric Ma (creator of the networkx graph data analysis package), I believe in showing newer data analysts and scientists I mentor that no one in this field started off with mastery of git, pandas, bash, etc, and that everyone who lasts loves to keep learning and improving.\nAfter I integrate these old posts into this blog, I’ll write an EDA post that starts from scratch using up-to-date data."
  },
  {
    "objectID": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#table-of-contents",
    "href": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#table-of-contents",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 1",
    "section": "1.1 Table of Contents",
    "text": "1.1 Table of Contents\n\nExploration in Criminal Justice and Corrections Data\nDatasets\nTotal Imprisonment Rates 3a. Observations\nImprisonment by Race 4a. Observations\nImprisonment by Gender 5a. Observations\nTo Be Continued"
  },
  {
    "objectID": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#datasets",
    "href": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#datasets",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 1",
    "section": "1.2 Datasets ",
    "text": "1.2 Datasets \nWith some questions in hand, I can start trying to gather data that could shed light on the situation. I may not be able to get data with the resolution needed to answer some of these questions (eg I may not be able to find data broken down by month).\nThe government makes some data publicly available. While government data is rarely current, often involves a bit of cleanup, and always involves hunting through old government sites, it’s the only source for much of this extremely valuable information. From the Bureau of Justice Statistics, I found a government project called the Prisoner Series and I downloaded the most recent data.\n\n\nImports, styling, and path definition\nimport os\nfrom urllib.request import urlretrieve\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nfrom IPython.core.display import display, HTML\n%matplotlib inline\n\n# Notebook Styling\npd.options.display.float_format = lambda x: \"%.5f\" % x\npd.options.display.max_columns = None\nplt.rcParams['figure.figsize'] = 10,10\n\n\nDATA_DIR_PATH = os.path.join('data', 'prison')\nos.makedirs(DATA_DIR_PATH, exist_ok=True)\n\n@ticker.FuncFormatter\ndef y_formatter(x, pos):\n    return '{:4.0f}'.format(x/1000)"
  },
  {
    "objectID": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#total-imprisonment-rates-table-p16f01",
    "href": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#total-imprisonment-rates-table-p16f01",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 1",
    "section": "1.3 Total Imprisonment Rates (Table p16f01) ",
    "text": "1.3 Total Imprisonment Rates (Table p16f01) \nThe values in the by-race dataset are [per 100k population].\n\n\nDownloading the relevant data and unzipping it\nimport zipfile\nimport requests\n\nurl = \"https://bjs.ojp.gov/redirect-legacy/content/pub/sheets/p16.zip\"\nfile_path = os.path.join(DATA_DIR_PATH, \"p16.zip\")\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n}\n\nif not os.path.isfile(file_path):\n    response = requests.get(url, headers=headers, stream=True)\n    if response.status_code == 200:\n        with open(file_path, \"wb\") as file:\n            for chunk in response.iter_content(chunk_size=1024):\n                if chunk:\n                    file.write(chunk)\n\n    with zipfile.ZipFile(file_path, 'r') as zf:\n        zf.extractall(DATA_DIR_PATH)\n\n\n\n\nLoading and preprocessing the f01 dataset, Total Counts\nCSV_PATH = os.path.join('data', 'prison', 'p16f01.csv')\ntotal_df = pd.read_csv(CSV_PATH, encoding='latin1', header=12, index_col='Year', parse_dates=['Year'])\ntotal_df.dropna(inplace=True)\ntotal_df.index = total_df.index.values.astype(int)\n\n\n\nprint(total_df.shape)\ntotal_df.head()\n\n(39, 2)\n\n\n\n\n\n\n\n\n\nAll ages\nAge 18 or older\n\n\n\n\n1978\n131.00000\n183.00000\n\n\n1979\n133.00000\n185.00000\n\n\n1980\n138.00000\n191.00000\n\n\n1981\n153.00000\n211.00000\n\n\n1982\n170.00000\n232.00000\n\n\n\n\n\n\n\n\n\nPlotting out the f01 data\nwith sns.axes_style(\"whitegrid\"):\n    fig, ax = plt.subplots(figsize=(10,7))\n    ax.plot(total_df['All ages'])\n    ax.plot(total_df['Age 18 or older'])\n    ax.set_title('Total Imprisonment Rates (table: p16f01)')\n    ax.set_xlabel('Year')\n    ax.set_ylabel('People imprisoned (per relevant 100k US population)')\n    ax.legend()\n    ax.set_ylim([0, 1.1*max([total_df['All ages'].max(), \n                             total_df['Age 18 or older'].max()])])"
  },
  {
    "objectID": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#observations",
    "href": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#observations",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 1",
    "section": "1.4 Observations ",
    "text": "1.4 Observations \nThe imprisonment rate normalized to the entire population of US residents is lower than the imprisonment rate normalized to the population of US residents that are 18 or older. This indicates that the imprisonment rate for people under age 18 is much lower than for people 18 or older. That fits with my intuition.\nWe also see that the imprisonment rate climbs steadily from 1980 up through 1999, dips, and peaks around 2007-2008, at which point it starts trending down. In 1978, 183 people were in prison per every 100k US residents 18 or older. In 2007, 670 people were in prison per every 100k US residents 18 or older. That’s a 266% increase in the imprisonment rate over that 29 year span. That’s huge.\n\n1.4.1 New Questions:\n\nWhat was responsible for the increase in the rate of imprisonment? What was responsible for the decrease?\n\nWas it proportional to the actual crime rates?\nWas it a product of different enforcement policies?\n\n\nTo answer these new questions, we will probably have to look at other sets of data."
  },
  {
    "objectID": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#imprisonment-by-race-table-p16f02",
    "href": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#imprisonment-by-race-table-p16f02",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 1",
    "section": "1.5 Imprisonment by Race (Table p16f02) ",
    "text": "1.5 Imprisonment by Race (Table p16f02) \nImprisonment rate of sentenced prisoners under the jurisdiction of state or federal correctional authorities, per 100,000 U.S. residents age 18 or older, by race and Hispanic origin, December 31, 2006–2016\n\n\nLoading and preprocessing the f02 data, Counts by Race\nCSV_PATH = os.path.join('data', 'prison', 'p16f02.csv')\nrace_df = pd.read_csv(CSV_PATH, encoding='latin1', header=12)\nrace_df.dropna(inplace=True)\nrace_df.rename(columns={'Unnamed: 0': 'Year'}, inplace=True)\nrace_df.set_index('Year', inplace=True)\nrace_df\n\n\n\n\n\n\n\n\n\nWhite/*\nBlack/*\nHispanic\n\n\nYear\n\n\n\n\n\n\n\n2006\n324.00000\n2261.00000\n1073.00000\n\n\n2007\n317.00000\n2233.00000\n1094.00000\n\n\n2008\n316.00000\n2196.00000\n1057.00000\n\n\n2009\n308.00000\n2134.00000\n1060.00000\n\n\n2010\n307.00000\n2059.00000\n1014.00000\n\n\n2011\n299.00000\n1973.00000\n990.00000\n\n\n2012\n293.00000\n1873.00000\n949.00000\n\n\n2013\n291.00000\n1817.00000\n922.00000\n\n\n2014\n289.00000\n1754.00000\n893.00000\n\n\n2015\n281.00000\n1670.00000\n862.00000\n\n\n2016\n274.00000\n1608.00000\n856.00000\n\n\n\n\n\n\n\n\n\nPlotting out the f02 data, Counts by Race\nwith sns.axes_style(\"whitegrid\"):\n    fig, ax = plt.subplots(figsize=(10,7))\n    ax.plot(race_df['White/*'])\n    ax.plot(race_df['Black/*'])\n    ax.plot(race_df['Hispanic'])\n    ax.set_title('Imprisonment Rates by Race (table: p16f02)')\n    ax.set_xlabel('Year')\n    ax.set_ylabel('People imprisoned (per 100k US population)')\n    ax.legend()\n    ax.set_ylim([0, 1.1*max([race_df['White/*'].max(), \n                         race_df['Black/*'].max(), \n                         race_df['Hispanic'].max()])])\n\n\n\n\n\n\n\nPrinting out summary stats for f02 data, Counts by Race\nprint('{:&gt;8s} imprisonment per 100k US pop: max: {}, min: {}'\n      .format('White/*', race_df['White/*'].max(), race_df['White/*'].min()))\nprint('{:&gt;8s} imprisonment per 100k US pop: max: {}, min: {}'\n      .format('Black/*', race_df['Black/*'].max(), race_df['Black/*'].min()))\nprint('{:&gt;8s} imprisonment per 100k US pop: max: {}, min: {}'\n      .format('Hispanic', race_df['Hispanic'].max(), race_df['Hispanic'].min()))\nprint('*: non-Hispanic')\n\n\n White/* imprisonment per 100k US pop: max: 324.0, min: 274.0\n Black/* imprisonment per 100k US pop: max: 2261.0, min: 1608.0\nHispanic imprisonment per 100k US pop: max: 1094.0, min: 856.0\n*: non-Hispanic"
  },
  {
    "objectID": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#observations-1",
    "href": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#observations-1",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 1",
    "section": "1.6 Observations ",
    "text": "1.6 Observations \nThis is very striking. We see that there is a very significant difference in the rates of white (non-Hispanic), black (non-Hispanic), and Hispanic imprisonment. We also see that rates for all three have dropped over this time period.\n\n1.6.1 New Questions:\n\nWhat is responsible for this difference in imprisonment rates for different demographic groups?\n\nBased on prior research, I suspect that this is the result of many systemic factors, but let’s continue exploring the data."
  },
  {
    "objectID": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#breakdown-by-gender-table-p16t01",
    "href": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#breakdown-by-gender-table-p16t01",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 1",
    "section": "1.7 Breakdown by Gender (Table p16t01) ",
    "text": "1.7 Breakdown by Gender (Table p16t01) \n\n\nLoading and preprocessing the t01 data, Total Counts by Gender and State/Federal\nCSV_PATH = os.path.join('data', 'prison', 'p16t01.csv')\nsex_df = pd.read_csv(CSV_PATH, encoding='latin1', header=11, thousands=r',')\nsex_df.dropna(inplace=True, thresh=3)\nsex_df.dropna(inplace=True, axis=1, thresh=3)\nsex_df.dropna(inplace=True)\nfix = lambda x: x.split('/')[0]\nsex_df['Year'] = sex_df['Year'].apply(fix)\nsex_df['Year'] = sex_df['Year'].astype(int)\nsex_df.set_index('Year', inplace=True)\nsex_df\n\n\n\n\n\n\n\n\n\nTotal\nFederal/a\nState\nMale\nFemale\n\n\nYear\n\n\n\n\n\n\n\n\n\n2006\n1568674.00000\n193046.00000\n1375628.00000\n1456366.00000\n112308.00000\n\n\n2007\n1596835.00000\n199618.00000\n1397217.00000\n1482524.00000\n114311.00000\n\n\n2008\n1608282.00000\n201280.00000\n1407002.00000\n1493670.00000\n114612.00000\n\n\n2009\n1615487.00000\n208118.00000\n1407369.00000\n1502002.00000\n113485.00000\n\n\n2010\n1613803.00000\n209771.00000\n1404032.00000\n1500936.00000\n112867.00000\n\n\n2011\n1598968.00000\n216362.00000\n1382606.00000\n1487561.00000\n111407.00000\n\n\n2012\n1570397.00000\n217815.00000\n1352582.00000\n1461625.00000\n108772.00000\n\n\n2013\n1576950.00000\n215866.00000\n1361084.00000\n1465592.00000\n111358.00000\n\n\n2014\n1562319.00000\n210567.00000\n1351752.00000\n1449291.00000\n113028.00000\n\n\n2015\n1526603.00000\n196455.00000\n1330148.00000\n1415112.00000\n111491.00000\n\n\n2016\n1505397.00000\n189192.00000\n1316205.00000\n1393975.00000\n111422.00000\n\n\n\n\n\n\n\n\n\nPlotting out the t01 data\nwith sns.axes_style(\"whitegrid\"):\n    fig, ax = plt.subplots(figsize=(10,7))\n    ax.plot(sex_df['Male'])\n    ax.plot(sex_df['Female'])\n    ax.set_title('Imprisonment Counts by Gender (table: p16t01)')\n    ax.set_xlabel('Year')\n    ax.yaxis.set_major_formatter(y_formatter)\n    ax.set_ylabel('People Imprisoned [in thousands of people]')\n    ax.legend()\n    ax.set_ylim([0, 1.1*max(sex_df['Male'].max(),\n                            sex_df['Female'].max())])"
  },
  {
    "objectID": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#observations-2",
    "href": "posts/010_crime_and_prisons_p1/Crime_and_Prisons_part1.html#observations-2",
    "title": "Exploration in Criminal Justice and Corrections Data, Part 1",
    "section": "1.8 Observations ",
    "text": "1.8 Observations \nThe first thing that I notice is that the number of men in prison is much higher than the number of females imprisoned. Per the chart below, over the entire span of the data set (2006 to 2016), there are at least 12 men in prison for each woman in prison. This is a massive asymmetry. It doesn’t feel very controversial, but should it? According to the 2010 US Census, the US population is 50.8% female and 49.2% male.\n\n1.8.1 New Questions\n\nWhy are men so much more likely to be in prison?\n\nWhat are the relevant differences between men and women?\nWhat is the gender breakdown of crimes?\n\n\n\n\nPlotting out Male to Female imprisonment ratio\nsex_df['m_f_ratio'] = sex_df['Male'] / sex_df['Female']\nwith sns.axes_style(\"whitegrid\"):\n    fig, ax = plt.subplots(figsize=(7,5))\n    ax.plot(sex_df['m_f_ratio'])\n    ax.set_title('Male to Female Imprisonment Ratio (table: p16t01)')\n    ax.set_xlabel('Year')\n    ax.set_ylabel('Average Number of Males imprisoned per Female')\n    ax.legend()\n    ax.set_ylim([0, 1.1*sex_df['m_f_ratio'].max()])\n\n\n\n\n\n\n\nPlotting out Counts of State and Federal imprisonment\nwith sns.axes_style(\"whitegrid\"):\n    fig, ax = plt.subplots(figsize=(10,7))\n    ax.plot(sex_df['Federal/a'])\n    ax.plot(sex_df['State'])\n    ax.set_title('Imprisonment Counts in State and Federal Prisons (table: p16t01)')\n    ax.set_xlabel('Year')\n    ax.yaxis.set_major_formatter(y_formatter)\n    ax.set_ylabel('People Imprisoned [in thousands of people]')\n    ax.legend()\n    ax.set_ylim([0, 1.1*max(sex_df['Federal/a'].max(),\n                            sex_df['State'].max())])\n\n\n\n\n\n\n\n1.8.2 Observations\nFar more people are in State prisons than are in Federal prisons. That isn’t very controversial and at this level, I won’t dig much deeper. It may be interesting to dig further into imprisonment counts broken down by state."
  }
]