{
 "cells": [
  {
   "cell_type": "raw",
   "id": "103816b3-4b1c-4b9a-9672-f5ee597d5bee",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Midjourney Experiments\"\n",
    "description: \"A full tutorial of a basic workflow\"\n",
    "author: \"Matt Triano\"\n",
    "date: \"07/01/2023\"\n",
    "date-modified: \"07/07/2023\"\n",
    "draft: false\n",
    "image: \"pip_setting_(up)_Great_Expectations.png\"\n",
    "categories: [generative AI, midjourney, prompt eng]\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    code-fold: true\n",
    "    code-tools: true\n",
    "jupyter:\n",
    "  kernelspec:\n",
    "    name: \"quarto_env\"\n",
    "    language: \"python\"\n",
    "    display_name: \"quarto_env\"\n",
    "execute:\n",
    "  freeze: true\n",
    "  cache: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a0df3-4f10-425f-b1a7-97ed8ff79e08",
   "metadata": {},
   "source": [
    "Over the past decade, the field of generative AI has made amazing progress. Driven by breakthrough advances in machine learning modeling strategies (primarily the GAN [^0] in 2014 and the Transformer [^1] in 2017) coupled with exponential growth of the amount of available computing power [^2], generative AI applications started appearing in the late 2010s.  drove this progress and enabled \n",
    "\n",
    "Over the past year, generative AI has transitioned from a \n",
    "\n",
    "https://huggingface.co/spaces\n",
    "\n",
    "![midjourney search frequency](GoogleTrends_Midjourney.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51adb87-5430-42e1-9adf-2b412f8429ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a52981-8a0f-4700-af82-f450e2cb12c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c61c68-4668-4d76-9477-25cbf2830693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4745204-4d6c-4a66-b1e5-310f1d1d409f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae096d9-edd1-48ab-82fe-9ceb73856c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8500cff-3dd7-4073-94b2-9634977a9361",
   "metadata": {},
   "source": [
    "[^0]: Ian Goodfellow et. al's paper (2014) presenting the [Generative Adversarial Network](https://arxiv.org/pdf/1406.2661.pdf) (or GAN) deep learning model architecture.\n",
    "\n",
    "[^1]: Google's famous [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf) paper (2017) which presented the Transformer deep learning model architecture.\n",
    "\n",
    "[^2]: OpenAI's [2018 analysis](https://openai.com/research/ai-and-compute) of available computing power (or \"compute\") and the amount of compute needed to train models.\n",
    "\n",
    "[^3]: https://www.thispersondoesnotexist.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(quarto_env)",
   "language": "python",
   "name": "quarto_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
