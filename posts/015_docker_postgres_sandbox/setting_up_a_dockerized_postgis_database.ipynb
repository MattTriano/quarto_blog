{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6fcb2eb0-40d2-4b2f-81cc-e2fcca53000c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"How to set up and play with a Postgres db using Docker\"\n",
    "description: \"A full tutorial of a basic workflow\"\n",
    "author: \"Matt Triano\"\n",
    "date: \"08/01/2023\"\n",
    "date-modified: \"08/01/2023\"\n",
    "draft: false\n",
    "image: \"imgs/postgres_container.png\"\n",
    "categories: [docker, Postgres, PostGIS, sandbox, tutorial]\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    code-fold: true\n",
    "    code-tools: true\n",
    "jupyter:\n",
    "  kernelspec:\n",
    "    name: \"quarto_env\"\n",
    "    language: \"python\"\n",
    "    display_name: \"quarto_env\"\n",
    "execute:\n",
    "  freeze: true\n",
    "  cache: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119a942d-f182-4d43-b2dc-a7a03f9eacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76587b11-9e14-4069-aae3-c36ff7823fc1",
   "metadata": {},
   "source": [
    "# The importance of sandboxes\n",
    "\n",
    "I've worked with SQL regularly over the past decade, but over the first half of that decade (and despite extensive formal knowledge of normalization, data modeling, and other database-related topics) I essentially only used SQL to extract data and use Python or R to do analysis. I only had access to production databases and I didn't know enough about how database management system work to risk experiments, and as a result, I learned at a glacial pace. But in 2018, I stumbled into a project interesting enough to motivate me to install PostGIS on a personal machine and freed from the fear of accidentally taking down a production system (and the power of a superuser), I was able to lift up the hood and see how the machine worked, and this enabled me to learn and build with Postgres + PostGIS (a geospatial Postgres extension) far faster.\n",
    "\n",
    "In this post, I show how to use Docker to set up a PostGIS database and experiment with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6dfb6-0314-4565-9c49-2aca6865cc84",
   "metadata": {},
   "source": [
    "## What is Docker\n",
    "\n",
    "Docker and Docker Compose[^1] enable you to import and run complicated applications in just a few lines of code.\n",
    "\n",
    "The internals of docker are really interesting, but for this post, all you need to know these things:\n",
    "\n",
    "1. A docker **image** is like a blueprint of an application, and it's defined in **Dockerfiles**.\n",
    "2. A docker **container** is a runnable instance of the application, built from the instructions in the blueprint.\n",
    "3. You can configure your application in a `docker-compose.yml` file.\n",
    "\n",
    "### Our Dockerfile\n",
    "The first one may sound complicated, as the contents of our Dockerfile show, this can only take one line of code (from us). That's possible because Dockerfiles can build an image based on another image, and the developers of many open source projects (e.g. Ubuntu, PostgreSQL/PostGIS, MySQL, Go, nginx, etc) public official images on [Docker Hub](https://registry.hub.docker.com/search?q=). Our Dockerfile pulls the [postgis/postgis image](https://registry.hub.docker.com/r/postgis/postgis) (translated, it pulls the `postgis` base image from the `postgis` organization), and then adds nothing else. So in one line, we indicate that we want the `postgis/postgis` image that has the tag \"15-3.3\" (which they've intuitively used to indicate the image provides a PostGIS database that has version 15-3.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffa04f3-90eb-43be-844a-2d4859681bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM postgis/postgis:15-3.3"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: The full contents of our Dockerfile\n",
    "\n",
    "!cat db_context/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a786b470-0572-4d2c-9b36-9d3dab815a1e",
   "metadata": {},
   "source": [
    "### Our docker-compose.yml file\n",
    "\n",
    "And this is our `docker-compose.yml` file. The `docker-compose.yml` file defines the services, and any networks, volumes, configs, and/or secrets/environment variables your system needs to work. The file below defines one service (named `postgis`) and one volume (named `sandbox_postgis_data`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5d9e97-e3c0-4597-a7f7-5adc4ab37274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: '3.9'\n",
      "\n",
      "services:\n",
      "  postgis:\n",
      "    image: sandbox_postgis:15.3.3\n",
      "    build:\n",
      "      context: ./db_context\n",
      "      dockerfile: Dockerfile\n",
      "    ports:\n",
      "      - 54321:5432\n",
      "    environment:\n",
      "      POSTGRES_DB: db_name\n",
      "      POSTGRES_USER: db_username\n",
      "      POSTGRES_PASSWORD: db_password\n",
      "    volumes:\n",
      "      - sandbox_postgis_data:/var/lib/postgresql/data\n",
      "\n",
      "volumes:\n",
      "  sandbox_postgis_data:\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: The contents of our docker-compose.yml\n",
    "\n",
    "!cat docker-compose.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8a0475-81a2-41d7-97fc-2f0ae9b12466",
   "metadata": {},
   "source": [
    "There are 3 top level elements in this file: `version`, `services`, and `volumes`.\n",
    "\n",
    "* `version` indicates the version of the Docker Compose specification; I don't think I've ever set it to anything other than 3.9.\n",
    "* `services` defines configurations for each container your system needs.\n",
    "* `volumes` defines persistent data stores that can be shared by different services.\n",
    "\n",
    "#### Services\n",
    "The `postgis` service has five elements: `image`, `build`, `ports`, `environment`, and `volumes`.\n",
    "\n",
    "The `image` and `build` elements define the docker image to use; `image` defines both the name (\"sandbox_postgis\") and tag (\"15.5.3\") for the docker image, and `build` defines the Dockerfile to build into an image as well as the context to build into the docker image.\n",
    "\n",
    "The `port` element defines a connection from a port on the host machine (host post 54321) to a port into the container (container port 5432, the default for PostgreSQL). We'll use that later to connect to the database.\n",
    "\n",
    "The `volumes` element (in the `postgis` service) defines a persistent storage volume that will hold the data in our database. Without this, our database would reset every time we restart the system[^2].\n",
    "\n",
    "And the `environment` element enables you to set environment variables in the container. Here, we pass in environment variables `POSTGRES_DB`, `POSTGRES_USER`, and `POSTGRES_PASSWORD` which are used to name the database (in this case, it's named `db_name`) and create a superuser (in this case having username `db_username` and password `db_password`) when the database is first created in a new volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d4183-2715-4414-9c0c-64225fa8ba30",
   "metadata": {},
   "source": [
    "### Building the image(s) used in our system\n",
    "\n",
    "The first time you build the image defined by your Dockerfile, docker will read your Dockerfile(s), download all layers of the base image(s) (defined in lines starting with `FROM `), process each subsequent instruction into a layer, cache layers, and then bind the layers into an image. This is a template for creating containers.\n",
    "\n",
    "The second time you run this command (assuming no changes have been made to the `docker-compose.yml` file, Dockerfile(s), or any other files the Dockerfile references), all layers will just be pulled from cache, producing much smaller output (like what's shown below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a35f5412-2ddf-41ed-b817-08be4f72302f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                                         \n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (2/3)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (3/4)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.3s\n",
      "\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (3/4)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.4s\n",
      "\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (3/4)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.7s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  0.1s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d7 0B / 32B  0.1s\n",
      "\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  0.3s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea59112599342876 0B / 67.45MB  0.2s\n",
      " => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b44290e 0B / 553B  0.2s\n",
      " => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e8e 0B / 589B  0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.0s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  0.4s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934 7.34MB / 67.45MB  0.4s\n",
      "\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  0.6s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 28.31MB / 67.45MB  0.5s\n",
      "\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.3s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  0.7s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 48.23MB / 67.45MB  0.7s\n",
      "\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.4s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  0.8s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 58.72MB / 67.45MB  0.8s\n",
      "\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.5s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  0.9s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.7s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  1.1s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  0.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.8s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  1.2s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.9s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  1.3s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.0s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  1.4s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  0.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.1s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  1.5s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.2s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  1.6s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  0.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.3s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  1.7s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  0.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.5s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  1.9s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  0.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.6s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  2.0s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  1.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.7s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  2.1s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  1.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.8s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  2.2s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  1.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.0s (4/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  2.3s\n",
      "\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  1.3s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6  0.0s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b44290  0.0s\n",
      "\u001b[0m => => extracting sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e8  0.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.1s (5/5)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m\u001b[34m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  2.5s\n",
      "\u001b[0m\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  1.3s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6  0.0s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b44290  0.0s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e8  0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.2s (6/6)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m\u001b[34m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  2.5s\n",
      "\u001b[0m\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  1.3s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6  0.0s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b44290  0.0s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e8  0.0s\n",
      "\u001b[0m\u001b[34m => [postgis] exporting to image                                           0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:1460a9b1410a939c0fd0035d534c14cd5fb7d051c13a4  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/sandbox_postgis:15.3.3                  0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.4s (6/6)                                                         \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m\u001b[34m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  2.5s\n",
      "\u001b[0m\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  1.3s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6  0.0s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b44290  0.0s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e8  0.0s\n",
      "\u001b[0m\u001b[34m => [postgis] exporting to image                                           0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:1460a9b1410a939c0fd0035d534c14cd5fb7d051c13a4  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/sandbox_postgis:15.3.3                  0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.4s (6/6) FINISHED                                                \n",
      "\u001b[34m => [postgis internal] load build definition from Dockerfile               0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 64B                                        0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load .dockerignore                                  0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [postgis internal] load metadata for docker.io/postgis/postgis:15-3.3  0.6s\n",
      "\u001b[0m\u001b[34m => [postgis auth] postgis/postgis:pull token for registry-1.docker.io     0.0s\n",
      "\u001b[0m\u001b[34m => [postgis 1/1] FROM docker.io/postgis/postgis:15-3.3@sha256:55a733ef94  2.5s\n",
      "\u001b[0m\u001b[34m => => resolve docker.io/postgis/postgis:15-3.3@sha256:55a733ef946c4d17d4  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:55a733ef946c4d17d4e0be916921c8d3ef470adb454 3.87kB / 3.87kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:1ecd3c2c63a24e734d9acb921a51c7833266e76a8 11.90kB / 11.90kB  0.0s\n",
      "\u001b[0m\u001b[34m => => sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea591125993 67.45MB / 67.45MB  0.9s\n",
      "\u001b[0m\u001b[34m => => sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b4429 553B / 553B  0.2s\n",
      "\u001b[0m\u001b[34m => => sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e 589B / 589B  0.3s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:7d2cfa4e6fa5eaafc2b3efb9053a1bea5911259934287677  1.3s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6  0.0s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:be8f370ee13ebd74de848b635e2996aa7ec0427975b44290  0.0s\n",
      "\u001b[0m\u001b[34m => => extracting sha256:15c2d87dff059a628b45d0aaea8d5f1344735481694950e8  0.0s\n",
      "\u001b[0m\u001b[34m => [postgis] exporting to image                                           0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:1460a9b1410a939c0fd0035d534c14cd5fb7d051c13a4  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/sandbox_postgis:15.3.3                  0.0s\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: The output produced while building our images\n",
    "\n",
    "!docker compose build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1f080b-20a2-485b-8e13-7cf4bb6a9785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Shows that our system's one container is not running yet\n",
    "\n",
    "!docker ps -f name=sandbox-postgis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a85a9f-cdd8-4f84-94af-1a72e6adbf09",
   "metadata": {},
   "source": [
    "`docker ps` shows running containers, and the `-f name=...` option allows us to filter to running containers with a name containing the entered string. Currently, \"sandbox-postgis\" isn't part of the name of any running container, so let's spin one up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aade6c3d-a1b1-4daa-baa0-b207f3c0df79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 2/0\n",
      " \u001b[32m\u001b[0m Network 015_docker_postgres_sandbox_default                \u001b[32mCreated\u001b[0m      \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m\u001b[0m Volume \"015_docker_postgres_sandbox_sandbox_postgis_data\"  \u001b[32mCreated\u001b[0m      \u001b[34m0.0s \u001b[0m\n",
      "  Container 015_docker_postgres_sandbox-postgis-1            Creating     \u001b[34m0.1s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 2/3\n",
      " \u001b[32m\u001b[0m Network 015_docker_postgres_sandbox_default                \u001b[32mCreated\u001b[0m      \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m\u001b[0m Volume \"015_docker_postgres_sandbox_sandbox_postgis_data\"  \u001b[32mCreated\u001b[0m      \u001b[34m0.0s \u001b[0m\n",
      "  Container 015_docker_postgres_sandbox-postgis-1            Starting     \u001b[34m0.2s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 2/3\n",
      " \u001b[32m\u001b[0m Network 015_docker_postgres_sandbox_default                \u001b[32mCreated\u001b[0m      \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m\u001b[0m Volume \"015_docker_postgres_sandbox_sandbox_postgis_data\"  \u001b[32mCreated\u001b[0m      \u001b[34m0.0s \u001b[0m\n",
      "  Container 015_docker_postgres_sandbox-postgis-1            Starting     \u001b[34m0.3s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 2/3\n",
      " \u001b[32m\u001b[0m Network 015_docker_postgres_sandbox_default                \u001b[32mCreated\u001b[0m      \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m\u001b[0m Volume \"015_docker_postgres_sandbox_sandbox_postgis_data\"  \u001b[32mCreated\u001b[0m      \u001b[34m0.0s \u001b[0m\n",
      "  Container 015_docker_postgres_sandbox-postgis-1            Starting     \u001b[34m0.4s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 2/3\n",
      " \u001b[32m\u001b[0m Network 015_docker_postgres_sandbox_default                \u001b[32mCreated\u001b[0m      \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m\u001b[0m Volume \"015_docker_postgres_sandbox_sandbox_postgis_data\"  \u001b[32mCreated\u001b[0m      \u001b[34m0.0s \u001b[0m\n",
      "  Container 015_docker_postgres_sandbox-postgis-1            Starting     \u001b[34m0.5s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 3/3\u001b[0m\n",
      " \u001b[32m\u001b[0m Network 015_docker_postgres_sandbox_default                \u001b[32mCreated\u001b[0m      \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m\u001b[0m Volume \"015_docker_postgres_sandbox_sandbox_postgis_data\"  \u001b[32mCreated\u001b[0m      \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m\u001b[0m Container 015_docker_postgres_sandbox-postgis-1            \u001b[32mStarted\u001b[0m      \u001b[34m0.5s \u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "#| code-summary: The command to start up our system\n",
    "\n",
    "!docker compose up -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1751a35-e624-43a5-8940-78d3a903b5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                    COMMAND                  CREATED         STATUS         PORTS                                         NAMES\n",
      "7719f4732487   sandbox_postgis:15.3.3   \"docker-entrypoint.s\"   4 seconds ago   Up 3 seconds   0.0.0.0:54321->5432/tcp, :::54321->5432/tcp   015_docker_postgres_sandbox-postgis-1\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Shows that our system's one container is running now\n",
    "\n",
    "!docker ps -f name=sandbox-postgis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7afea3-d738-4995-b79c-942eacfaf67c",
   "metadata": {},
   "source": [
    "# Using our sandbox\n",
    "\n",
    "## Sending commands to our database\n",
    "Now we have our database up and running on our local system, but now we need to connect to it from this jupyter notebook. I want to focus on experimenting with SQL, so I've implemented some functions than handle connecting to the database and executing SQL queries/commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b4632b3-7c96-4655-b6a9-ed79d306593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Helper functions for our main python-to-postgres connector code\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from typing import Tuple, Union, Optional\n",
    "\n",
    "import autopep8\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "def add_indentation(query, spaces=4):\n",
    "    lines = query.splitlines()\n",
    "    indented_lines = [(\" \" * spaces) + line for line in lines]\n",
    "    indented_query = \"\\n\".join(indented_lines)\n",
    "    return indented_query\n",
    "\n",
    "def execute_query_w_existing_conn(\n",
    "    query: str, conn: psycopg2.extensions.connection\n",
    ") -> Tuple[str, Union[pd.DataFrame, None]]:\n",
    "    with conn.cursor() as cur:\n",
    "        try:\n",
    "            cur.execute(query)\n",
    "            rows = cur.fetchall()\n",
    "            col_names = [desc[0] for desc in cur.description]\n",
    "            return (cur.statusmessage, pd.DataFrame(rows, columns=col_names))\n",
    "        except psycopg2.errors.InsufficientPrivilege as err:\n",
    "            return (add_indentation(f\"\\n{err.pgerror}  Error type: {type(err)}\"), None)\n",
    "        except psycopg2.ProgrammingError as err:\n",
    "            if \"no results to fetch\" in str(err):\n",
    "                return (cur.statusmessage, None)\n",
    "            else:\n",
    "                raise psycopg2.ProgrammingError(err)\n",
    "\n",
    "def execute_query(\n",
    "    query: str, conn: Optional[psycopg2.extensions.connection] = None\n",
    ") -> Union[pd.DataFrame, None]:\n",
    "    if conn is None:\n",
    "        with get_db_connection() as new_conn:\n",
    "            return execute_query_w_existing_conn(query=query, conn=new_conn)\n",
    "    else:\n",
    "        return execute_query_w_existing_conn(query=query, conn=conn)\n",
    "\n",
    "def show_transaction_results(result: Tuple[str, str, Union[pd.DataFrame, None]]) -> None:\n",
    "    query, status, result_df = result\n",
    "    dedented_query = add_indentation(query=autopep8.fix_code(query))\n",
    "    print(f\"\"\"\\nQuery:\\n{dedented_query}\"\"\")\n",
    "    print(f\"Database response message: '{status}'\")\n",
    "    if result_df is not None:\n",
    "        print(f\"records in result: {len(result_df)}\")\n",
    "        display(result_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e808c95b-e1bf-498c-b265-5757978ee86a",
   "metadata": {},
   "source": [
    "The `get_db_connection()` function provides a connection to our database. Note that `get_db_connection()` uses the `POSTGRES_DB`, `POSTGRES_USER`, and `POSTGRES_PASSWORD` environment variables as well as port number 54321, all of which we set in our `docker-compose.yml` file.\n",
    "\n",
    "The `execute_transaction()` function takes in a string containing one or more semicolon-separated SQL queries, executes each query using the same connection, displays the query and response from the database, and returns a list containing the query, database response, and result_set for each query from the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dad16f31-91c0-48e1-9814-8e4ecc4ee8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "#| code-summary: Our thin python-to-postgres connector code\n",
    "\n",
    "@contextmanager\n",
    "def get_db_connection():\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"db_name\",\n",
    "        user=\"db_username\",\n",
    "        password=\"db_password\",\n",
    "        host=\"localhost\",\n",
    "        port=54321\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "    try:\n",
    "        yield conn\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "def execute_transaction(\n",
    "    query: str, print_results: bool = True\n",
    ") -> Tuple[str, str, Union[pd.DataFrame, None]]:\n",
    "    queries = [el.strip() for el in query.split(\";\") if el.strip() != \"\"]\n",
    "    with get_db_connection() as conn:\n",
    "        results = []\n",
    "        for q in queries:\n",
    "            status_msg, result_df = execute_query(query=q, conn=conn)\n",
    "            result = (q, status_msg, result_df)\n",
    "            results.append(result)\n",
    "            if print_results:\n",
    "                show_transaction_results(result=result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcfe6a6-e7aa-453b-ad15-33bde59a8dd5",
   "metadata": {},
   "source": [
    "## Learning exercise\n",
    "\n",
    "Imagine you're designing a data warehousing platform and you want to let other analysts or data scientists query data in the warehouse. Some users need to be able to update records or insert new records, but others only need to be able to view some datasets.\n",
    "\n",
    "PostgreSQL has a concept called [Roles](https://www.postgresql.org/docs/15/user-manag.html) that enables you to define permissions for users or groups of users. If you aren't already familiar with how roles and permissions work, you don't have a skilled database administrator looking over your work, and you only have access to a database that other systems depend on, it would be extremely intimidating to figure out the correct permissions. Our sandbox takes off that weight by eliminating the cost of mistakes.\n",
    "\n",
    "Let's create "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb2652a-7ef1-4f25-a633-2663c38556b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    DROP SCHEMA raw_data CASCADE\n",
      "Database response message: 'DROP SCHEMA'\n",
      "\n",
      "Query:\n",
      "    DROP SCHEMA clean_data CASCADE\n",
      "Database response message: 'DROP SCHEMA'\n"
     ]
    }
   ],
   "source": [
    "# CLEANUP_CODE\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        DROP SCHEMA raw_data CASCADE;\n",
    "        DROP SCHEMA clean_data CASCADE;\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d5a05c5a-6c28-4ab8-a808-cf55ddc27129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3028bf0-a38c-4aa1-b853-3df3738c3d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    CREATE SCHEMA raw_data\n",
      "Database response message: 'CREATE SCHEMA'\n",
      "\n",
      "Query:\n",
      "    CREATE TABLE raw_data.customers(\n",
      "        customer_id int PRIMARY KEY,\n",
      "        customer_name text,\n",
      "        contact_name text,\n",
      "        country text,\n",
      "        email text\n",
      "    )\n",
      "Database response message: 'CREATE TABLE'\n",
      "\n",
      "Query:\n",
      "    INSERT INTO raw_data.customers(customer_id, customer_name, contact_name, country, email)\n",
      "    VALUES\n",
      "    (1, 'Customer A', 'Contact A', 'Country A', 'contactA@email.com'),\n",
      "    (2, 'Customer B', 'Contact B', 'Country B', 'contactB@email.com'),\n",
      "    (3, 'Customer C', 'Contact C', 'Country C', 'contactC@email.com')\n",
      "Database response message: 'INSERT 0 3'\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: fold\n",
    "#| code-summary: Setting up some test data tables in a raw_data schema\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        CREATE SCHEMA raw_data;\n",
    "        CREATE TABLE raw_data.customers (\n",
    "            customer_id int PRIMARY KEY,\n",
    "            customer_name text,\n",
    "            contact_name text,\n",
    "            country text,\n",
    "            email text\n",
    "        );\n",
    "        INSERT INTO raw_data.customers (customer_id, customer_name, contact_name, country, email)\n",
    "        VALUES\n",
    "            (1, 'Customer A', 'Contact A', 'Country A', 'contactA@email.com'),\n",
    "            (2, 'Customer B', 'Contact B', 'Country B', 'contactB@email.com'),\n",
    "            (3, 'Customer C', 'Contact C', 'Country C', 'contactC@email.com');\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad9022d-5c40-40ed-bc50-a7f093f35baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    CREATE SCHEMA clean_data\n",
      "Database response message: 'CREATE SCHEMA'\n",
      "\n",
      "Query:\n",
      "    CREATE TABLE clean_data.customers(\n",
      "        customer_id int PRIMARY KEY,\n",
      "        customer_name text,\n",
      "        contact_name text,\n",
      "        country text,\n",
      "        email text\n",
      "    )\n",
      "Database response message: 'CREATE TABLE'\n",
      "\n",
      "Query:\n",
      "    INSERT INTO clean_data.customers(customer_id, customer_name, contact_name, country, email)\n",
      "       SELECT\n",
      "           customer_id,\n",
      "            customer_name,\n",
      "            contact_name,\n",
      "            country,\n",
      "            lower(email) AS email\n",
      "        FROM raw_data.customers\n",
      "Database response message: 'INSERT 0 3'\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: fold\n",
    "#| code-summary: Creating a clean_data schema and cleaning raw data\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        CREATE SCHEMA clean_data;\n",
    "        CREATE TABLE clean_data.customers (\n",
    "            customer_id int PRIMARY KEY,\n",
    "            customer_name text,\n",
    "            contact_name text,\n",
    "            country text,\n",
    "            email text\n",
    "        );\n",
    "        INSERT INTO clean_data.customers (customer_id, customer_name, contact_name, country, email)\n",
    "        SELECT\n",
    "            customer_id,\n",
    "            customer_name,\n",
    "            contact_name,\n",
    "            country,\n",
    "            lower(email) AS email\n",
    "        FROM raw_data.customers;\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90fdae83-0c39-4c17-ae65-1b9c70882785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    SELECT current_user\n",
      "Database response message: 'SELECT 1'\n",
      "records in result: 1\n",
      "  current_user\n",
      "0  db_username\n",
      "\n",
      "Query:\n",
      "    SELECT * FROM clean_data.customers\n",
      "Database response message: 'SELECT 3'\n",
      "records in result: 3\n",
      "   customer_id customer_name contact_name    country               email\n",
      "0            1    Customer A    Contact A  Country A  contacta@email.com\n",
      "1            2    Customer B    Contact B  Country B  contactb@email.com\n",
      "2            3    Customer C    Contact C  Country C  contactc@email.com\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: Checking that my role can see a table\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        SELECT current_user;\n",
    "        SELECT * FROM clean_data.customers;\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecebf158-2dc7-4a54-bc63-7d9ffa4000af",
   "metadata": {},
   "source": [
    "#### START: Cleanup Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "336bda61-6091-47a2-bdbb-641c36eb7104",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "role \"data_analyst\" does not exist\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedObject\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m, in \u001b[0;36mexecute_query_w_existing_conn\u001b[0;34m(query, conn)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     rows \u001b[38;5;241m=\u001b[39m cur\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "\u001b[0;31mUndefinedObject\u001b[0m: role \"data_analyst\" does not exist\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| code-fold: show\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#| code-summary: Creating a new role and seeing what it can see before granting it permissions\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_transaction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m        DROP ROLE data_analyst;\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m, in \u001b[0;36mexecute_transaction\u001b[0;34m(query, print_results)\u001b[0m\n\u001b[1;32m     24\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[0;32m---> 26\u001b[0m     status_msg, result_df \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     result \u001b[38;5;241m=\u001b[39m (q, status_msg, result_df)\n\u001b[1;32m     28\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[0;32mIn[8], line 41\u001b[0m, in \u001b[0;36mexecute_query\u001b[0;34m(query, conn)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m execute_query_w_existing_conn(query\u001b[38;5;241m=\u001b[39mquery, conn\u001b[38;5;241m=\u001b[39mnew_conn)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecute_query_w_existing_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 32\u001b[0m, in \u001b[0;36mexecute_query_w_existing_conn\u001b[0;34m(query, conn)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (cur\u001b[38;5;241m.\u001b[39mstatusmessage, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m psycopg2\u001b[38;5;241m.\u001b[39mProgrammingError(err)\n",
      "\u001b[0;31mProgrammingError\u001b[0m: role \"data_analyst\" does not exist\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: Creating a new role and seeing what it can see before granting it permissions\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        --DROP ROLE analyst1;\n",
    "        --DROP ROLE analyst2;\n",
    "        DROP ROLE data_analyst;\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265351dc-63d6-4c18-9088-b186b7332d87",
   "metadata": {},
   "source": [
    "#### END: Cleanup Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f49c53-4b59-49e1-9695-808601c1976f",
   "metadata": {},
   "source": [
    "### Creating a role to set permissions for a group of users\n",
    "\n",
    "If we had to individually set the permissions for each database user, it wouldn't take long before some user(s) were mistakenly granted privileges they shouldn't have, and it would also be a chore for the data governance/IT team to have to manage this. Fortunately, Postgres allows us to create a role for a [group of users](https://www.postgresql.org/docs/15/role-membership.html) (e.g. data analysts, data engineers, data scientists, etc), define the permissions that class should have, and then grant the role to relevant users.\n",
    "\n",
    "Let's create a role for data analysts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac17253e-6a9e-4016-89a2-b06f4900e83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    CREATE ROLE data_analyst\n",
      "Database response message: 'CREATE ROLE'\n",
      "\n",
      "Query:\n",
      "    SET ROLE data_analyst\n",
      "Database response message: 'SET'\n",
      "\n",
      "Query:\n",
      "    SELECT current_user\n",
      "Database response message: 'SELECT 1'\n",
      "records in result: 1\n",
      "   current_user\n",
      "0  data_analyst\n",
      "\n",
      "Query:\n",
      "    SELECT * FROM raw_data.customers\n",
      "Database response message: '    \n",
      "    ERROR:  permission denied for schema raw_data\n",
      "    LINE 1: SELECT * FROM raw_data.customers\n",
      "                          ^\n",
      "      Error type: <class 'psycopg2.errors.InsufficientPrivilege'>'\n",
      "\n",
      "Query:\n",
      "    SELECT * FROM clean_data.customers\n",
      "Database response message: '    \n",
      "    ERROR:  permission denied for schema clean_data\n",
      "    LINE 1: SELECT * FROM clean_data.customers\n",
      "                          ^\n",
      "      Error type: <class 'psycopg2.errors.InsufficientPrivilege'>'\n",
      "\n",
      "Query:\n",
      "    SELECT rolname, rolsuper, rolcreaterole, rolcreatedb\n",
      "    FROM pg_roles\n",
      "    WHERE rolname = 'data_analyst'\n",
      "Database response message: 'SELECT 1'\n",
      "records in result: 1\n",
      "        rolname  rolsuper  rolcreaterole  rolcreatedb\n",
      "0  data_analyst     False          False        False\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: Creating a new role and seeing what it can see before granting it permissions\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        CREATE ROLE data_analyst;\n",
    "\n",
    "        SET ROLE data_analyst;\n",
    "        SELECT current_user;\n",
    "\n",
    "        SELECT * FROM raw_data.customers;\n",
    "        SELECT * FROM clean_data.customers;\n",
    "        SELECT rolname, rolsuper, rolcreaterole, rolcreatedb\n",
    "        FROM pg_roles\n",
    "        WHERE rolname = 'data_analyst';\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9915470e-f563-47ff-b2f2-c74e0a0b4181",
   "metadata": {},
   "source": [
    "Good. We created that role, switched into that role, confirmed we were in the `data_analyst` role, and then were stopped from accessing a table we didn't have permission to view.\n",
    "\n",
    "::: {.callout-note appearance=\"simple\" title=\"Question 1: What privileges does a role have by default?\" collapse=\"true\"}\n",
    "From the result above, we see that the `data_analyst` doesn't have permission to view the only tables the `raw_data` or `clean_data` schemas, but it is able to view the `pg_roles` table (which is in the public schema).\n",
    ":::\n",
    "\n",
    "The error message also helps us see what we don't have permission to access: the `clean_data` schema.\n",
    "\n",
    "A few privileges have to be granted before the `data_analyst` role can view that table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128c2c5-3882-49ab-9026-bf16b9e269ed",
   "metadata": {},
   "source": [
    "::: {.callout-note appearance=\"simple\" title=\"Note: Why I keep setting the role in each transaction\" collapse=\"true\"}\n",
    "\n",
    "Because I implemented my database connector as a context manager, it closes the connection after every transaction. This is generally a good practice, as ensures that process that was listening to the connection is released (along with all of the process's resources). In this situation however, when we execute another transaction, `get_db_connection()` will create a new connection that will have the original role: `db_username`, and we'll have to set the role to `data_analyst` in each transaction.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543515da-e365-465f-95ef-7f4fc2beedaa",
   "metadata": {},
   "source": [
    "##### Necessary Permission 1: GRANT USAGE ON SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a3aae97-11ca-46f1-b7a0-da27cb06435a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    GRANT USAGE ON SCHEMA clean_data TO data_analyst\n",
      "Database response message: 'GRANT'\n",
      "\n",
      "Query:\n",
      "    SELECT current_user\n",
      "Database response message: 'SELECT 1'\n",
      "records in result: 1\n",
      "  current_user\n",
      "0  db_username\n",
      "\n",
      "Query:\n",
      "    SET ROLE data_analyst\n",
      "Database response message: 'SET'\n",
      "\n",
      "Query:\n",
      "    SELECT current_user\n",
      "Database response message: 'SELECT 1'\n",
      "records in result: 1\n",
      "   current_user\n",
      "0  data_analyst\n",
      "\n",
      "Query:\n",
      "    SELECT * FROM clean_data.customers\n",
      "Database response message: '    \n",
      "    ERROR:  permission denied for table customers\n",
      "      Error type: <class 'psycopg2.errors.InsufficientPrivilege'>'\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: Granting the role permission to use a schema and checking again\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        GRANT USAGE ON SCHEMA clean_data TO data_analyst;\n",
    "        SELECT current_user;\n",
    "        SET ROLE data_analyst;\n",
    "        SELECT current_user;\n",
    "        SELECT * FROM clean_data.customers;\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aafa70c-9395-46e8-b628-02b806d9e8df",
   "metadata": {},
   "source": [
    "##### Necessary Permission 2: GRANT privilege ON ALL TABLES IN SCHEMA\n",
    "\n",
    "Our role still doesn't have enough privileges to see the `customers` table in the `clean_data` schema. We haven't specified whether the role should be allowed to delete tables, insert data into tables, select data from tables, etc, and `postgres` defaults to the more secure choice when there's ambiguity. So we have to specify what we want to allow the role to do.\n",
    "\n",
    "Let's assume our organization separates responsibilities such that data engineers and/or scientists updating/inserting/deleting tasks and analysts only need to be able to access data. There are many privileges we could [grant](https://www.postgresql.org/docs/15/sql-grant.html), but we only want to grant SELECT privileges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a77fdd94-a0d8-44cf-84dd-75755655cea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    GRANT SELECT ON ALL TABLES IN SCHEMA clean_data TO data_analyst\n",
      "Database response message: 'GRANT'\n",
      "\n",
      "Query:\n",
      "    SET ROLE data_analyst\n",
      "Database response message: 'SET'\n",
      "\n",
      "Query:\n",
      "    SELECT current_user\n",
      "Database response message: 'SELECT 1'\n",
      "records in result: 1\n",
      "   current_user\n",
      "0  data_analyst\n",
      "\n",
      "Query:\n",
      "    SELECT * FROM clean_data.customers\n",
      "Database response message: 'SELECT 3'\n",
      "records in result: 3\n",
      "   customer_id customer_name contact_name    country               email\n",
      "0            1    Customer A    Contact A  Country A  contacta@email.com\n",
      "1            2    Customer B    Contact B  Country B  contactb@email.com\n",
      "2            3    Customer C    Contact C  Country C  contactc@email.com\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: Granting the data_analyst role privileges to SELECT from tables in the clean_data schema\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        GRANT SELECT ON ALL TABLES IN SCHEMA clean_data TO data_analyst;\n",
    "\n",
    "        SET ROLE data_analyst;\n",
    "        SELECT current_user;\n",
    "        SELECT * FROM clean_data.customers;\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdafd83-aed0-48d9-96a2-46778f58a135",
   "metadata": {},
   "source": [
    "Now we see that the `data_analyst` role can select data from the table.\n",
    "\n",
    "Let's try creating some users and granting them the `data_analyst` role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11032146-e457-460b-9196-e35e3330dc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    SELECT rolname, rolsuper, rolcreaterole, rolcreatedb\n",
      "    FROM pg_roles\n",
      "    WHERE rolname LIKE '%analyst%'\n",
      "Database response message: 'SELECT 1'\n",
      "records in result: 1\n",
      "        rolname  rolsuper  rolcreaterole  rolcreatedb\n",
      "0  data_analyst     False          False        False\n",
      "\n",
      "Query:\n",
      "    CREATE USER analyst1\n",
      "Database response message: 'CREATE ROLE'\n",
      "\n",
      "Query:\n",
      "    GRANT data_analyst TO analyst1\n",
      "Database response message: 'GRANT ROLE'\n",
      "\n",
      "Query:\n",
      "    SELECT rolname, rolsuper, rolcreaterole, rolcreatedb\n",
      "    FROM pg_roles\n",
      "    WHERE rolname LIKE '%analyst%'\n",
      "Database response message: 'SELECT 2'\n",
      "records in result: 2\n",
      "        rolname  rolsuper  rolcreaterole  rolcreatedb\n",
      "0  data_analyst     False          False        False\n",
      "1      analyst1     False          False        False\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: Altering the default permissions for any user granted role data_analyst in the future\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        SELECT rolname, rolsuper, rolcreaterole, rolcreatedb\n",
    "        FROM pg_roles\n",
    "        WHERE rolname LIKE '%analyst%';\n",
    "\n",
    "        CREATE USER analyst1;\n",
    "        GRANT data_analyst TO analyst1;\n",
    "\n",
    "        SELECT rolname, rolsuper, rolcreaterole, rolcreatedb\n",
    "        FROM pg_roles\n",
    "        WHERE rolname LIKE '%analyst%';\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad40db0-f764-4eb5-ba9e-0ecf8fc47152",
   "metadata": {},
   "source": [
    "Let's confirm that our new user can view the table that we viewed as `data_analyst`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f163437-82c6-4613-9672-13514dd31a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    SET ROLE analyst1\n",
      "Database response message: 'SET'\n",
      "\n",
      "Query:\n",
      "    SELECT current_user\n",
      "Database response message: 'SELECT 1'\n",
      "records in result: 1\n",
      "  current_user\n",
      "0     analyst1\n",
      "\n",
      "Query:\n",
      "    SELECT * FROM clean_data.customers\n",
      "Database response message: 'SELECT 3'\n",
      "records in result: 3\n",
      "   customer_id customer_name contact_name    country               email\n",
      "0            1    Customer A    Contact A  Country A  contacta@email.com\n",
      "1            2    Customer B    Contact B  Country B  contactb@email.com\n",
      "2            3    Customer C    Contact C  Country C  contactc@email.com\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: Checking if our new user can view the tables the data_analyst role can view.\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        SET ROLE analyst1;\n",
    "        SELECT current_user;\n",
    "        SELECT * FROM clean_data.customers;\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24583a0-afb2-4af7-b688-6dec61f5e1d3",
   "metadata": {},
   "source": [
    "Confirmed, our new user has the ability to select from a table in the `data_clean` schema. Let's add another table and confirm the `data_analyst` and `analyst1` roles have permissions to view it, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c4a8ccb-e605-443f-9b07-f9c2e9e67782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    CREATE TABLE raw_data.orders(\n",
      "        order_id int PRIMARY KEY,\n",
      "        customer_id int,\n",
      "        order_date text,\n",
      "        product text,\n",
      "        quantity int,\n",
      "        FOREIGN KEY(customer_id) REFERENCES raw_data.customers(customer_id)\n",
      "    )\n",
      "Database response message: 'CREATE TABLE'\n",
      "\n",
      "Query:\n",
      "    INSERT INTO raw_data.orders(order_id, customer_id, order_date, product, quantity)\n",
      "    VALUES\n",
      "    (1, 1, '2023-01-01', 'Product A', 10),\n",
      "    (2, 1, '2023-01-02', 'Product B', 15),\n",
      "    (3, 2, '2023-02-01', 'Product A', 5),\n",
      "    (4, 3, '2023-02-02', 'Product C', 20)\n",
      "Database response message: 'INSERT 0 4'\n",
      "\n",
      "Query:\n",
      "    CREATE TABLE clean_data.orders(\n",
      "        order_id int PRIMARY KEY,\n",
      "        customer_id int,\n",
      "        order_date date,\n",
      "        product text,\n",
      "        quantity int,\n",
      "        FOREIGN KEY(customer_id) REFERENCES clean_data.customers(customer_id)\n",
      "    )\n",
      "Database response message: 'CREATE TABLE'\n",
      "\n",
      "Query:\n",
      "    INSERT INTO clean_data.orders(order_id, customer_id, order_date, product, quantity)\n",
      "       SELECT\n",
      "           order_id,\n",
      "            customer_id,\n",
      "            order_date: : date AS order_date,\n",
      "            product,\n",
      "            quantity\n",
      "        FROM raw_data.orders\n",
      "Database response message: 'INSERT 0 4'\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: Checking if our new user can view the tables the data_analyst role can view.\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        CREATE TABLE raw_data.orders (\n",
    "            order_id int PRIMARY KEY,\n",
    "            customer_id int,\n",
    "            order_date text,\n",
    "            product text,\n",
    "            quantity int,\n",
    "            FOREIGN KEY (customer_id) REFERENCES raw_data.customers(customer_id)\n",
    "        );\n",
    "        INSERT INTO raw_data.orders (order_id, customer_id, order_date, product, quantity)\n",
    "        VALUES\n",
    "            (1, 1, '2023-01-01', 'Product A', 10),\n",
    "            (2, 1, '2023-01-02', 'Product B', 15),\n",
    "            (3, 2, '2023-02-01', 'Product A', 5),\n",
    "            (4, 3, '2023-02-02', 'Product C', 20);\n",
    "        CREATE TABLE clean_data.orders (\n",
    "            order_id int PRIMARY KEY,\n",
    "            customer_id int,\n",
    "            order_date date,\n",
    "            product text,\n",
    "            quantity int,\n",
    "            FOREIGN KEY (customer_id) REFERENCES clean_data.customers(customer_id)\n",
    "        );\n",
    "        INSERT INTO clean_data.orders (order_id, customer_id, order_date, product, quantity)\n",
    "        SELECT\n",
    "            order_id,\n",
    "            customer_id,\n",
    "            order_date::date AS order_date,\n",
    "            product,\n",
    "            quantity\n",
    "        FROM raw_data.orders;\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c02582d7-aee4-422c-8803-26003689048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    SET ROLE data_analyst\n",
      "Database response message: 'SET'\n",
      "\n",
      "Query:\n",
      "    SELECT current_user\n",
      "Database response message: 'SELECT 1'\n",
      "records in result: 1\n",
      "   current_user\n",
      "0  data_analyst\n",
      "\n",
      "Query:\n",
      "    SELECT * FROM clean_data.orders\n",
      "Database response message: '    \n",
      "    ERROR:  permission denied for table orders\n",
      "      Error type: <class 'psycopg2.errors.InsufficientPrivilege'>'\n",
      "\n",
      "Query:\n",
      "    SET ROLE analyst1\n",
      "Database response message: 'SET'\n",
      "\n",
      "Query:\n",
      "    SELECT current_user\n",
      "Database response message: 'SELECT 1'\n",
      "records in result: 1\n",
      "  current_user\n",
      "0     analyst1\n",
      "\n",
      "Query:\n",
      "    SELECT * FROM clean_data.orders\n",
      "Database response message: '    \n",
      "    ERROR:  permission denied for table orders\n",
      "      Error type: <class 'psycopg2.errors.InsufficientPrivilege'>'\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: Checking if our new user can view the tables the data_analyst role can view.\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        SET ROLE data_analyst;\n",
    "        SELECT current_user;\n",
    "        SELECT * FROM clean_data.orders;\n",
    "\n",
    "        SET ROLE analyst1;\n",
    "        SELECT current_user;\n",
    "        SELECT * FROM clean_data.orders;\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb74cacf-ac60-45f3-89c7-5f5d3132b23d",
   "metadata": {},
   "source": [
    "Wait, our neither the `data_analyst` nor the `analyst1` roles have sufficient privileges to select from the new table in the `clean_data` table? Good thing we checked, as now we know we need to do more before our `data_analyst` role delivers the behavior we specified.\n",
    "\n",
    "##### Necessary Permission 2 part 2: ALTER DEFAULT PRIVILEGES\n",
    "\n",
    "`GRANT SELECT ON ALL TABLES IN clean_data` gave the `data_analyst` role (and any role inheriting from `data_analyst` at grant-execution-time) permission to select from any table in `clean_data`, but doesn't set that as the default for users granted the `data_analyst` role later on. We have to [`ALTER DEFAULT PRIVILEGES`](https://www.postgresql.org/docs/15/sql-alterdefaultprivileges.html) (which will apply to future grantings), and then we have to run the `GRANT SELECT ...` command again (to apply to the already-existing `analyst1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26ca37fc-3f99-4750-a078-07a571f700a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    ALTER DEFAULT PRIVILEGES IN SCHEMA clean_data\n",
      "    GRANT SELECT ON TABLES TO data_analyst\n",
      "Database response message: 'ALTER DEFAULT PRIVILEGES'\n",
      "\n",
      "Query:\n",
      "    GRANT SELECT ON ALL TABLES IN SCHEMA clean_data TO data_analyst\n",
      "Database response message: 'GRANT'\n",
      "\n",
      "Query:\n",
      "    SET ROLE data_analyst\n",
      "Database response message: 'SET'\n",
      "\n",
      "Query:\n",
      "    SELECT current_user\n",
      "Database response message: 'SELECT 1'\n",
      "records in result: 1\n",
      "   current_user\n",
      "0  data_analyst\n",
      "\n",
      "Query:\n",
      "    SELECT * FROM clean_data.orders\n",
      "Database response message: 'SELECT 4'\n",
      "records in result: 4\n",
      "   order_id  customer_id  order_date    product  quantity\n",
      "0         1            1  2023-01-01  Product A        10\n",
      "1         2            1  2023-01-02  Product B        15\n",
      "2         3            2  2023-02-01  Product A         5\n",
      "3         4            3  2023-02-02  Product C        20\n",
      "\n",
      "Query:\n",
      "    SET ROLE analyst1\n",
      "Database response message: 'SET'\n",
      "\n",
      "Query:\n",
      "    SELECT current_user\n",
      "Database response message: 'SELECT 1'\n",
      "records in result: 1\n",
      "  current_user\n",
      "0     analyst1\n",
      "\n",
      "Query:\n",
      "    SELECT * FROM clean_data.orders\n",
      "Database response message: 'SELECT 4'\n",
      "records in result: 4\n",
      "   order_id  customer_id  order_date    product  quantity\n",
      "0         1            1  2023-01-01  Product A        10\n",
      "1         2            1  2023-01-02  Product B        15\n",
      "2         3            2  2023-02-01  Product A         5\n",
      "3         4            3  2023-02-02  Product C        20\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: Altering the default permissions for any user granted role data_analyst in the future\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        ALTER DEFAULT PRIVILEGES IN SCHEMA clean_data\n",
    "            GRANT SELECT ON TABLES TO data_analyst;\n",
    "        GRANT SELECT ON ALL TABLES IN SCHEMA clean_data TO data_analyst;\n",
    "\n",
    "        SET ROLE data_analyst;\n",
    "        SELECT current_user;\n",
    "        SELECT * FROM clean_data.orders;\n",
    "\n",
    "        SET ROLE analyst1;\n",
    "        SELECT current_user;\n",
    "        SELECT * FROM clean_data.orders;\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0bdb287-48b6-42d9-9ee7-b22bcaabdc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    SELECT rolname, rolsuper, rolcreaterole, rolcreatedb\n",
      "    FROM pg_roles\n",
      "    WHERE rolname LIKE '%analyst%'\n",
      "Database response message: 'SELECT 3'\n",
      "records in result: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rolname</th>\n",
       "      <th>rolsuper</th>\n",
       "      <th>rolcreaterole</th>\n",
       "      <th>rolcreatedb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>analyst1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>analyst2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rolname  rolsuper  rolcreaterole  rolcreatedb\n",
       "0  data_analyst     False          False        False\n",
       "1      analyst1     False          False        False\n",
       "2      analyst2     False          False        False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ProgrammingError",
     "evalue": "role \"analyst2\" already exists\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateObject\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 22\u001b[0m, in \u001b[0;36mexecute_query_w_existing_conn\u001b[0;34m(query, conn)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     rows \u001b[38;5;241m=\u001b[39m cur\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "\u001b[0;31mDuplicateObject\u001b[0m: role \"analyst2\" already exists\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| code-fold: show\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#| code-summary: Altering the default permissions for any user granted role data_analyst in the future\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_transaction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m        SELECT rolname, rolsuper, rolcreaterole, rolcreatedb\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m        FROM pg_roles\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m        WHERE rolname LIKE \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%a\u001b[39;49;00m\u001b[38;5;124;43mnalyst\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m        CREATE USER analyst2;\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43m        GRANT data_analyst TO analyst2;\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43m        SELECT rolname, rolsuper, rolcreaterole, rolcreatedb\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43m        FROM pg_roles\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43m        WHERE rolname LIKE \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%a\u001b[39;49;00m\u001b[38;5;124;43mnalyst\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m, in \u001b[0;36mexecute_transaction\u001b[0;34m(query, print_results)\u001b[0m\n\u001b[1;32m     24\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[0;32m---> 26\u001b[0m     status_msg, result_df \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     result \u001b[38;5;241m=\u001b[39m (q, status_msg, result_df)\n\u001b[1;32m     28\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[0;32mIn[36], line 41\u001b[0m, in \u001b[0;36mexecute_query\u001b[0;34m(query, conn)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m execute_query_w_existing_conn(query\u001b[38;5;241m=\u001b[39mquery, conn\u001b[38;5;241m=\u001b[39mnew_conn)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecute_query_w_existing_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 32\u001b[0m, in \u001b[0;36mexecute_query_w_existing_conn\u001b[0;34m(query, conn)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (cur\u001b[38;5;241m.\u001b[39mstatusmessage, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m psycopg2\u001b[38;5;241m.\u001b[39mProgrammingError(err)\n",
      "\u001b[0;31mProgrammingError\u001b[0m: role \"analyst2\" already exists\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: Altering the default permissions for any user granted role data_analyst in the future\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        SELECT rolname, rolsuper, rolcreaterole, rolcreatedb\n",
    "        FROM pg_roles\n",
    "        WHERE rolname LIKE '%analyst%';\n",
    "\n",
    "        CREATE USER analyst2;\n",
    "        GRANT data_analyst TO analyst2;\n",
    "\n",
    "        SELECT rolname, rolsuper, rolcreaterole, rolcreatedb\n",
    "        FROM pg_roles\n",
    "        WHERE rolname LIKE '%analyst%';\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c0d898-fe32-406e-a9e5-659413009be3",
   "metadata": {},
   "source": [
    "#### Revoking privileges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff6955e9-c69e-40e4-b58c-85a115a8c783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    REVOKE USAGE ON SCHEMA clean_data FROM data_analyst\n",
      "Database response message: 'REVOKE'\n",
      "\n",
      "Query:\n",
      "    REVOKE SELECT ON ALL TABLES IN SCHEMA clean_data FROM data_analyst\n",
      "Database response message: 'REVOKE'\n"
     ]
    }
   ],
   "source": [
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        REVOKE USAGE ON SCHEMA clean_data FROM data_analyst;\n",
    "        REVOKE SELECT ON ALL TABLES IN SCHEMA clean_data FROM data_analyst;\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c845156d-3e65-4b35-8f16-6f8bef5ff6a6",
   "metadata": {},
   "source": [
    "### Cleaning up the sandbox\n",
    "\n",
    "When we're done with our experiments, we can tell docker to shut down our sandbox container and delete the volume storing our sandbox's database via this command.\n",
    "\n",
    "```bash\n",
    "docker compose down -v\n",
    "```\n",
    "\n",
    "To shut down our container without deleting the volume, just leave off the `-v` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0618490-884d-4e66-9024-9ea8257fcd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 1/0\n",
      " \u001b[32m\u001b[0m Volume 015_docker_postgres_sandbox_sandbox_postgis_data  \u001b[32mRemoved\u001b[0m        \u001b[34m0.0s \u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Shutting down our sandbox and deleting our volume\n",
    "\n",
    "!docker compose down -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a7a1edc4-7372-4840-9744-66c07ea56a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Shows that our system's one container has shut down\n",
    "\n",
    "!docker ps -a -f name=sandbox-postgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc3b951-afe3-4096-a4d7-4fc7d5b41b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a0adce-6d51-48e2-8167-7ac2018124e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595475b-8eee-4b9d-a1a9-f7f1c6cfbc71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fadbd4-2349-4844-af57-1d469be3a896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e69465-250c-407c-998e-76da986f0f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        CREATE TABLE raw_data.orders (\n",
    "            order_id int PRIMARY KEY,\n",
    "            customer_id int,\n",
    "            order_date text,\n",
    "            product text,\n",
    "            quantity int,\n",
    "            FOREIGN KEY (customer_id) REFERENCES raw_data.customers(customer_id)\n",
    "        );\n",
    "        INSERT INTO raw_data.orders (order_id, customer_id, order_date, product, quantity)\n",
    "        VALUES\n",
    "            (1, 1, '2023-01-01', 'Product A', 10),\n",
    "            (2, 1, '2023-01-02', 'Product B', 15),\n",
    "            (3, 2, '2023-02-01', 'Product A', 5),\n",
    "            (4, 3, '2023-02-02', 'Product C', 20);\n",
    "        CREATE TABLE clean_data.orders (\n",
    "            order_id int PRIMARY KEY,\n",
    "            customer_id int,\n",
    "            order_date date,\n",
    "            product text,\n",
    "            quantity int,\n",
    "            FOREIGN KEY (customer_id) REFERENCES clean_data.customers(customer_id)\n",
    "        );\n",
    "        INSERT INTO clean_data.orders (order_id, customer_id, order_date, product, quantity)\n",
    "        SELECT\n",
    "            order_id,\n",
    "            customer_id,\n",
    "            order_date::date AS order_date,\n",
    "            product,\n",
    "            quantity\n",
    "        FROM raw_data.orders;\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "01f3c10e-4d3f-477f-b836-04bdb76415e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:\n",
      "    CREATE SCHEMA clean_data\n",
      "Database response message: 'CREATE SCHEMA'\n",
      "\n",
      "Query:\n",
      "    CREATE TABLE clean_data.customers(\n",
      "        customer_id int PRIMARY KEY,\n",
      "        customer_name text,\n",
      "        contact_name text,\n",
      "        country text,\n",
      "        email text\n",
      "    )\n",
      "Database response message: 'CREATE TABLE'\n",
      "\n",
      "Query:\n",
      "    CREATE TABLE clean_data.orders(\n",
      "        order_id int PRIMARY KEY,\n",
      "        customer_id int,\n",
      "        order_date date,\n",
      "        product text,\n",
      "        quantity int,\n",
      "        FOREIGN KEY(customer_id) REFERENCES clean_data.customers(customer_id)\n",
      "    )\n",
      "Database response message: 'CREATE TABLE'\n",
      "\n",
      "Query:\n",
      "    INSERT INTO clean_data.customers(customer_id, customer_name, contact_name, country, email)\n",
      "       SELECT\n",
      "           customer_id,\n",
      "            customer_name,\n",
      "            contact_name,\n",
      "            country,\n",
      "            lower(email) AS email\n",
      "        FROM raw_data.customers\n",
      "Database response message: 'INSERT 0 3'\n",
      "\n",
      "Query:\n",
      "    INSERT INTO clean_data.orders(order_id, customer_id, order_date, product, quantity)\n",
      "       SELECT\n",
      "           order_id,\n",
      "            customer_id,\n",
      "            order_date: : date AS order_date,\n",
      "            product,\n",
      "            quantity\n",
      "        FROM raw_data.orders\n",
      "Database response message: 'INSERT 0 4'\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: fold\n",
    "#| code-summary: Creating a clean_data schema and cleaning raw data\n",
    "\n",
    "results = execute_transaction(\n",
    "    query=\"\"\"\n",
    "        CREATE TABLE clean_data.orders (\n",
    "            order_id int PRIMARY KEY,\n",
    "            customer_id int,\n",
    "            order_date date,\n",
    "            product text,\n",
    "            quantity int,\n",
    "            FOREIGN KEY (customer_id) REFERENCES clean_data.customers(customer_id)\n",
    "        );\n",
    "        INSERT INTO clean_data.orders (order_id, customer_id, order_date, product, quantity)\n",
    "        SELECT\n",
    "            order_id,\n",
    "            customer_id,\n",
    "            order_date::date AS order_date,\n",
    "            product,\n",
    "            quantity\n",
    "        FROM raw_data.orders;\n",
    "    \"\"\",\n",
    "    print_results=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7573b046-4f1e-4e3d-be6a-2aa800b151f7",
   "metadata": {},
   "source": [
    "It took all three steps to grant the `data_analyst` role sufficient privileges to view the table.\n",
    "\n",
    "TODO:\n",
    "~~* Create a user role,~~\n",
    "~~* Grant the user that data analyst role,~~\n",
    "~~* Show it gained the privileges,~~\n",
    "* Create a new table in `clean_data`\n",
    "* Show that the user can't view the table,\n",
    "\n",
    "* Revoke privs,\n",
    "* Show revocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d713652b-5b3d-4480-a195-dd79b6ebd687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rolname</th>\n",
       "      <th>rolsuper</th>\n",
       "      <th>rolcreaterole</th>\n",
       "      <th>rolcreatedb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rolname  rolsuper  rolcreaterole  rolcreatedb\n",
       "0  data_analyst     False          False        False"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: show\n",
    "#| code-summary: Checking \n",
    "\n",
    "msg, pg_roles_df = execute_query(\n",
    "    query=\"\"\"\n",
    "        SELECT rolname, rolsuper, rolcreaterole, rolcreatedb\n",
    "        FROM pg_roles\n",
    "        WHERE rolname = 'data_analyst';\n",
    "    \"\"\"\n",
    ")\n",
    "pg_roles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "609e0f88-c98b-4173-9055-6d92c2eb0cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CREATE ROLE', None)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query(query=\"\"\"CREATE ROLE data_analyst;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ddfe281d-bd27-4318-84cb-c2a4bdb43f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rolname</th>\n",
       "      <th>rolsuper</th>\n",
       "      <th>rolcreaterole</th>\n",
       "      <th>rolcreatedb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_analyst</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rolname  rolsuper  rolcreaterole  rolcreatedb\n",
       "0  data_analyst     False          False        False"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg, pg_roles_df = execute_query(\n",
    "    query=\"\"\"\n",
    "        SELECT rolname, rolsuper, rolcreaterole, rolcreatedb\n",
    "        FROM pg_roles\n",
    "        WHERE rolname LIKE '%analyst%';\n",
    "    \"\"\"\n",
    ")\n",
    "pg_roles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0c9eb493-db0d-42f3-9e09-9d7cdfd36e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SET', None)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query(query=\"\"\"SET ROLE data_analyst;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "40a36120-25ac-47b6-a5b5-6b906e606302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RESET', None)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = execute_query(query=\"\"\"RESET ROLE;\"\"\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e42e1be6-dd92-4799-bb60-1ba80129e01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \n",
      "    SELECT current_user\n",
      "Status msg: SELECT 1\n",
      "\n",
      "records in result: 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>db_username</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  current_user\n",
       "0  db_username"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = execute_transaction(query=\"\"\"SELECT current_user;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "88add3c9-24fc-4ce8-93e9-a2417d3468c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \n",
      "    DROP ROLE data_analyst\n",
      "Status msg: DROP ROLE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = execute_transaction(query=\"\"\"DROP ROLE data_analyst;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6e0958f5-c480-41c7-a493-abe87df2ce19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SELECT 1',\n",
       "   current_user\n",
       " 0  db_username)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query(query=\"\"\"SELECT current_user;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a6f7a-f983-4f88-8631-e0bf2c8868d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa57d2b-4efb-42ef-bce1-d12315513fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7cb0b9-a4c3-46db-8a8c-3b63e94db189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630e9c6-eb7f-42f1-931f-b37ac54d63c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef084ad-ecaf-43a8-9baf-064c35d5e8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6350a740-c0fa-4bd7-b95d-c3255e970ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "091b1cda-89dd-4818-8331-00f51c4b3b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schema_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pg_toast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pg_catalog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>information_schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>topology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tiger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tiger_data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          schema_name\n",
       "0            pg_toast\n",
       "1          pg_catalog\n",
       "2              public\n",
       "3  information_schema\n",
       "4            topology\n",
       "5               tiger\n",
       "6          tiger_data"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemas = execute_query(query=\"\"\"\n",
    "    SELECT nspname AS schema_name\n",
    "    FROM pg_namespace;\n",
    "\"\"\")\n",
    "schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfba0ef-f89a-4c46-9b77-997bca39f440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec72c85-542e-4274-a807-9fbbc49f7b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb9e85f3-2b64-49bf-a01d-d1b66042ef08",
   "metadata": {},
   "source": [
    "[^1]: Before you can use docker and compose, you have to install [docker](https://docs.docker.com/engine/install/) and [compose](https://docs.docker.com/compose/install/). I installed the docker engine and compose, but it looks like the developers at Docker Inc. guide people towards installing their Docker Desktop client. In either setup, docker should still become available to you via the command line, so instructions in this post should work.\n",
    "\n",
    "[^2]: Docker containers are designed to be a replicable instance of an image, so when you shut down your application, your containers are removed and new ones are created next time you start it up. This is great for reproducibility (you always get a new, clean instance based on your image), but you don't want the data you ingest into your database to get wiped every time you shut down your system, so you can define a persistent **volume** that will live on in the host system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ac0b1-e92d-4e7c-921d-6682e23d3337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(pg_env)",
   "language": "python",
   "name": "pg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
